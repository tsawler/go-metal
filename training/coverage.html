
<!DOCTYPE html>
<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
		<title>training: Go Coverage Report</title>
		<style>
			body {
				background: black;
				color: rgb(80, 80, 80);
			}
			body, pre, #legend span {
				font-family: Menlo, monospace;
				font-weight: bold;
			}
			#topbar {
				background: black;
				position: fixed;
				top: 0; left: 0; right: 0;
				height: 42px;
				border-bottom: 1px solid rgb(80, 80, 80);
			}
			#content {
				margin-top: 50px;
			}
			#nav, #legend {
				float: left;
				margin-left: 10px;
			}
			#legend {
				margin-top: 12px;
			}
			#nav {
				margin-top: 10px;
			}
			#legend span {
				margin: 0 5px;
			}
			.cov0 { color: rgb(192, 0, 0) }
.cov1 { color: rgb(128, 128, 128) }
.cov2 { color: rgb(116, 140, 131) }
.cov3 { color: rgb(104, 152, 134) }
.cov4 { color: rgb(92, 164, 137) }
.cov5 { color: rgb(80, 176, 140) }
.cov6 { color: rgb(68, 188, 143) }
.cov7 { color: rgb(56, 200, 146) }
.cov8 { color: rgb(44, 212, 149) }
.cov9 { color: rgb(32, 224, 152) }
.cov10 { color: rgb(20, 236, 155) }

		</style>
	</head>
	<body>
		<div id="topbar">
			<div id="nav">
				<select id="files">
				
				<option value="file0">github.com/tsawler/go-metal/training/checkpoint_integration.go (0.0%)</option>
				
				<option value="file1">github.com/tsawler/go-metal/training/labels.go (0.0%)</option>
				
				<option value="file2">github.com/tsawler/go-metal/training/metrics.go (1.6%)</option>
				
				<option value="file3">github.com/tsawler/go-metal/training/model_inferencer.go (0.0%)</option>
				
				<option value="file4">github.com/tsawler/go-metal/training/model_trainer.go (8.0%)</option>
				
				<option value="file5">github.com/tsawler/go-metal/training/plotting_service.go (1.0%)</option>
				
				<option value="file6">github.com/tsawler/go-metal/training/progress.go (93.8%)</option>
				
				<option value="file7">github.com/tsawler/go-metal/training/progress_example.go (0.0%)</option>
				
				<option value="file8">github.com/tsawler/go-metal/training/scheduler.go (74.1%)</option>
				
				<option value="file9">github.com/tsawler/go-metal/training/sidecar_helper.go (0.0%)</option>
				
				<option value="file10">github.com/tsawler/go-metal/training/simple_trainer.go (8.5%)</option>
				
				<option value="file11">github.com/tsawler/go-metal/training/visualization.go (0.2%)</option>
				
				</select>
			</div>
			<div id="legend">
				<span>not tracked</span>
			
				<span class="cov0">not covered</span>
				<span class="cov8">covered</span>
			
			</div>
		</div>
		<div id="content">
		
		<pre class="file" id="file0" style="display: none">package training

import (
        "fmt"
        "os"
        "path/filepath"

        "github.com/tsawler/go-metal/checkpoints"
        "github.com/tsawler/go-metal/layers"
        "github.com/tsawler/go-metal/memory"
)

// CheckpointConfig configures checkpoint saving behavior
type CheckpointConfig struct {
        SaveDirectory    string                        // Directory to save checkpoints
        SaveFrequency    int                          // Save every N epochs (0 = disabled)
        SaveBest         bool                         // Save checkpoint when validation improves
        MaxCheckpoints   int                          // Maximum number of checkpoints to keep (0 = unlimited)
        Format           checkpoints.CheckpointFormat // JSON or ONNX
        FilenamePattern  string                       // Pattern for checkpoint filenames
}

// DefaultCheckpointConfig returns a sensible default configuration
func DefaultCheckpointConfig() CheckpointConfig <span class="cov0" title="0">{
        return CheckpointConfig{
                SaveDirectory:   "./checkpoints",
                SaveFrequency:   5, // Save every 5 epochs
                SaveBest:        true,
                MaxCheckpoints:  10,
                Format:          checkpoints.FormatJSON,
                FilenamePattern: "checkpoint_epoch_%d_step_%d",
        }
}</span>

// CheckpointManager handles checkpoint saving and loading for ModelTrainer
type CheckpointManager struct {
        config      CheckpointConfig
        trainer     *ModelTrainer
        saver       *checkpoints.CheckpointSaver
        bestLoss    float32
        bestAccuracy float32
        savedFiles  []string // Track saved checkpoint files for cleanup
}

// NewCheckpointManager creates a new checkpoint manager
func NewCheckpointManager(trainer *ModelTrainer, config CheckpointConfig) *CheckpointManager <span class="cov0" title="0">{
        return &amp;CheckpointManager{
                config:       config,
                trainer:      trainer,
                saver:        checkpoints.NewCheckpointSaver(config.Format),
                bestLoss:     float32(1e9), // Initialize with high loss
                bestAccuracy: 0.0,
                savedFiles:   make([]string, 0),
        }
}</span>

// SaveCheckpoint saves the current model state
func (cm *CheckpointManager) SaveCheckpoint(epoch int, step int, loss float32, accuracy float32, description string) error <span class="cov0" title="0">{
        // Create checkpoint from current trainer state
        checkpoint, err := cm.createCheckpointFromTrainer(epoch, step, loss, accuracy, description)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create checkpoint: %v", err)
        }</span>
        
        // Generate filename
        <span class="cov0" title="0">filename := cm.generateFilename(epoch, step)
        filepath := filepath.Join(cm.config.SaveDirectory, filename)
        
        // Ensure directory exists
        if err := cm.ensureDirectory(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create checkpoint directory: %v", err)
        }</span>
        
        // Save checkpoint
        <span class="cov0" title="0">if err := cm.saver.SaveCheckpoint(checkpoint, filepath); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to save checkpoint: %v", err)
        }</span>
        
        // Track saved file
        <span class="cov0" title="0">cm.savedFiles = append(cm.savedFiles, filepath)
        
        // Cleanup old checkpoints if needed
        if err := cm.cleanupOldCheckpoints(); err != nil </span><span class="cov0" title="0">{
                // Log warning but don't fail the save operation
                fmt.Printf("Warning: failed to cleanup old checkpoints: %v\n", err)
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// SaveBestCheckpoint saves a checkpoint if it's better than previous best
func (cm *CheckpointManager) SaveBestCheckpoint(epoch int, step int, loss float32, accuracy float32) (bool, error) <span class="cov0" title="0">{
        if !cm.config.SaveBest </span><span class="cov0" title="0">{
                return false, nil
        }</span>
        
        // Check if this is better than previous best
        <span class="cov0" title="0">isBetterLoss := loss &lt; cm.bestLoss
        isBetterAccuracy := accuracy &gt; cm.bestAccuracy
        
        if isBetterLoss || isBetterAccuracy </span><span class="cov0" title="0">{
                // Update best metrics
                if isBetterLoss </span><span class="cov0" title="0">{
                        cm.bestLoss = loss
                }</span>
                <span class="cov0" title="0">if isBetterAccuracy </span><span class="cov0" title="0">{
                        cm.bestAccuracy = accuracy
                }</span>
                
                // Save as best checkpoint
                <span class="cov0" title="0">description := fmt.Sprintf("Best checkpoint - Loss: %.6f, Accuracy: %.2f%%", loss, accuracy*100)
                filename := fmt.Sprintf("best_checkpoint.%s", cm.getFileExtension())
                filepath := filepath.Join(cm.config.SaveDirectory, filename)
                
                checkpoint, err := cm.createCheckpointFromTrainer(epoch, step, loss, accuracy, description)
                if err != nil </span><span class="cov0" title="0">{
                        return false, fmt.Errorf("failed to create best checkpoint: %v", err)
                }</span>
                
                <span class="cov0" title="0">if err := cm.saver.SaveCheckpoint(checkpoint, filepath); err != nil </span><span class="cov0" title="0">{
                        return false, fmt.Errorf("failed to save best checkpoint: %v", err)
                }</span>
                
                <span class="cov0" title="0">return true, nil</span>
        }
        
        <span class="cov0" title="0">return false, nil</span>
}

// SavePeriodicCheckpoint saves a checkpoint if it's time based on frequency
func (cm *CheckpointManager) SavePeriodicCheckpoint(epoch int, step int, loss float32, accuracy float32) (bool, error) <span class="cov0" title="0">{
        if cm.config.SaveFrequency &lt;= 0 </span><span class="cov0" title="0">{
                return false, nil
        }</span>
        
        <span class="cov0" title="0">if epoch%cm.config.SaveFrequency == 0 </span><span class="cov0" title="0">{
                description := fmt.Sprintf("Periodic checkpoint - Epoch %d", epoch)
                if err := cm.SaveCheckpoint(epoch, step, loss, accuracy, description); err != nil </span><span class="cov0" title="0">{
                        return false, err
                }</span>
                <span class="cov0" title="0">return true, nil</span>
        }
        
        <span class="cov0" title="0">return false, nil</span>
}

// LoadCheckpoint loads a checkpoint and restores trainer state
func (cm *CheckpointManager) LoadCheckpoint(filepath string) error <span class="cov0" title="0">{
        // Load checkpoint
        checkpoint, err := cm.saver.LoadCheckpoint(filepath)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to load checkpoint: %v", err)
        }</span>
        
        // Restore trainer state from checkpoint
        <span class="cov0" title="0">if err := cm.restoreTrainerFromCheckpoint(checkpoint); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to restore trainer state: %v", err)
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// createCheckpointFromTrainer creates a checkpoint from current trainer state
func (cm *CheckpointManager) createCheckpointFromTrainer(epoch int, step int, loss float32, accuracy float32, description string) (*checkpoints.Checkpoint, error) <span class="cov0" title="0">{
        // Get model specification
        modelSpec := cm.trainer.GetModelSpec()
        if modelSpec == nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("trainer has no model specification")
        }</span>
        
        // Extract weights from GPU tensors
        <span class="cov0" title="0">parameterTensors := cm.trainer.GetParameterTensors()
        weights, err := checkpoints.ExtractWeightsFromTensors(parameterTensors, modelSpec)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to extract weights: %v", err)
        }</span>
        
        // Create training state
        <span class="cov0" title="0">trainingState := checkpoints.TrainingState{
                Epoch:        epoch,
                Step:         step,
                LearningRate: cm.trainer.GetCurrentLearningRate(),
                BestLoss:     cm.bestLoss,
                BestAccuracy: cm.bestAccuracy,
                TotalSteps:   step,
        }
        
        // Create optimizer state (if available)
        var optimizerState *checkpoints.OptimizerState
        if optimizerData := cm.trainer.GetOptimizerState(); optimizerData != nil </span><span class="cov0" title="0">{
                optimizerState = &amp;checkpoints.OptimizerState{
                        Type:       optimizerData.Type,
                        Parameters: optimizerData.Parameters,
                        StateData:  optimizerData.StateData,
                }
        }</span>
        
        // Create checkpoint
        <span class="cov0" title="0">checkpoint := &amp;checkpoints.Checkpoint{
                ModelSpec:      modelSpec,
                Weights:        weights,
                TrainingState:  trainingState,
                OptimizerState: optimizerState,
                Metadata: checkpoints.CheckpointMetadata{
                        Version:     "1.0.0",
                        Framework:   "go-metal",
                        Description: description,
                        Tags:        []string{fmt.Sprintf("epoch_%d", epoch)},
                },
        }
        
        return checkpoint, nil</span>
}

// restoreTrainerFromCheckpoint restores trainer state from checkpoint
func (cm *CheckpointManager) restoreTrainerFromCheckpoint(checkpoint *checkpoints.Checkpoint) error <span class="cov0" title="0">{
        // Validate model compatibility
        currentModelSpec := cm.trainer.GetModelSpec()
        if currentModelSpec == nil </span><span class="cov0" title="0">{
                return fmt.Errorf("trainer has no model specification")
        }</span>
        
        // Check if model architectures match
        <span class="cov0" title="0">if !cm.modelsCompatible(currentModelSpec, checkpoint.ModelSpec) </span><span class="cov0" title="0">{
                return fmt.Errorf("checkpoint model architecture incompatible with current trainer")
        }</span>
        
        // Load weights into GPU tensors
        <span class="cov0" title="0">parameterTensors := cm.trainer.GetParameterTensors()
        if err := checkpoints.LoadWeightsIntoTensors(checkpoint.Weights, parameterTensors); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to load weights: %v", err)
        }</span>
        
        // Restore training state
        <span class="cov0" title="0">cm.bestLoss = checkpoint.TrainingState.BestLoss
        cm.bestAccuracy = checkpoint.TrainingState.BestAccuracy
        
        // Set learning rate if scheduler is available
        if scheduler := cm.trainer.GetLRScheduler(); scheduler != nil </span><span class="cov0" title="0">{
                cm.trainer.SetLearningRate(checkpoint.TrainingState.LearningRate)
        }</span>
        
        // Restore optimizer state if available
        <span class="cov0" title="0">if checkpoint.OptimizerState != nil </span><span class="cov0" title="0">{
                if err := cm.trainer.SetOptimizerState(checkpoint.OptimizerState); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to restore optimizer state: %v", err)
                }</span>
        }
        
        <span class="cov0" title="0">return nil</span>
}

// Helper methods

func (cm *CheckpointManager) generateFilename(epoch int, step int) string <span class="cov0" title="0">{
        pattern := cm.config.FilenamePattern
        if pattern == "" </span><span class="cov0" title="0">{
                pattern = "checkpoint_epoch_%d_step_%d"
        }</span>
        
        // Generate the base filename using the pattern
        <span class="cov0" title="0">baseFilename := fmt.Sprintf(pattern, epoch, step)
        
        // Add the file extension
        filename := fmt.Sprintf("%s.%s", baseFilename, cm.getFileExtension())
        
        return filename</span>
}

func (cm *CheckpointManager) getFileExtension() string <span class="cov0" title="0">{
        switch cm.config.Format </span>{
        case checkpoints.FormatJSON:<span class="cov0" title="0">
                return "json"</span>
        case checkpoints.FormatONNX:<span class="cov0" title="0">
                return "onnx"</span>
        default:<span class="cov0" title="0">
                return "json"</span>
        }
}

func (cm *CheckpointManager) ensureDirectory() error <span class="cov0" title="0">{
        return os.MkdirAll(cm.config.SaveDirectory, 0755)
}</span>

func (cm *CheckpointManager) cleanupOldCheckpoints() error <span class="cov0" title="0">{
        if cm.config.MaxCheckpoints &lt;= 0 </span><span class="cov0" title="0">{
                return nil // No limit
        }</span>
        
        <span class="cov0" title="0">if len(cm.savedFiles) &lt;= cm.config.MaxCheckpoints </span><span class="cov0" title="0">{
                return nil // Under limit
        }</span>
        
        // Remove oldest checkpoints
        <span class="cov0" title="0">toRemove := len(cm.savedFiles) - cm.config.MaxCheckpoints
        for i := 0; i &lt; toRemove; i++ </span><span class="cov0" title="0">{
                if err := os.Remove(cm.savedFiles[i]); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to remove old checkpoint %s: %v", cm.savedFiles[i], err)
                }</span>
        }
        
        // Update tracked files
        <span class="cov0" title="0">cm.savedFiles = cm.savedFiles[toRemove:]
        
        return nil</span>
}

func (cm *CheckpointManager) modelsCompatible(model1, model2 *layers.ModelSpec) bool <span class="cov0" title="0">{
        // Check if models have same number of layers
        if len(model1.Layers) != len(model2.Layers) </span><span class="cov0" title="0">{
                return false
        }</span>
        
        // Check if each layer is compatible
        <span class="cov0" title="0">for i, layer1 := range model1.Layers </span><span class="cov0" title="0">{
                layer2 := model2.Layers[i]
                
                // Check layer type
                if layer1.Type != layer2.Type </span><span class="cov0" title="0">{
                        return false
                }</span>
                
                // Check parameter shapes (this ensures weight tensors are compatible)
                <span class="cov0" title="0">if len(layer1.ParameterShapes) != len(layer2.ParameterShapes) </span><span class="cov0" title="0">{
                        return false
                }</span>
                
                <span class="cov0" title="0">for j, shape1 := range layer1.ParameterShapes </span><span class="cov0" title="0">{
                        shape2 := layer2.ParameterShapes[j]
                        if len(shape1) != len(shape2) </span><span class="cov0" title="0">{
                                return false
                        }</span>
                        <span class="cov0" title="0">for k, dim1 := range shape1 </span><span class="cov0" title="0">{
                                if dim1 != shape2[k] </span><span class="cov0" title="0">{
                                        return false
                                }</span>
                        }
                }
        }
        
        <span class="cov0" title="0">return true</span>
}

// Add checkpoint methods to ModelTrainer interface
type CheckpointCapable interface {
        GetModelSpec() *layers.ModelSpec
        GetParameterTensors() []*memory.Tensor
        GetCurrentLearningRate() float32
        GetLRScheduler() interface{} // Returns the scheduler if available
        SetLearningRate(lr float32)
        GetOptimizerState() *OptimizerStateData
        SetOptimizerState(state *checkpoints.OptimizerState) error
}

// OptimizerStateData represents internal optimizer state
type OptimizerStateData struct {
        Type       string
        Parameters map[string]interface{}
        StateData  []checkpoints.OptimizerTensor
}</pre>
		
		<pre class="file" id="file1" style="display: none">package training

import (
        "fmt"
        "unsafe"
)

// LabelData provides a flexible interface for different label types
// This enables zero-cost abstractions for both classification and regression
// while maintaining GPU-residency and minimizing CGO calls
type LabelData interface {
        // ToFloat32Slice returns the underlying data as []float32 for GPU consumption
        // For Float32Labels: returns slice directly (zero-cost)
        // For Int32Labels: converts to float32 (one-time cost)
        // PERFORMANCE: This method is designed to minimize allocations
        ToFloat32Slice() []float32
        
        // DataType returns the semantic type of labels for loss function selection
        DataType() LabelDataType
        
        // Size returns the number of label elements
        Size() int
        
        // Shape returns the tensor shape of labels [batch_size, num_classes/dims]
        Shape() []int
        
        // UnsafePointer returns a pointer to the underlying data for CGO
        // This enables zero-copy transfer to GPU
        UnsafePointer() unsafe.Pointer
}

// LabelDataType represents the semantic type of labels
type LabelDataType int

const (
        LabelTypeInt32   LabelDataType = iota // Classification labels
        LabelTypeFloat32                      // Regression targets
)

// String returns human-readable label type name
func (ldt LabelDataType) String() string <span class="cov0" title="0">{
        switch ldt </span>{
        case LabelTypeInt32:<span class="cov0" title="0">
                return "Classification"</span>
        case LabelTypeFloat32:<span class="cov0" title="0">
                return "Regression"</span>
        default:<span class="cov0" title="0">
                return fmt.Sprintf("Unknown(%d)", ldt)</span>
        }
}

// Int32Labels wraps []int32 for classification tasks
// Implements LabelData interface with minimal overhead
type Int32Labels struct {
        data  []int32
        shape []int
        // Cache the float32 conversion to avoid repeated allocations
        cachedFloat32 []float32
}

// NewInt32Labels creates classification labels with shape validation
func NewInt32Labels(data []int32, shape []int) (*Int32Labels, error) <span class="cov0" title="0">{
        if len(shape) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("shape cannot be empty")
        }</span>
        
        <span class="cov0" title="0">expectedSize := 1
        for _, dim := range shape </span><span class="cov0" title="0">{
                if dim &lt;= 0 </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("invalid shape dimension: %d", dim)
                }</span>
                <span class="cov0" title="0">expectedSize *= dim</span>
        }
        
        <span class="cov0" title="0">if len(data) != expectedSize </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("data size %d doesn't match shape %v (expected %d)", 
                        len(data), shape, expectedSize)
        }</span>
        
        // Make a copy of shape to prevent external modifications
        <span class="cov0" title="0">shapeCopy := make([]int, len(shape))
        copy(shapeCopy, shape)
        
        return &amp;Int32Labels{
                data:  data,
                shape: shapeCopy,
        }, nil</span>
}

// ToFloat32Slice converts int32 labels to float32
// Uses cached conversion to minimize allocations
func (l *Int32Labels) ToFloat32Slice() []float32 <span class="cov0" title="0">{
        if l.cachedFloat32 == nil </span><span class="cov0" title="0">{
                l.cachedFloat32 = make([]float32, len(l.data))
                for i, v := range l.data </span><span class="cov0" title="0">{
                        l.cachedFloat32[i] = float32(v)
                }</span>
        }
        <span class="cov0" title="0">return l.cachedFloat32</span>
}

// DataType returns LabelTypeInt32 for classification
func (l *Int32Labels) DataType() LabelDataType <span class="cov0" title="0">{
        return LabelTypeInt32
}</span>

// Size returns the total number of labels
func (l *Int32Labels) Size() int <span class="cov0" title="0">{
        return len(l.data)
}</span>

// Shape returns a copy of the label tensor shape
func (l *Int32Labels) Shape() []int <span class="cov0" title="0">{
        shapeCopy := make([]int, len(l.shape))
        copy(shapeCopy, l.shape)
        return shapeCopy
}</span>

// UnsafePointer returns pointer to the underlying int32 data
// This enables zero-copy transfer to GPU for classification
func (l *Int32Labels) UnsafePointer() unsafe.Pointer <span class="cov0" title="0">{
        if len(l.data) == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">return unsafe.Pointer(&amp;l.data[0])</span>
}

// Float32Labels wraps []float32 for regression tasks
// Implements LabelData interface with zero overhead
type Float32Labels struct {
        data  []float32
        shape []int
}

// NewFloat32Labels creates regression labels with shape validation
func NewFloat32Labels(data []float32, shape []int) (*Float32Labels, error) <span class="cov0" title="0">{
        if len(shape) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("shape cannot be empty")
        }</span>
        
        <span class="cov0" title="0">expectedSize := 1
        for _, dim := range shape </span><span class="cov0" title="0">{
                if dim &lt;= 0 </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("invalid shape dimension: %d", dim)
                }</span>
                <span class="cov0" title="0">expectedSize *= dim</span>
        }
        
        <span class="cov0" title="0">if len(data) != expectedSize </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("data size %d doesn't match shape %v (expected %d)", 
                        len(data), shape, expectedSize)
        }</span>
        
        // Make a copy of shape to prevent external modifications
        <span class="cov0" title="0">shapeCopy := make([]int, len(shape))
        copy(shapeCopy, shape)
        
        return &amp;Float32Labels{
                data:  data,
                shape: shapeCopy,
        }, nil</span>
}

// ToFloat32Slice returns the underlying float32 slice directly
// ZERO-COST: No allocation, no copying
func (l *Float32Labels) ToFloat32Slice() []float32 <span class="cov0" title="0">{
        return l.data
}</span>

// DataType returns LabelTypeFloat32 for regression
func (l *Float32Labels) DataType() LabelDataType <span class="cov0" title="0">{
        return LabelTypeFloat32
}</span>

// Size returns the total number of labels
func (l *Float32Labels) Size() int <span class="cov0" title="0">{
        return len(l.data)
}</span>

// Shape returns a copy of the label tensor shape
func (l *Float32Labels) Shape() []int <span class="cov0" title="0">{
        shapeCopy := make([]int, len(l.shape))
        copy(shapeCopy, l.shape)
        return shapeCopy
}</span>

// UnsafePointer returns pointer to the underlying float32 data
// This enables zero-copy transfer to GPU for regression
func (l *Float32Labels) UnsafePointer() unsafe.Pointer <span class="cov0" title="0">{
        if len(l.data) == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">return unsafe.Pointer(&amp;l.data[0])</span>
}

// BatchedLabels represents a collection of label batches
// Useful for multi-GPU training or pipeline parallelism
type BatchedLabels struct {
        batches []LabelData
}

// NewBatchedLabels creates a collection of label batches
func NewBatchedLabels(batches []LabelData) (*BatchedLabels, error) <span class="cov0" title="0">{
        if len(batches) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("batches cannot be empty")
        }</span>
        
        // Validate all batches have the same type
        <span class="cov0" title="0">firstType := batches[0].DataType()
        for i, batch := range batches </span><span class="cov0" title="0">{
                if batch.DataType() != firstType </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("batch %d has type %v, expected %v", 
                                i, batch.DataType(), firstType)
                }</span>
        }
        
        <span class="cov0" title="0">return &amp;BatchedLabels{
                batches: batches,
        }, nil</span>
}

// GetBatch returns the label batch at the specified index
func (bl *BatchedLabels) GetBatch(index int) (LabelData, error) <span class="cov0" title="0">{
        if index &lt; 0 || index &gt;= len(bl.batches) </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("batch index %d out of range [0, %d)", index, len(bl.batches))
        }</span>
        <span class="cov0" title="0">return bl.batches[index], nil</span>
}

// NumBatches returns the number of label batches
func (bl *BatchedLabels) NumBatches() int <span class="cov0" title="0">{
        return len(bl.batches)
}</pre>
		
		<pre class="file" id="file2" style="display: none">package training

import (
        "fmt"
        "math"
        "sort"
)

// MetricType represents different evaluation metrics
type MetricType int

const (
        // Binary Classification Metrics
        Precision MetricType = iota
        Recall
        F1Score
        Specificity
        NPV // Negative Predictive Value
        
        // Multi-class Metrics  
        MacroPrecision
        MacroRecall
        MacroF1
        MicroPrecision
        MicroRecall
        MicroF1
        
        // Ranking Metrics
        AUCROC
        AUCPR // Area Under Precision-Recall Curve
        
        // Regression Metrics
        MAE  // Mean Absolute Error
        MSE  // Mean Squared Error
        RMSE // Root Mean Squared Error
        R2   // R-squared
        NMAE // Normalized Mean Absolute Error
)

func (mt MetricType) String() string <span class="cov0" title="0">{
        switch mt </span>{
        case Precision:<span class="cov0" title="0">
                return "Precision"</span>
        case Recall:<span class="cov0" title="0">
                return "Recall"</span>
        case F1Score:<span class="cov0" title="0">
                return "F1Score"</span>
        case Specificity:<span class="cov0" title="0">
                return "Specificity"</span>
        case NPV:<span class="cov0" title="0">
                return "NPV"</span>
        case MacroPrecision:<span class="cov0" title="0">
                return "MacroPrecision"</span>
        case MacroRecall:<span class="cov0" title="0">
                return "MacroRecall"</span>
        case MacroF1:<span class="cov0" title="0">
                return "MacroF1"</span>
        case MicroPrecision:<span class="cov0" title="0">
                return "MicroPrecision"</span>
        case MicroRecall:<span class="cov0" title="0">
                return "MicroRecall"</span>
        case MicroF1:<span class="cov0" title="0">
                return "MicroF1"</span>
        case AUCROC:<span class="cov0" title="0">
                return "AUCROC"</span>
        case AUCPR:<span class="cov0" title="0">
                return "AUCPR"</span>
        case MAE:<span class="cov0" title="0">
                return "MAE"</span>
        case MSE:<span class="cov0" title="0">
                return "MSE"</span>
        case RMSE:<span class="cov0" title="0">
                return "RMSE"</span>
        case R2:<span class="cov0" title="0">
                return "R2"</span>
        case NMAE:<span class="cov0" title="0">
                return "NMAE"</span>
        default:<span class="cov0" title="0">
                return fmt.Sprintf("Unknown(%d)", int(mt))</span>
        }
}

// ConfusionMatrix represents a confusion matrix for classification tasks
// Adheres to GPU-resident architecture: all tensors on GPU, only scalar results on CPU
type ConfusionMatrix struct {
        NumClasses int
        Matrix     [][]int // [true_class][predicted_class]
        TotalSamples int
        
        // Cached metrics to avoid recomputation
        cachedMetrics map[MetricType]float64
        metricsValid  bool
}

// NewConfusionMatrix creates a new confusion matrix
func NewConfusionMatrix(numClasses int) *ConfusionMatrix <span class="cov8" title="1">{
        matrix := make([][]int, numClasses)
        for i := range matrix </span><span class="cov8" title="1">{
                matrix[i] = make([]int, numClasses)
        }</span>
        
        <span class="cov8" title="1">return &amp;ConfusionMatrix{
                NumClasses:    numClasses,
                Matrix:        matrix,
                cachedMetrics: make(map[MetricType]float64),
        }</span>
}

// Reset clears the confusion matrix
func (cm *ConfusionMatrix) Reset() <span class="cov0" title="0">{
        for i := range cm.Matrix </span><span class="cov0" title="0">{
                for j := range cm.Matrix[i] </span><span class="cov0" title="0">{
                        cm.Matrix[i][j] = 0
                }</span>
        }
        <span class="cov0" title="0">cm.TotalSamples = 0
        cm.metricsValid = false
        cm.cachedMetrics = make(map[MetricType]float64)</span>
}

// UpdateFromPredictions updates confusion matrix from GPU-resident predictions
// Maintains design compliance: predictions/labels come from GPU, only scalar updates on CPU
func (cm *ConfusionMatrix) UpdateFromPredictions(
        predictions []float32, // GPU tensor data copied to CPU for scalar extraction
        trueLabels []int32,    // True class labels
        batchSize int,
        numClasses int,
) error <span class="cov0" title="0">{
        // Handle single output binary classification (BCEWithLogits)
        expectedPredictions := batchSize * numClasses
        if cm.NumClasses == 2 &amp;&amp; len(predictions) == batchSize </span><span class="cov0" title="0">{
                // Single output binary classification - convert to 2-class format
                expectedPredictions = batchSize
        }</span>
        
        <span class="cov0" title="0">if len(predictions) != expectedPredictions </span><span class="cov0" title="0">{
                return fmt.Errorf("predictions length mismatch: expected %d, got %d", expectedPredictions, len(predictions))
        }</span>
        
        <span class="cov0" title="0">if len(trueLabels) != batchSize </span><span class="cov0" title="0">{
                return fmt.Errorf("labels length mismatch: expected %d, got %d", batchSize, len(trueLabels))
        }</span>
        
        <span class="cov0" title="0">if numClasses != cm.NumClasses </span><span class="cov0" title="0">{
                return fmt.Errorf("class count mismatch: expected %d, got %d", cm.NumClasses, numClasses)
        }</span>
        
        // CPU-only processing for final scalar metrics (design compliant)
        <span class="cov0" title="0">for i := 0; i &lt; batchSize; i++ </span><span class="cov0" title="0">{
                var predClass int
                
                if cm.NumClasses == 2 &amp;&amp; len(predictions) == batchSize </span><span class="cov0" title="0">{
                        // Single output binary classification (BCEWithLogits)
                        // prediction &gt; 0 means class 1, prediction &lt;= 0 means class 0
                        if predictions[i] &gt; 0 </span><span class="cov0" title="0">{
                                predClass = 1
                        }</span> else<span class="cov0" title="0"> {
                                predClass = 0
                        }</span>
                } else<span class="cov0" title="0"> {
                        // Multi-class classification - find predicted class (argmax)
                        maxIdx := 0
                        maxVal := predictions[i*numClasses]
                        
                        for j := 1; j &lt; numClasses; j++ </span><span class="cov0" title="0">{
                                if predictions[i*numClasses+j] &gt; maxVal </span><span class="cov0" title="0">{
                                        maxVal = predictions[i*numClasses+j]
                                        maxIdx = j
                                }</span>
                        }
                        <span class="cov0" title="0">predClass = maxIdx</span>
                }
                
                <span class="cov0" title="0">trueClass := int(trueLabels[i])
                
                // Validate class indices
                if trueClass &lt; 0 || trueClass &gt;= cm.NumClasses || predClass &lt; 0 || predClass &gt;= cm.NumClasses </span><span class="cov0" title="0">{
                        continue</span> // Skip invalid samples
                }
                
                // Update confusion matrix
                <span class="cov0" title="0">cm.Matrix[trueClass][predClass]++
                cm.TotalSamples++</span>
        }
        
        // Invalidate cached metrics
        <span class="cov0" title="0">cm.metricsValid = false
        return nil</span>
}

// GetMetric calculates and caches evaluation metrics
// Only CPU access for final scalar metrics (GPU-resident architecture compliance)
func (cm *ConfusionMatrix) GetMetric(metric MetricType) float64 <span class="cov0" title="0">{
        if cm.metricsValid </span><span class="cov0" title="0">{
                if value, exists := cm.cachedMetrics[metric]; exists </span><span class="cov0" title="0">{
                        return value
                }</span>
        }
        
        <span class="cov0" title="0">var result float64
        
        switch metric </span>{
        case Precision:<span class="cov0" title="0">
                result = cm.calculateBinaryPrecision()</span>
        case Recall:<span class="cov0" title="0">
                result = cm.calculateBinaryRecall()</span>
        case F1Score:<span class="cov0" title="0">
                result = cm.calculateBinaryF1()</span>
        case Specificity:<span class="cov0" title="0">
                result = cm.calculateSpecificity()</span>
        case NPV:<span class="cov0" title="0">
                result = cm.calculateNPV()</span>
        case MacroPrecision:<span class="cov0" title="0">
                result = cm.calculateMacroPrecision()</span>
        case MacroRecall:<span class="cov0" title="0">
                result = cm.calculateMacroRecall()</span>
        case MacroF1:<span class="cov0" title="0">
                result = cm.calculateMacroF1()</span>
        case MicroPrecision:<span class="cov0" title="0">
                result = cm.calculateMicroPrecision()</span>
        case MicroRecall:<span class="cov0" title="0">
                result = cm.calculateMicroRecall()</span>
        case MicroF1:<span class="cov0" title="0">
                result = cm.calculateMicroF1()</span>
        default:<span class="cov0" title="0">
                return 0.0</span>
        }
        
        // Cache the result
        <span class="cov0" title="0">cm.cachedMetrics[metric] = result
        return result</span>
}

// Binary classification metrics (assuming class 1 is positive)
func (cm *ConfusionMatrix) calculateBinaryPrecision() float64 <span class="cov0" title="0">{
        if cm.NumClasses != 2 </span><span class="cov0" title="0">{
                return 0.0 // Only valid for binary classification
        }</span>
        
        <span class="cov0" title="0">tp := float64(cm.Matrix[1][1]) // True positives
        fp := float64(cm.Matrix[0][1]) // False positives
        
        if tp+fp == 0 </span><span class="cov0" title="0">{
                return 0.0 // No positive predictions
        }</span>
        
        <span class="cov0" title="0">return tp / (tp + fp)</span>
}

func (cm *ConfusionMatrix) calculateBinaryRecall() float64 <span class="cov0" title="0">{
        if cm.NumClasses != 2 </span><span class="cov0" title="0">{
                return 0.0
        }</span>
        
        <span class="cov0" title="0">tp := float64(cm.Matrix[1][1]) // True positives
        fn := float64(cm.Matrix[1][0]) // False negatives
        
        if tp+fn == 0 </span><span class="cov0" title="0">{
                return 0.0 // No actual positives
        }</span>
        
        <span class="cov0" title="0">return tp / (tp + fn)</span>
}

func (cm *ConfusionMatrix) calculateBinaryF1() float64 <span class="cov0" title="0">{
        precision := cm.calculateBinaryPrecision()
        recall := cm.calculateBinaryRecall()
        
        if precision+recall == 0 </span><span class="cov0" title="0">{
                return 0.0
        }</span>
        
        <span class="cov0" title="0">return 2 * (precision * recall) / (precision + recall)</span>
}

func (cm *ConfusionMatrix) calculateSpecificity() float64 <span class="cov0" title="0">{
        if cm.NumClasses != 2 </span><span class="cov0" title="0">{
                return 0.0
        }</span>
        
        <span class="cov0" title="0">tn := float64(cm.Matrix[0][0]) // True negatives
        fp := float64(cm.Matrix[0][1]) // False positives
        
        if tn+fp == 0 </span><span class="cov0" title="0">{
                return 0.0 // No actual negatives
        }</span>
        
        <span class="cov0" title="0">return tn / (tn + fp)</span>
}

func (cm *ConfusionMatrix) calculateNPV() float64 <span class="cov0" title="0">{
        if cm.NumClasses != 2 </span><span class="cov0" title="0">{
                return 0.0
        }</span>
        
        <span class="cov0" title="0">tn := float64(cm.Matrix[0][0]) // True negatives
        fn := float64(cm.Matrix[1][0]) // False negatives
        
        if tn+fn == 0 </span><span class="cov0" title="0">{
                return 0.0 // No negative predictions
        }</span>
        
        <span class="cov0" title="0">return tn / (tn + fn)</span>
}

// Multi-class metrics
func (cm *ConfusionMatrix) calculateMacroPrecision() float64 <span class="cov0" title="0">{
        if cm.NumClasses &lt; 2 </span><span class="cov0" title="0">{
                return 0.0
        }</span>
        
        <span class="cov0" title="0">sum := 0.0
        validClasses := 0
        
        for class := 0; class &lt; cm.NumClasses; class++ </span><span class="cov0" title="0">{
                tp := float64(cm.Matrix[class][class])
                fp := 0.0
                
                // Sum false positives for this class
                for otherClass := 0; otherClass &lt; cm.NumClasses; otherClass++ </span><span class="cov0" title="0">{
                        if otherClass != class </span><span class="cov0" title="0">{
                                fp += float64(cm.Matrix[otherClass][class])
                        }</span>
                }
                
                <span class="cov0" title="0">if tp+fp &gt; 0 </span><span class="cov0" title="0">{
                        sum += tp / (tp + fp)
                        validClasses++
                }</span>
        }
        
        <span class="cov0" title="0">if validClasses == 0 </span><span class="cov0" title="0">{
                return 0.0
        }</span>
        
        <span class="cov0" title="0">return sum / float64(validClasses)</span>
}

func (cm *ConfusionMatrix) calculateMacroRecall() float64 <span class="cov0" title="0">{
        if cm.NumClasses &lt; 2 </span><span class="cov0" title="0">{
                return 0.0
        }</span>
        
        <span class="cov0" title="0">sum := 0.0
        validClasses := 0
        
        for class := 0; class &lt; cm.NumClasses; class++ </span><span class="cov0" title="0">{
                tp := float64(cm.Matrix[class][class])
                fn := 0.0
                
                // Sum false negatives for this class
                for otherClass := 0; otherClass &lt; cm.NumClasses; otherClass++ </span><span class="cov0" title="0">{
                        if otherClass != class </span><span class="cov0" title="0">{
                                fn += float64(cm.Matrix[class][otherClass])
                        }</span>
                }
                
                <span class="cov0" title="0">if tp+fn &gt; 0 </span><span class="cov0" title="0">{
                        sum += tp / (tp + fn)
                        validClasses++
                }</span>
        }
        
        <span class="cov0" title="0">if validClasses == 0 </span><span class="cov0" title="0">{
                return 0.0
        }</span>
        
        <span class="cov0" title="0">return sum / float64(validClasses)</span>
}

func (cm *ConfusionMatrix) calculateMacroF1() float64 <span class="cov0" title="0">{
        precision := cm.calculateMacroPrecision()
        recall := cm.calculateMacroRecall()
        
        if precision+recall == 0 </span><span class="cov0" title="0">{
                return 0.0
        }</span>
        
        <span class="cov0" title="0">return 2 * (precision * recall) / (precision + recall)</span>
}

func (cm *ConfusionMatrix) calculateMicroPrecision() float64 <span class="cov0" title="0">{
        totalTP := 0.0
        totalFP := 0.0
        
        for class := 0; class &lt; cm.NumClasses; class++ </span><span class="cov0" title="0">{
                totalTP += float64(cm.Matrix[class][class])
                
                for otherClass := 0; otherClass &lt; cm.NumClasses; otherClass++ </span><span class="cov0" title="0">{
                        if otherClass != class </span><span class="cov0" title="0">{
                                totalFP += float64(cm.Matrix[otherClass][class])
                        }</span>
                }
        }
        
        <span class="cov0" title="0">if totalTP+totalFP == 0 </span><span class="cov0" title="0">{
                return 0.0
        }</span>
        
        <span class="cov0" title="0">return totalTP / (totalTP + totalFP)</span>
}

func (cm *ConfusionMatrix) calculateMicroRecall() float64 <span class="cov0" title="0">{
        totalTP := 0.0
        totalFN := 0.0
        
        for class := 0; class &lt; cm.NumClasses; class++ </span><span class="cov0" title="0">{
                totalTP += float64(cm.Matrix[class][class])
                
                for otherClass := 0; otherClass &lt; cm.NumClasses; otherClass++ </span><span class="cov0" title="0">{
                        if otherClass != class </span><span class="cov0" title="0">{
                                totalFN += float64(cm.Matrix[class][otherClass])
                        }</span>
                }
        }
        
        <span class="cov0" title="0">if totalTP+totalFN == 0 </span><span class="cov0" title="0">{
                return 0.0
        }</span>
        
        <span class="cov0" title="0">return totalTP / (totalTP + totalFN)</span>
}

func (cm *ConfusionMatrix) calculateMicroF1() float64 <span class="cov0" title="0">{
        precision := cm.calculateMicroPrecision()
        recall := cm.calculateMicroRecall()
        
        if precision+recall == 0 </span><span class="cov0" title="0">{
                return 0.0
        }</span>
        
        <span class="cov0" title="0">return 2 * (precision * recall) / (precision + recall)</span>
}

// GetAccuracy returns overall classification accuracy
func (cm *ConfusionMatrix) GetAccuracy() float64 <span class="cov0" title="0">{
        if cm.TotalSamples == 0 </span><span class="cov0" title="0">{
                return 0.0
        }</span>
        
        <span class="cov0" title="0">correct := 0
        for i := 0; i &lt; cm.NumClasses; i++ </span><span class="cov0" title="0">{
                correct += cm.Matrix[i][i]
        }</span>
        
        <span class="cov0" title="0">return float64(correct) / float64(cm.TotalSamples)</span>
}

// ROCPoint represents a point on the ROC curve
type ROCPoint struct {
        Threshold float32
        TPR       float64 // True Positive Rate (Recall)
        FPR       float64 // False Positive Rate (1 - Specificity)
}

// CalculateAUCROC calculates Area Under ROC Curve for binary classification
// GPU-resident architecture: operates on GPU tensor data, returns CPU scalar
func CalculateAUCROC(
        predictions []float32, // Raw prediction scores from GPU tensor
        trueLabels []int32,    // Binary labels (0 or 1)
        batchSize int,
) float64 <span class="cov0" title="0">{
        if len(predictions) != batchSize || len(trueLabels) != batchSize </span><span class="cov0" title="0">{
                return 0.0
        }</span>
        
        // Create prediction-label pairs for sorting
        <span class="cov0" title="0">type predLabel struct {
                score float32
                label int32
        }
        
        pairs := make([]predLabel, batchSize)
        for i := 0; i &lt; batchSize; i++ </span><span class="cov0" title="0">{
                pairs[i] = predLabel{score: predictions[i], label: trueLabels[i]}
        }</span>
        
        // Sort by prediction score (descending)
        <span class="cov0" title="0">sort.Slice(pairs, func(i, j int) bool </span><span class="cov0" title="0">{
                return pairs[i].score &gt; pairs[j].score
        }</span>)
        
        // Count total positives and negatives
        <span class="cov0" title="0">totalPos := 0
        totalNeg := 0
        for _, pair := range pairs </span><span class="cov0" title="0">{
                if pair.label == 1 </span><span class="cov0" title="0">{
                        totalPos++
                }</span> else<span class="cov0" title="0"> {
                        totalNeg++
                }</span>
        }
        
        <span class="cov0" title="0">if totalPos == 0 || totalNeg == 0 </span><span class="cov0" title="0">{
                return 0.0 // Cannot calculate AUC without both classes
        }</span>
        
        // Calculate AUC using trapezoidal rule
        <span class="cov0" title="0">auc := 0.0
        tp := 0
        fp := 0
        prevTPR := 0.0
        prevFPR := 0.0
        
        for _, pair := range pairs </span><span class="cov0" title="0">{
                if pair.label == 1 </span><span class="cov0" title="0">{
                        tp++
                }</span> else<span class="cov0" title="0"> {
                        fp++
                }</span>
                
                <span class="cov0" title="0">tpr := float64(tp) / float64(totalPos)
                fpr := float64(fp) / float64(totalNeg)
                
                // Add trapezoid area
                auc += (fpr - prevFPR) * (tpr + prevTPR) / 2.0
                
                prevTPR = tpr
                prevFPR = fpr</span>
        }
        
        <span class="cov0" title="0">return auc</span>
}

// RegressionMetrics holds comprehensive regression evaluation metrics
type RegressionMetrics struct {
        MAE  float64 // Mean Absolute Error
        MSE  float64 // Mean Squared Error
        RMSE float64 // Root Mean Squared Error
        R2   float64 // R-squared
        NMAE float64 // Normalized Mean Absolute Error
}

// CalculateRegressionMetrics computes comprehensive regression metrics
// GPU-resident architecture: operates on GPU tensor data, returns CPU scalars
func CalculateRegressionMetrics(
        predictions []float32,
        trueValues []float32,
        batchSize int,
) *RegressionMetrics <span class="cov0" title="0">{
        if len(predictions) &lt; batchSize || len(trueValues) &lt; batchSize </span><span class="cov0" title="0">{
                return &amp;RegressionMetrics{}
        }</span>
        
        // Calculate mean of true values for R²
        <span class="cov0" title="0">meanTrue := 0.0
        for i := 0; i &lt; batchSize; i++ </span><span class="cov0" title="0">{
                meanTrue += float64(trueValues[i])
        }</span>
        <span class="cov0" title="0">meanTrue /= float64(batchSize)
        
        // Calculate metrics
        sumAbsErr := 0.0
        sumSqErr := 0.0
        sumSqTotal := 0.0
        minTrue := math.Inf(1)
        maxTrue := math.Inf(-1)
        
        for i := 0; i &lt; batchSize; i++ </span><span class="cov0" title="0">{
                pred := float64(predictions[i])
                true := float64(trueValues[i])
                
                absErr := math.Abs(pred - true)
                sqErr := (pred - true) * (pred - true)
                
                sumAbsErr += absErr
                sumSqErr += sqErr
                sumSqTotal += (true - meanTrue) * (true - meanTrue)
                
                if true &lt; minTrue </span><span class="cov0" title="0">{
                        minTrue = true
                }</span>
                <span class="cov0" title="0">if true &gt; maxTrue </span><span class="cov0" title="0">{
                        maxTrue = true
                }</span>
        }
        
        <span class="cov0" title="0">mae := sumAbsErr / float64(batchSize)
        mse := sumSqErr / float64(batchSize)
        rmse := math.Sqrt(mse)
        
        // R² calculation
        r2 := 0.0
        if sumSqTotal &gt; 0 </span><span class="cov0" title="0">{
                r2 = 1.0 - (sumSqErr / sumSqTotal)
        }</span>
        
        // Normalized MAE (scale by range)
        <span class="cov0" title="0">nmae := 0.0
        if maxTrue &gt; minTrue </span><span class="cov0" title="0">{
                nmae = mae / (maxTrue - minTrue)
        }</span>
        
        <span class="cov0" title="0">return &amp;RegressionMetrics{
                MAE:  mae,
                MSE:  mse,
                RMSE: rmse,
                R2:   r2,
                NMAE: nmae,
        }</span>
}</pre>
		
		<pre class="file" id="file3" style="display: none">package training

import (
        "fmt"

        "github.com/tsawler/go-metal/cgo_bridge"
        "github.com/tsawler/go-metal/checkpoints"
        "github.com/tsawler/go-metal/engine"
        "github.com/tsawler/go-metal/layers"
        "github.com/tsawler/go-metal/memory"
)

// ModelInferencer provides inference-only functionality using dedicated InferenceEngine
// Optimized for forward-pass only without training overhead
type ModelInferencer struct {
        inferenceEngine *engine.ModelInferenceEngine
        modelSpec       *layers.ModelSpec
        batchSize       int
        config          InferencerConfig
}

// InferencerConfig holds configuration for inference-only operations
type InferencerConfig struct {
        // Performance settings
        BatchSize            int  `json:"batch_size"`             // Target batch size for inference
        UseDynamicEngine     bool `json:"use_dynamic_engine"`     // Use dynamic graph (recommended: true)
        OptimizeForSingleBatch bool `json:"optimize_single_batch"` // Optimize for batch size 1
        UseCommandPooling    bool `json:"use_command_pooling"`    // Enable command buffer pooling
        
        // Batch normalization mode
        BatchNormInferenceMode bool `json:"batchnorm_inference_mode"` // Use running stats for batch norm
}

// NewModelInferencer creates a new inference-only engine
func NewModelInferencer(
        modelSpec *layers.ModelSpec,
        config InferencerConfig,
) (*ModelInferencer, error) <span class="cov0" title="0">{
        // Validate configuration
        if err := validateInferencerConfig(config); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("invalid inferencer configuration: %v", err)
        }</span>
        
        // Convert to inference engine config
        <span class="cov0" title="0">inferenceConfig := cgo_bridge.InferenceConfig{
                UseDynamicEngine:       config.UseDynamicEngine,
                BatchNormInferenceMode: config.BatchNormInferenceMode,
                UseCommandPooling:      config.UseCommandPooling,
                OptimizeForSingleBatch: config.OptimizeForSingleBatch,
        }
        
        // Set input shape
        if len(modelSpec.InputShape) &gt; 0 </span><span class="cov0" title="0">{
                inferenceConfig.InputShape = make([]int32, len(modelSpec.InputShape))
                for i, dim := range modelSpec.InputShape </span><span class="cov0" title="0">{
                        inferenceConfig.InputShape[i] = int32(dim)
                }</span>
                <span class="cov0" title="0">inferenceConfig.InputShapeLen = int32(len(modelSpec.InputShape))</span>
        }
        
        // Create inference engine
        <span class="cov0" title="0">inferenceEngine, err := engine.NewModelInferenceEngine(modelSpec, inferenceConfig)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create inference engine: %v", err)
        }</span>
        
        <span class="cov0" title="0">return &amp;ModelInferencer{
                inferenceEngine: inferenceEngine,
                modelSpec:       modelSpec,
                batchSize:       config.BatchSize,
                config:          config,
        }, nil</span>
}

// Cleanup performs deterministic resource cleanup
func (mi *ModelInferencer) Cleanup() <span class="cov0" title="0">{
        if mi.inferenceEngine != nil </span><span class="cov0" title="0">{
                mi.inferenceEngine.Cleanup()
                mi.inferenceEngine = nil
        }</span>
}

// LoadWeights loads pre-trained weights into the inference engine
func (mi *ModelInferencer) LoadWeights(weights []checkpoints.WeightTensor) error <span class="cov0" title="0">{
        if mi.inferenceEngine == nil </span><span class="cov0" title="0">{
                return fmt.Errorf("inference engine not initialized")
        }</span>
        
        <span class="cov0" title="0">return mi.inferenceEngine.LoadWeights(weights)</span>
}

// LoadWeightsFromCheckpoint loads weights from a checkpoint
func (mi *ModelInferencer) LoadWeightsFromCheckpoint(weights []checkpoints.WeightTensor) error <span class="cov0" title="0">{
        if mi.inferenceEngine == nil </span><span class="cov0" title="0">{
                return fmt.Errorf("inference engine not initialized")
        }</span>
        
        // Convert checkpoint weights to checkpoints.WeightTensor format
        // (already in the correct format)
        <span class="cov0" title="0">memoryWeights := weights
        
        return mi.inferenceEngine.LoadWeights(memoryWeights)</span>
}

// Predict performs single forward pass for inference
// This is the lightweight method optimized for single-image or small batch inference
func (mi *ModelInferencer) Predict(
        inputData []float32,
        inputShape []int,
) (*cgo_bridge.InferenceResult, error) <span class="cov0" title="0">{
        if mi.inferenceEngine == nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("inference engine not initialized")
        }</span>
        
        // Use the inference engine's optimized predict method
        <span class="cov0" title="0">return mi.inferenceEngine.Predict(inputData, inputShape)</span>
}

// PredictBatch performs inference on a batch of data
// Optimized for larger batches with efficient GPU utilization
func (mi *ModelInferencer) PredictBatch(
        inputData []float32,
        inputShape []int,
) (*cgo_bridge.InferenceResult, error) <span class="cov0" title="0">{
        // For now, use the same predict method
        // In a full implementation, this could have batch-specific optimizations
        return mi.Predict(inputData, inputShape)
}</span>

// GetModelSpec returns the model specification
func (mi *ModelInferencer) GetModelSpec() *layers.ModelSpec <span class="cov0" title="0">{
        return mi.modelSpec
}</span>

// GetParameterTensors returns the GPU-resident parameter tensors
func (mi *ModelInferencer) GetParameterTensors() []*memory.Tensor <span class="cov0" title="0">{
        if mi.inferenceEngine == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">return mi.inferenceEngine.GetParameterTensors()</span>
}

// validateInferencerConfig validates the inferencer configuration
func validateInferencerConfig(config InferencerConfig) error <span class="cov0" title="0">{
        if config.BatchSize &lt;= 0 </span><span class="cov0" title="0">{
                return fmt.Errorf("batch size must be positive, got %d", config.BatchSize)
        }</span>
        
        <span class="cov0" title="0">if config.BatchSize &gt; 1024 </span><span class="cov0" title="0">{
                return fmt.Errorf("batch size too large, got %d (max: 1024)", config.BatchSize)
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// DefaultInferencerConfig returns a sensible default configuration for inference
func DefaultInferencerConfig() InferencerConfig <span class="cov0" title="0">{
        return InferencerConfig{
                BatchSize:              1,    // Single image inference by default
                UseDynamicEngine:       true, // Use dynamic engine for flexibility
                OptimizeForSingleBatch: true, // Optimize for single image inference
                UseCommandPooling:      true, // Enable command buffer pooling for performance
                BatchNormInferenceMode: true, // Use running stats for batch normalization
        }
}</span>

// Note: Using checkpoints.WeightTensor directly to avoid type conflicts</pre>
		
		<pre class="file" id="file4" style="display: none">package training

import (
        "fmt"
        "math"
        "sort"
        "time"
        "unsafe"

        "github.com/tsawler/go-metal/async"
        "github.com/tsawler/go-metal/cgo_bridge"
        "github.com/tsawler/go-metal/engine"
        "github.com/tsawler/go-metal/layers"
        "github.com/tsawler/go-metal/memory"
)

// ModelTrainer provides layer-based training while maintaining the proven single-CGO-call architecture
// This is the compliant implementation that integrates with the existing high-performance TrainingEngine
type ModelTrainer struct {
        modelEngine *engine.ModelTrainingEngine
        modelSpec   *layers.ModelSpec
        batchSize   int
        config      cgo_bridge.TrainingConfig
        trainerConfig TrainerConfig  // High-level config for type checking
        currentStep int
        
        // Performance tracking
        lastStepTime    time.Duration
        totalSteps      int64
        totalLoss       float64
        averageLoss     float32
        
        // MEMORY LEAK FIX: Reuse slices to avoid allocations
        oneHotBuffer []float32
        
        // PERFORMANCE OPTIMIZATION: Persistent GPU tensors to reduce allocation overhead
        // These tensors are pre-allocated once and reused across training steps
        persistentInputTensor   *memory.Tensor
        persistentLabelTensor   *memory.Tensor
        persistentGradientTensors []*memory.Tensor  // CRITICAL: Pre-allocate gradient tensors
        persistentEnabled       bool
        
        // PERFORMANCE OPTIMIZATION: Configurable inference frequency to reduce CGO overhead
        // Instead of calculating accuracy every step, do it every N steps
        accuracyCheckInterval  int     // Calculate accuracy every N steps (0 = every step)
        lastAccuracy          float64 // Last calculated accuracy value
        accuracyStepCounter   int     // Counter for accuracy calculation
        
        // RESOURCE LEAK FIX: Command buffer pooling to prevent Metal resource accumulation
        // This addresses the 34% performance degradation from MTLCommandBuffer and MPSImage accumulation
        commandBufferPool  *async.CommandBufferPool
        commandQueue       unsafe.Pointer  // MTLCommandQueue for command buffer creation
        
        // Learning Rate Scheduling - maintains GPU-resident principles
        lrScheduler      LRScheduler // Optional learning rate scheduler
        baseLearningRate float32     // Original learning rate from config
        currentEpoch     int         // Current epoch for scheduler
        
        // Evaluation Metrics - GPU-resident architecture compliance
        confusionMatrix     *ConfusionMatrix // Confusion matrix for classification metrics
        metricsEnabled      bool             // Whether to calculate comprehensive metrics
        lastRegressionMetrics *RegressionMetrics // Last calculated regression metrics
        metricHistory       map[MetricType][]float64 // History of metrics for plotting
        
        // Visualization &amp; Plotting - follows GPU-resident architecture
        visualizationCollector *VisualizationCollector // Collects data for plotting
        plottingService        *PlottingService        // Service for sending plots to sidecar
        visualizationEnabled   bool                    // Whether visualization is enabled
        
        // Probability collection for proper PR/ROC curves - GPU-resident compliant
        // These are only populated during validation when visualization is enabled
        validationProbabilities []float32  // Concatenated probabilities from all validation batches
        validationLabels       []int32    // Corresponding true labels
        maxProbabilityBatches  int        // Maximum number of batches to collect (to limit memory)
        probabilityBatchCount  int        // Current number of collected batches
        
        // Mixed Precision Training State
        useMixedPrecision     bool                    // Whether mixed precision is enabled
        lossScale             float32                 // Current loss scale
        lossScaleGrowthFactor float32                 // Loss scale growth factor
        lossScaleBackoffFactor float32                // Loss scale reduction factor
        lossScaleGrowthInterval int                   // Steps between growth attempts
        stepsSinceLastScale   int                     // Steps since last scale change
        fp16WeightTensors     []*memory.Tensor        // FP16 versions of weights
        fp16GradientTensors   []*memory.Tensor        // FP16 gradient tensors
}

// NewModelTrainer creates a new model-based trainer using the existing TrainingEngine architecture
func NewModelTrainer(
        modelSpec *layers.ModelSpec,
        config TrainerConfig,
) (*ModelTrainer, error) <span class="cov8" title="1">{
        // Validate configuration
        if err := validateTrainerConfig(config); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("invalid trainer configuration: %v", err)
        }</span>
        
        // Convert to CGO bridge config
        <span class="cov8" title="1">bridgeConfig := cgo_bridge.TrainingConfig{
                LearningRate:  config.LearningRate,
                Beta1:         config.Beta1,
                Beta2:         config.Beta2,
                WeightDecay:   config.WeightDecay,
                Epsilon:       config.Epsilon,
                Alpha:         config.Alpha,
                Momentum:      config.Momentum,
                Centered:      config.Centered,
                OptimizerType: config.OptimizerType,
                ProblemType:   int(config.ProblemType),
                LossFunction:  int(config.LossFunction),
        }
        
        // SMART ROUTING: Select optimal engine based on model architecture
        // Maintains GPU-resident architecture compliance across all engine types
        var modelEngine *engine.ModelTrainingEngine
        var err error
        
        // Determine optimal engine type using smart routing
        selectedEngine := SelectOptimalEngine(modelSpec, config)
        archInfo := AnalyzeModelArchitecture(modelSpec)
        
        fmt.Printf("🧠 Smart Routing Analysis:\n")
        fmt.Printf("   - Input: %dD %v\n", archInfo.InputDimensions, modelSpec.InputShape)
        fmt.Printf("   - Architecture: %s (%d layers, %d params)\n", 
                archInfo.Complexity, archInfo.LayerCount, archInfo.ParameterCount)
        fmt.Printf("   - Pattern: CNN=%v, MLP=%v\n", archInfo.IsCNNPattern, archInfo.IsMLPOnly)
        fmt.Printf("   - Selected Engine: %s\n", selectedEngine.String())
        
        // Create engine based on smart routing decision
        switch selectedEngine </span>{
        case Dynamic:<span class="cov0" title="0">
                // Dynamic Engine: Maximum flexibility for any architecture
                // - Supports 2D, 4D, or any dimensional input
                // - Supports any layer combination (Dense, Conv2D, etc.)
                // - MPSGraph-centric architecture with automatic kernel fusion
                fmt.Printf("🔧 Creating Dynamic Engine (any architecture support)\n")
                modelEngine, err = engine.NewModelTrainingEngineDynamic(modelSpec, bridgeConfig)</span>
                
        case Hybrid:<span class="cov8" title="1">
                // Hybrid Engine: Maximum performance for CNN architectures
                // - Optimized for 4D input [batch, channels, height, width]
                // - MPS for convolutions + MPSGraph for dense layers
                // - Achieves 20k+ batches/second performance
                fmt.Printf("🚀 Creating Hybrid Engine (CNN optimization)\n")
                
                // Route to appropriate hybrid engine based on optimizer
                if config.OptimizerType == cgo_bridge.Adam </span><span class="cov0" title="0">{
                        adamConfig := map[string]interface{}{
                                "learning_rate": config.LearningRate,
                                "beta1":         config.Beta1,
                                "beta2":         config.Beta2,
                                "epsilon":       config.Epsilon,
                                "weight_decay":  config.WeightDecay,
                        }
                        modelEngine, err = engine.NewModelTrainingEngineWithAdam(modelSpec, bridgeConfig, adamConfig)
                }</span> else<span class="cov8" title="1"> if config.OptimizerType == cgo_bridge.LBFGS </span><span class="cov0" title="0">{
                        // L-BFGS requires dynamic engine due to its complexity
                        fmt.Printf("📊 L-BFGS optimizer detected, switching to Dynamic Engine\n")
                        modelEngine, err = engine.NewModelTrainingEngineDynamic(modelSpec, bridgeConfig)
                }</span> else<span class="cov8" title="1"> {
                        // SGD or RMSProp with hybrid engine
                        modelEngine, err = engine.NewModelTrainingEngine(modelSpec, bridgeConfig)
                }</span>
                
                // SMART FALLBACK: If Hybrid Engine fails due to architecture constraints,
                // automatically fall back to Dynamic Engine for flexible architecture support
                <span class="cov8" title="1">if err != nil &amp;&amp; (selectedEngine == Hybrid) </span><span class="cov8" title="1">{
                        fmt.Printf("⚠️  Hybrid Engine incompatible with model architecture, falling back to Dynamic Engine\n")
                        fmt.Printf("    Error: %v\n", err)
                        modelEngine, err = engine.NewModelTrainingEngineDynamic(modelSpec, bridgeConfig)
                        if err == nil </span><span class="cov8" title="1">{
                                fmt.Printf("✅ Successfully created Dynamic Engine as fallback\n")
                        }</span>
                }
                
        default:<span class="cov0" title="0">
                // Fallback to dynamic engine for unknown types
                fmt.Printf("⚠️  Unknown engine type, falling back to Dynamic Engine\n")
                modelEngine, err = engine.NewModelTrainingEngineDynamic(modelSpec, bridgeConfig)</span>
        }
        
        <span class="cov8" title="1">if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create model training engine: %v", err)
        }</span>
        
        // Debug: Show which engine type was actually created
        <span class="cov8" title="1">fmt.Printf("✅ Created engine: isDynamic=%t\n", modelEngine.IsDynamicEngine())
        
        // RESOURCE LEAK FIX: Initialize command buffer pool for Metal resource management
        // This prevents MTLCommandBuffer and MPSImage accumulation that causes 34% performance degradation
        device := modelEngine.GetDevice()
        commandQueue, err := cgo_bridge.CreateCommandQueue(device)
        if err != nil </span><span class="cov0" title="0">{
                modelEngine.Cleanup()
                return nil, fmt.Errorf("failed to create command queue: %v", err)
        }</span>
        
        // Create command buffer pool with reasonable pool size (16 buffers should handle most workloads)
        <span class="cov8" title="1">commandBufferPool, err := async.NewCommandBufferPool(commandQueue, 16)
        if err != nil </span><span class="cov0" title="0">{
                cgo_bridge.ReleaseCommandQueue(commandQueue)
                modelEngine.Cleanup()
                return nil, fmt.Errorf("failed to create command buffer pool: %v", err)
        }</span>
        
        <span class="cov8" title="1">trainer := &amp;ModelTrainer{
                modelEngine: modelEngine,
                modelSpec:   modelSpec,
                batchSize:   config.BatchSize,
                config:      bridgeConfig,
                trainerConfig: config,
                currentStep: 0,
                
                // Default: calculate accuracy every step (traditional behavior)
                accuracyCheckInterval: 0,
                lastAccuracy:         0.0,
                accuracyStepCounter:  0,
                
                // RESOURCE LEAK FIX: Store command buffer pool and queue for resource management
                commandBufferPool: commandBufferPool,
                commandQueue:      commandQueue,
                
                // Learning rate scheduling initialization
                baseLearningRate: config.LearningRate,
                currentEpoch:     0,
                lrScheduler:      nil, // No scheduler by default (constant LR)
                
                // Evaluation metrics initialization - GPU-resident architecture compliance
                confusionMatrix:       NewConfusionMatrix(getNumClassesForMetrics(modelSpec, config)),
                metricsEnabled:        false, // Disabled by default for performance
                lastRegressionMetrics: &amp;RegressionMetrics{},
                metricHistory:         make(map[MetricType][]float64),
                
                // Visualization initialization - GPU-resident architecture compliance
                visualizationCollector: NewVisualizationCollector("Model"),
                plottingService:        NewPlottingService(DefaultPlottingServiceConfig()),
                visualizationEnabled:   false, // Disabled by default for performance
                
                // Probability collection initialization
                maxProbabilityBatches: 50, // Limit to 50 batches to control memory usage
                probabilityBatchCount: 0,
                
                // Mixed Precision Training initialization
                useMixedPrecision:     config.UseMixedPrecision,
                lossScale:             config.InitialLossScale,
                lossScaleGrowthFactor: config.LossScaleGrowthFactor,
                lossScaleBackoffFactor: config.LossScaleBackoffFactor,
                lossScaleGrowthInterval: config.LossScaleGrowthInterval,
                stepsSinceLastScale:   0,
        }
        
        // Initialize default values for mixed precision if not specified
        if trainer.useMixedPrecision </span><span class="cov0" title="0">{
                if trainer.lossScale == 0 </span><span class="cov0" title="0">{
                        trainer.lossScale = 65536.0 // Default initial loss scale
                }</span>
                <span class="cov0" title="0">if trainer.lossScaleGrowthFactor == 0 </span><span class="cov0" title="0">{
                        trainer.lossScaleGrowthFactor = 2.0
                }</span>
                <span class="cov0" title="0">if trainer.lossScaleBackoffFactor == 0 </span><span class="cov0" title="0">{
                        trainer.lossScaleBackoffFactor = 0.5
                }</span>
                <span class="cov0" title="0">if trainer.lossScaleGrowthInterval == 0 </span><span class="cov0" title="0">{
                        trainer.lossScaleGrowthInterval = 2000
                }</span>
                
                // Initialize FP16 weight tensors
                <span class="cov0" title="0">err = trainer.initializeMixedPrecisionTensors()
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to initialize mixed precision tensors: %v", err)
                }</span>
        }
        
        <span class="cov8" title="1">return trainer, nil</span>
}

// initializeMixedPrecisionTensors creates FP16 versions of weights and gradient tensors
func (mt *ModelTrainer) initializeMixedPrecisionTensors() error <span class="cov0" title="0">{
        // Get the number of parameters from the model
        numParams := 0
        for _, layer := range mt.modelSpec.Layers </span><span class="cov0" title="0">{
                if layer.Type == layers.Dense || layer.Type == layers.Conv2D || layer.Type == layers.BatchNorm </span><span class="cov0" title="0">{
                        // Each layer can have weights and biases
                        numParams += 2
                }</span>
        }
        
        // Pre-allocate FP16 tensors for weights and gradients
        <span class="cov0" title="0">mt.fp16WeightTensors = make([]*memory.Tensor, 0, numParams)
        mt.fp16GradientTensors = make([]*memory.Tensor, 0, numParams)
        
        // Note: Actual tensor creation will happen during training when we have the weight shapes
        return nil</span>
}

// convertWeightsToFP16 converts FP32 weights to FP16 for mixed precision training
func (mt *ModelTrainer) convertWeightsToFP16(fp32Weights []*memory.Tensor) error <span class="cov0" title="0">{
        // Ensure we have enough FP16 tensors
        for i := len(mt.fp16WeightTensors); i &lt; len(fp32Weights); i++ </span><span class="cov0" title="0">{
                fp32Weight := fp32Weights[i]
                fp16Weight, err := fp32Weight.ConvertTo(memory.Float16)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to convert weight %d to FP16: %v", i, err)
                }</span>
                <span class="cov0" title="0">mt.fp16WeightTensors = append(mt.fp16WeightTensors, fp16Weight)
                
                // Also create FP16 gradient tensor with same shape
                fp16Gradient, err := memory.NewTensor(fp32Weight.Shape(), memory.Float16, memory.GPU)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to create FP16 gradient tensor %d: %v", i, err)
                }</span>
                <span class="cov0" title="0">mt.fp16GradientTensors = append(mt.fp16GradientTensors, fp16Gradient)</span>
        }
        
        // Update existing FP16 weights with current FP32 values
        <span class="cov0" title="0">for i := 0; i &lt; len(fp32Weights) &amp;&amp; i &lt; len(mt.fp16WeightTensors); i++ </span><span class="cov0" title="0">{
                // Release old FP16 weight
                mt.fp16WeightTensors[i].Release()
                
                // Convert current FP32 weight to FP16
                fp16Weight, err := fp32Weights[i].ConvertTo(memory.Float16)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to update FP16 weight %d: %v", i, err)
                }</span>
                <span class="cov0" title="0">mt.fp16WeightTensors[i] = fp16Weight</span>
        }
        
        <span class="cov0" title="0">return nil</span>
}

// updateFP32WeightsFromFP16 updates FP32 master weights from FP16 weights after optimization
func (mt *ModelTrainer) updateFP32WeightsFromFP16(fp32Weights []*memory.Tensor) error <span class="cov0" title="0">{
        for i := 0; i &lt; len(fp32Weights) &amp;&amp; i &lt; len(mt.fp16WeightTensors); i++ </span><span class="cov0" title="0">{
                // Convert FP16 weight back to FP32
                updatedFP32, err := mt.fp16WeightTensors[i].ConvertTo(memory.Float32)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to convert FP16 weight %d back to FP32: %v", i, err)
                }</span>
                <span class="cov0" title="0">defer updatedFP32.Release()</span>
                
                // Copy the data to the original FP32 weight tensor
                // This requires a memory copy operation
                // For now, we'll need to implement a tensor copy function
                // TODO: Implement tensor copy function in memory package
        }
        
        <span class="cov0" title="0">return nil</span>
}

// getModelOutputSize extracts the output size from model specification
// Used for initializing confusion matrix with correct dimensions
func getModelOutputSize(modelSpec *layers.ModelSpec) int <span class="cov8" title="1">{
        if modelSpec == nil || len(modelSpec.Layers) == 0 </span><span class="cov0" title="0">{
                return 2 // Default to binary classification
        }</span>
        
        // Find the last Dense layer to get output size
        <span class="cov8" title="1">for i := len(modelSpec.Layers) - 1; i &gt;= 0; i-- </span><span class="cov8" title="1">{
                layer := modelSpec.Layers[i]
                if layer.Type == layers.Dense </span><span class="cov8" title="1">{
                        if outputSize, ok := layer.Parameters["output_size"].(int); ok </span><span class="cov8" title="1">{
                                return outputSize
                        }</span>
                }
        }
        
        // Default to 2 classes if not found
        <span class="cov0" title="0">return 2</span>
}

// getNumClassesForMetrics determines the number of classes for confusion matrix
// For binary classification with single output (BCEWithLogits), we need 2 classes
func getNumClassesForMetrics(modelSpec *layers.ModelSpec, config TrainerConfig) int <span class="cov8" title="1">{
        outputSize := getModelOutputSize(modelSpec)
        
        // For classification problems
        if config.ProblemType == Classification </span><span class="cov8" title="1">{
                // Single output usually means binary classification with 2 classes
                if outputSize == 1 </span><span class="cov0" title="0">{
                        return 2
                }</span>
                // Multiple outputs mean multi-class classification
                <span class="cov8" title="1">return outputSize</span>
        }
        
        // For regression, we don't use confusion matrix, but return 2 as safe default
        <span class="cov0" title="0">return 2</span>
}

// TrainBatch executes a single training step on a batch of data
// This maintains the single-CGO-call principle while supporting flexible layer models
func (mt *ModelTrainer) TrainBatch(
        inputData []float32,
        inputShape []int,
        labelData []int32,
        labelShape []int,
) (*TrainingResult, error) <span class="cov0" title="0">{
        start := time.Now()
        defer func() </span><span class="cov0" title="0">{
                mt.lastStepTime = time.Since(start)
        }</span>()
        
        // Create input tensor and copy data to GPU
        <span class="cov0" title="0">inputTensor, err := memory.NewTensor(inputShape, memory.Float32, memory.GPU)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create input tensor: %v", err)
        }</span>
        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                inputTensor.Release()
                // DEBUG: Log tensor lifecycle
                if mt.currentStep%50 == 0 </span>{<span class="cov0" title="0">
                        // Released input tensor
                }</span>
        }()
        
        <span class="cov0" title="0">err = cgo_bridge.CopyFloat32ArrayToMetalBuffer(inputTensor.MetalBuffer(), inputData)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to copy input data to GPU: %v", err)
        }</span>
        
        // Create label tensor (one-hot encoded for loss computation)
        <span class="cov0" title="0">oneHotShape := []int{labelShape[0], mt.getOutputSize()}
        labelTensor, err := memory.NewTensor(oneHotShape, memory.Float32, memory.GPU)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create label tensor: %v", err)
        }</span>
        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                labelTensor.Release()
                // DEBUG: Log tensor lifecycle
                if mt.currentStep%50 == 0 </span>{<span class="cov0" title="0">
                        // Released label tensor
                }</span>
        }()
        
        // Convert labels to one-hot format
        <span class="cov0" title="0">oneHotData := mt.labelsToOneHot(labelData, oneHotShape)
        err = cgo_bridge.CopyFloat32ArrayToMetalBuffer(labelTensor.MetalBuffer(), oneHotData)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to copy label data to GPU: %v", err)
        }</span>
        
        // Memory pool stats available if needed
        <span class="cov0" title="0">if mt.currentStep%100 == 0 </span>{<span class="cov0" title="0"> // Reduced frequency
                // Pool stats can be logged here if debugging memory issues
        }</span>
        
        // Execute training step using the appropriate optimizer
        <span class="cov0" title="0">var loss float32
        if mt.config.OptimizerType == cgo_bridge.Adam </span><span class="cov0" title="0">{
                loss, err = mt.modelEngine.ExecuteModelTrainingStepWithAdam(inputTensor, labelTensor)
        }</span> else<span class="cov0" title="0"> if mt.config.OptimizerType == cgo_bridge.LBFGS </span><span class="cov0" title="0">{
                loss, err = mt.modelEngine.ExecuteModelTrainingStepWithLBFGS(inputTensor, labelTensor)
        }</span> else<span class="cov0" title="0"> {
                loss, err = mt.modelEngine.ExecuteModelTrainingStep(inputTensor, labelTensor, mt.config.LearningRate)
        }</span>
        
        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("model training step failed: %v", err)
        }</span>
        
        // Update statistics
        <span class="cov0" title="0">mt.currentStep++
        mt.totalSteps++
        mt.totalLoss += float64(loss)
        mt.averageLoss = float32(mt.totalLoss / float64(mt.totalSteps))
        
        return &amp;TrainingResult{
                Loss:      loss,
                BatchSize: mt.batchSize,
                StepTime:  mt.lastStepTime,
                Success:   true,
                BatchRate: float64(mt.batchSize) / mt.lastStepTime.Seconds(),
        }, nil</span>
}

// labelsToOneHot converts integer labels to one-hot encoded format
// MEMORY LEAK FIX: Reuses internal buffer to avoid allocations
func (mt *ModelTrainer) labelsToOneHot(labels []int32, oneHotShape []int) []float32 <span class="cov0" title="0">{
        batchSize := oneHotShape[0]
        numClasses := oneHotShape[1]
        requiredSize := batchSize * numClasses
        
        // MEMORY LEAK FIX: Reuse buffer if possible, only allocate if needed
        if len(mt.oneHotBuffer) &lt; requiredSize </span><span class="cov0" title="0">{
                mt.oneHotBuffer = make([]float32, requiredSize)
        }</span>
        <span class="cov0" title="0">oneHot := mt.oneHotBuffer[:requiredSize]
        
        for i, label := range labels </span><span class="cov0" title="0">{
                if i &gt;= batchSize </span><span class="cov0" title="0">{
                        break</span>
                }
                
                // Zero out the row
                <span class="cov0" title="0">baseIdx := i * numClasses
                for j := 0; j &lt; numClasses; j++ </span><span class="cov0" title="0">{
                        oneHot[baseIdx+j] = 0.0
                }</span>
                
                // Set the correct class to 1.0
                <span class="cov0" title="0">if int(label) &lt; numClasses </span><span class="cov0" title="0">{
                        oneHot[baseIdx+int(label)] = 1.0
                }</span>
        }
        
        <span class="cov0" title="0">return oneHot</span>
}

// TrainBatchOptimized executes a training step with batched CGO operations
// This reduces CGO overhead by combining multiple operations into a single call
// Follows design principle: "Single CGO call per training step"
func (mt *ModelTrainer) TrainBatchOptimized(
        inputData []float32,
        inputShape []int,
        labelData []int32,
        labelShape []int,
) (*TrainingResultOptimized, error) <span class="cov0" title="0">{
        start := time.Now()
        defer func() </span><span class="cov0" title="0">{
                mt.lastStepTime = time.Since(start)
        }</span>()
        
        // Create input tensor and copy data to GPU
        <span class="cov0" title="0">inputTensor, err := memory.NewTensor(inputShape, memory.Float32, memory.GPU)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create input tensor: %v", err)
        }</span>
        <span class="cov0" title="0">defer inputTensor.Release()
        
        // Create label tensor (one-hot encoded for loss computation)
        oneHotShape := []int{labelShape[0], mt.getOutputSize()}
        labelTensor, err := memory.NewTensor(oneHotShape, memory.Float32, memory.GPU)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create label tensor: %v", err)
        }</span>
        <span class="cov0" title="0">defer labelTensor.Release()
        
        // Convert labels to one-hot format (reuses buffer)
        oneHotData := mt.labelsToOneHot(labelData, oneHotShape)
        
        // PERFORMANCE OPTIMIZATION: Smart accuracy calculation based on configured interval
        calculateAccuracy := mt.shouldCalculateAccuracy()
        
        // OPTIMIZATION: Single batched CGO call for entire training step
        // Combines: data copy + forward pass + backward pass + optimizer step + optional inference
        result, err := mt.modelEngine.ExecuteModelTrainingStepBatched(
                inputTensor, labelTensor,
                inputData, oneHotData,
                calculateAccuracy,
        )
        
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("batched training step failed: %v", err)
        }</span>
        
        // Update statistics
        <span class="cov0" title="0">mt.currentStep++
        mt.totalSteps++
        mt.totalLoss += float64(result.Loss)
        mt.averageLoss = float32(mt.totalLoss / float64(mt.totalSteps))
        
        // Update cached accuracy if it was calculated
        if calculateAccuracy </span><span class="cov0" title="0">{
                mt.lastAccuracy = result.Accuracy
        }</span>
        
        <span class="cov0" title="0">return &amp;TrainingResultOptimized{
                Loss:         result.Loss,
                Accuracy:     mt.lastAccuracy, // Use cached value if not calculated this step
                HasAccuracy:  calculateAccuracy, // Training step batched method returns accuracy based on calculation request
                BatchSize:    mt.batchSize,
                StepTime:     mt.lastStepTime,
                Success:      true,
                BatchRate:    float64(mt.batchSize) / mt.lastStepTime.Seconds(),
        }, nil</span>
}

// getOutputSize gets the number of output classes from the model
func (mt *ModelTrainer) getOutputSize() int <span class="cov0" title="0">{
        // Find the last Dense layer to get output size
        for i := len(mt.modelSpec.Layers) - 1; i &gt;= 0; i-- </span><span class="cov0" title="0">{
                layer := mt.modelSpec.Layers[i]
                if layer.Type == layers.Dense </span><span class="cov0" title="0">{
                        if outputSize, ok := layer.Parameters["output_size"].(int); ok </span><span class="cov0" title="0">{
                                return outputSize
                        }</span>
                }
        }
        
        // Default to 2 classes if not found
        <span class="cov0" title="0">return 2</span>
}

// GetStats returns comprehensive training statistics
func (mt *ModelTrainer) GetStats() *ModelTrainingStats <span class="cov0" title="0">{
        memStats := memory.GetGlobalMemoryManager().Stats()
        
        return &amp;ModelTrainingStats{
                CurrentStep:      mt.currentStep,
                TotalSteps:       mt.totalSteps,
                BatchSize:        mt.batchSize,
                OptimizerType:    mt.config.OptimizerType,
                LearningRate:     mt.config.LearningRate,
                AverageLoss:      mt.averageLoss,
                LastStepTime:     mt.lastStepTime,
                ModelSummary:     mt.modelEngine.GetModelSummary(),
                MemoryPoolStats:  memStats,
                ModelParameters:  mt.modelSpec.TotalParameters,
                LayerCount:       int64(len(mt.modelSpec.Layers)),
        }
}</span>

// GetModelSpec returns the model specification
func (mt *ModelTrainer) GetModelSpec() *layers.ModelSpec <span class="cov8" title="1">{
        return mt.modelSpec
}</span>

// GetModelSummary returns a human-readable model summary
func (mt *ModelTrainer) GetModelSummary() string <span class="cov0" title="0">{
        return mt.modelEngine.GetModelSummary()
}</span>

// CreateTrainingSession creates a training session with progress visualization
func (mt *ModelTrainer) CreateTrainingSession(
        modelName string,
        epochs int,
        stepsPerEpoch int,
        validationSteps int,
) *TrainingSession <span class="cov0" title="0">{
        return NewTrainingSession(mt, modelName, epochs, stepsPerEpoch, validationSteps)
}</span>

// PrintModelArchitecture prints the model architecture in PyTorch style
func (mt *ModelTrainer) PrintModelArchitecture(modelName string) <span class="cov0" title="0">{
        printer := NewModelArchitecturePrinter(modelName)
        printer.PrintArchitecture(mt.modelSpec)
}</span>

// SetAccuracyCheckInterval configures how often accuracy is calculated
// interval=0: every step (default, maximum accuracy but higher CGO overhead)
// interval=10: every 10 steps (reduces CGO calls by ~40%, slight accuracy tracking lag)
// interval=50: every 50 steps (reduces CGO calls by ~80%, minimal accuracy tracking)
func (mt *ModelTrainer) SetAccuracyCheckInterval(interval int) <span class="cov0" title="0">{
        if interval &lt; 0 </span><span class="cov0" title="0">{
                interval = 0
        }</span>
        <span class="cov0" title="0">mt.accuracyCheckInterval = interval
        mt.accuracyStepCounter = 0</span>
}

// shouldCalculateAccuracy determines if accuracy should be calculated this step
func (mt *ModelTrainer) shouldCalculateAccuracy() bool <span class="cov0" title="0">{
        if mt.accuracyCheckInterval == 0 </span><span class="cov0" title="0">{
                return true // Calculate every step
        }</span>
        
        <span class="cov0" title="0">mt.accuracyStepCounter++
        if mt.accuracyStepCounter &gt;= mt.accuracyCheckInterval </span><span class="cov0" title="0">{
                mt.accuracyStepCounter = 0
                return true
        }</span>
        <span class="cov0" title="0">return false</span>
}

// EnablePersistentBuffers pre-allocates GPU tensors for reuse across training steps
// This reduces allocation overhead and improves performance
func (mt *ModelTrainer) EnablePersistentBuffers(inputShape []int) error <span class="cov0" title="0">{
        if mt.persistentEnabled </span><span class="cov0" title="0">{
                return nil // Already enabled
        }</span>
        
        // Pre-allocate input tensor
        <span class="cov0" title="0">inputTensor, err := memory.NewTensor(inputShape, memory.Float32, memory.GPU)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create persistent input tensor: %v", err)
        }</span>
        <span class="cov0" title="0">mt.persistentInputTensor = inputTensor
        
        // Pre-allocate label tensor (one-hot encoded)
        oneHotShape := []int{inputShape[0], mt.getOutputSize()}
        labelTensor, err := memory.NewTensor(oneHotShape, memory.Float32, memory.GPU)
        if err != nil </span><span class="cov0" title="0">{
                mt.persistentInputTensor.Release()
                return fmt.Errorf("failed to create persistent label tensor: %v", err)
        }</span>
        <span class="cov0" title="0">mt.persistentLabelTensor = labelTensor
        
        // CRITICAL PERFORMANCE FIX: Pre-allocate gradient tensors to eliminate the major allocation source
        // This addresses the 128MB/step allocation that was causing 83% performance degradation
        if mt.modelEngine != nil &amp;&amp; mt.modelEngine.IsDynamicEngine() &amp;&amp; len(mt.modelEngine.GetParameterTensors()) &gt; 0 </span><span class="cov0" title="0">{
                paramTensors := mt.modelEngine.GetParameterTensors()
                gradientTensors := make([]*memory.Tensor, len(paramTensors))
                for i, paramTensor := range paramTensors </span><span class="cov0" title="0">{
                        gradTensor, err := memory.NewTensor(paramTensor.Shape(), memory.Float32, memory.GPU)
                        if err != nil </span><span class="cov0" title="0">{
                                // Cleanup on error
                                mt.persistentInputTensor.Release()
                                mt.persistentLabelTensor.Release()
                                for j := 0; j &lt; i; j++ </span><span class="cov0" title="0">{
                                        gradientTensors[j].Release()
                                }</span>
                                <span class="cov0" title="0">return fmt.Errorf("failed to create persistent gradient tensor %d: %v", i, err)</span>
                        }
                        <span class="cov0" title="0">gradientTensors[i] = gradTensor</span>
                }
                <span class="cov0" title="0">mt.persistentGradientTensors = gradientTensors</span>
        }
        
        <span class="cov0" title="0">mt.persistentEnabled = true
        return nil</span>
}

// TrainBatchPersistent executes a training step using persistent GPU buffers
// This provides maximum performance by eliminating per-step tensor allocations
func (mt *ModelTrainer) TrainBatchPersistent(
        inputData []float32,
        inputShape []int,
        labelData []int32,
        labelShape []int,
) (*TrainingResultOptimized, error) <span class="cov0" title="0">{
        if !mt.persistentEnabled </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("persistent buffers not enabled - call EnablePersistentBuffers() first")
        }</span>
        
        <span class="cov0" title="0">start := time.Now()
        defer func() </span><span class="cov0" title="0">{
                mt.lastStepTime = time.Since(start)
        }</span>()
        
        // PERFORMANCE FIX: Handle variable batch sizes dynamically
        // Check if persistent tensors need to be resized for current batch
        <span class="cov0" title="0">currentBatchSize := inputShape[0]
        persistentBatchSize := mt.persistentInputTensor.Shape()[0]
        
        if currentBatchSize &gt; persistentBatchSize </span><span class="cov0" title="0">{
                // Need larger tensors - reallocate (rare case for partial batches)
                return nil, fmt.Errorf("batch size %d exceeds persistent buffer size %d - use smaller batches", 
                        currentBatchSize, persistentBatchSize)
        }</span>
        
        // For smaller batches, use the persistent tensors as-is (they're sized for max batch)
        
        // Convert labels to one-hot format (reuses buffer)
        <span class="cov0" title="0">oneHotShape := []int{labelShape[0], mt.getOutputSize()}
        oneHotData := mt.labelsToOneHot(labelData, oneHotShape)
        
        // PERFORMANCE OPTIMIZATION: Smart accuracy calculation based on configured interval
        calculateAccuracy := mt.shouldCalculateAccuracy()
        
        
        // OPTIMIZATION: Single batched CGO call using persistent tensors
        // Maximum performance: no allocations, single CGO call
        result, err := mt.modelEngine.ExecuteModelTrainingStepBatchedPersistentWithGradients(
                mt.persistentInputTensor, mt.persistentLabelTensor,
                inputData, oneHotData,
                calculateAccuracy,
                mt.persistentGradientTensors, // CRITICAL: Pass pre-allocated gradient tensors
        )
        
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("persistent batched training step failed: %v", err)
        }</span>
        
        // Update statistics
        <span class="cov0" title="0">mt.currentStep++
        mt.totalSteps++
        mt.totalLoss += float64(result.Loss)
        mt.averageLoss = float32(mt.totalLoss / float64(mt.totalSteps))
        
        // Update cached accuracy if it was calculated
        var accuracyToReturn float64
        var hasAccuracy bool
        
        if calculateAccuracy </span><span class="cov0" title="0">{
                mt.lastAccuracy = result.Accuracy
                accuracyToReturn = result.Accuracy
                hasAccuracy = true
        }</span> else<span class="cov0" title="0"> {
                // Don't return cached accuracy - return 0 and indicate no accuracy calculated
                accuracyToReturn = 0.0
                hasAccuracy = false
        }</span>
        
        <span class="cov0" title="0">return &amp;TrainingResultOptimized{
                Loss:         result.Loss,
                Accuracy:     accuracyToReturn, // Only return accuracy if calculated this step
                HasAccuracy:  hasAccuracy,
                BatchSize:    mt.batchSize,
                StepTime:     mt.lastStepTime,
                Success:      true,
                BatchRate:    float64(mt.batchSize) / mt.lastStepTime.Seconds(),
        }, nil</span>
}

// TrainBatchWithCommandPool executes a training step using pooled command buffers
// This method implements the complete command buffer pooling strategy to prevent resource leaks
func (mt *ModelTrainer) TrainBatchWithCommandPool(
        inputData []float32,
        inputShape []int,
        labelData []int32,
        labelShape []int,
) (*TrainingResultOptimized, error) <span class="cov0" title="0">{
        if mt.commandBufferPool == nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("command buffer pool not initialized")
        }</span>
        
        <span class="cov0" title="0">start := time.Now()
        defer func() </span><span class="cov0" title="0">{
                mt.lastStepTime = time.Since(start)
        }</span>()
        
        // Get a command buffer from the pool
        <span class="cov0" title="0">commandBuffer, err := mt.commandBufferPool.GetBuffer()
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to get command buffer from pool: %v", err)
        }</span>
        
        // Ensure command buffer is returned to pool on completion
        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                if commandBuffer != nil </span><span class="cov0" title="0">{
                        mt.commandBufferPool.ReturnBuffer(commandBuffer)
                }</span>
        }()
        
        // Setup autorelease pool for proper Metal resource management
        <span class="cov0" title="0">cgo_bridge.SetupAutoreleasePool()
        defer cgo_bridge.DrainAutoreleasePool()
        
        // Create input tensor and copy data to GPU
        inputTensor, err := memory.NewTensor(inputShape, memory.Float32, memory.GPU)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create input tensor: %v", err)
        }</span>
        <span class="cov0" title="0">defer inputTensor.Release()
        
        // Create label tensor (one-hot encoded for loss computation)
        oneHotShape := []int{labelShape[0], mt.getOutputSize()}
        labelTensor, err := memory.NewTensor(oneHotShape, memory.Float32, memory.GPU)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create label tensor: %v", err)
        }</span>
        <span class="cov0" title="0">defer labelTensor.Release()
        
        // Convert labels to one-hot format (reuses buffer)
        oneHotData := mt.labelsToOneHot(labelData, oneHotShape)
        
        // Copy data to GPU
        err = cgo_bridge.CopyFloat32ArrayToMetalBuffer(inputTensor.MetalBuffer(), inputData)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to copy input data to GPU: %v", err)
        }</span>
        
        <span class="cov0" title="0">err = cgo_bridge.CopyFloat32ArrayToMetalBuffer(labelTensor.MetalBuffer(), oneHotData)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to copy label data to GPU: %v", err)
        }</span>
        
        // PERFORMANCE OPTIMIZATION: Smart accuracy calculation
        <span class="cov0" title="0">calculateAccuracy := mt.shouldCalculateAccuracy()
        
        // Execute training step with the existing engine methods
        // Note: The underlying engine will use its own command buffers, but our pooled
        // command buffer ensures proper cleanup and prevents accumulation
        var loss float32
        if mt.config.OptimizerType == cgo_bridge.Adam </span><span class="cov0" title="0">{
                loss, err = mt.modelEngine.ExecuteModelTrainingStepWithAdam(inputTensor, labelTensor)
        }</span> else<span class="cov0" title="0"> if mt.config.OptimizerType == cgo_bridge.LBFGS </span><span class="cov0" title="0">{
                loss, err = mt.modelEngine.ExecuteModelTrainingStepWithLBFGS(inputTensor, labelTensor)
        }</span> else<span class="cov0" title="0"> {
                loss, err = mt.modelEngine.ExecuteModelTrainingStep(inputTensor, labelTensor, mt.config.LearningRate)
        }</span>
        
        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("training step failed: %v", err)
        }</span>
        
        // Calculate accuracy if requested
        <span class="cov0" title="0">var accuracy float64
        var hasAccuracy bool
        if calculateAccuracy </span><span class="cov0" title="0">{
                // Perform inference to get predictions
                inferenceResult, inferErr := mt.modelEngine.ExecuteInference(inputTensor, inputShape[0])
                if inferErr == nil </span><span class="cov0" title="0">{
                        accuracy = mt.CalculateAccuracy(
                                inferenceResult.Predictions, 
                                labelData, 
                                inputShape[0], 
                                mt.getOutputSize(),
                        )
                        mt.lastAccuracy = accuracy
                        hasAccuracy = true
                }</span> else<span class="cov0" title="0"> {
                        // Log inference error but don't fail the training step
                        if mt.currentStep % 100 == 0 </span><span class="cov0" title="0">{ // Log occasionally to avoid spam
                                fmt.Printf("Warning: Training accuracy inference failed at step %d: %v\n", mt.currentStep, inferErr)
                        }</span>
                        <span class="cov0" title="0">accuracy = 0.0
                        hasAccuracy = false</span>
                }
        } else<span class="cov0" title="0"> {
                accuracy = mt.lastAccuracy
                hasAccuracy = false
        }</span>
        
        // Update statistics
        <span class="cov0" title="0">mt.currentStep++
        mt.totalSteps++
        mt.totalLoss += float64(loss)
        mt.averageLoss = float32(mt.totalLoss / float64(mt.totalSteps))
        
        // VISUALIZATION: Record training step data (CPU-only scalar access)
        // This follows GPU-resident architecture - only CPU access for final metrics
        if hasAccuracy </span><span class="cov0" title="0">{
                mt.recordTrainingStep(mt.currentStep, float64(loss), accuracy)
        }</span>
        
        <span class="cov0" title="0">return &amp;TrainingResultOptimized{
                Loss:         loss,
                Accuracy:     accuracy,
                HasAccuracy:  hasAccuracy, // Use the actual result of accuracy calculation
                BatchSize:    mt.batchSize,
                StepTime:     mt.lastStepTime,
                Success:      true,
                BatchRate:    float64(mt.batchSize) / mt.lastStepTime.Seconds(),
        }, nil</span>
}

// TrainBatchUnified executes a training step with flexible label types
// This is the recommended API for new code as it supports both classification and regression
// while maintaining GPU-residency and minimizing CGO calls
func (mt *ModelTrainer) TrainBatchUnified(
        inputData []float32,
        inputShape []int,
        labelData LabelData,
) (*TrainingResultOptimized, error) <span class="cov0" title="0">{
        // Validate label data compatibility with trainer configuration
        if err := mt.validateLabelCompatibility(labelData); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        
        // Convert labels to float32 for GPU consumption (zero-cost for regression)
        <span class="cov0" title="0">labels := labelData.ToFloat32Slice()
        labelShape := labelData.Shape()
        
        // Call the internal training function with converted labels
        return mt.trainBatchPersistentWithCommandPoolInternal(
                inputData, inputShape, labels, labelShape, labelData.DataType())</span>
}

// validateLabelCompatibility ensures label data matches the configured problem type
func (mt *ModelTrainer) validateLabelCompatibility(labelData LabelData) error <span class="cov0" title="0">{
        configType := mt.trainerConfig.ProblemType
        dataType := labelData.DataType()
        
        switch configType </span>{
        case Classification:<span class="cov0" title="0">
                if dataType != LabelTypeInt32 </span><span class="cov0" title="0">{
                        return fmt.Errorf("classification trainer requires Int32Labels, got %v", dataType)
                }</span>
        case Regression:<span class="cov0" title="0">
                if dataType != LabelTypeFloat32 </span><span class="cov0" title="0">{
                        return fmt.Errorf("regression trainer requires Float32Labels, got %v", dataType)
                }</span>
        default:<span class="cov0" title="0">
                return fmt.Errorf("unsupported problem type: %v", configType)</span>
        }
        
        <span class="cov0" title="0">return nil</span>
}

// TrainBatchPersistentWithCommandPool executes a training step using both persistent tensors 
// and pooled command buffers for maximum performance and resource efficiency
// DEPRECATED: Use TrainBatchUnified for new code
func (mt *ModelTrainer) TrainBatchPersistentWithCommandPool(
        inputData []float32,
        inputShape []int,
        labelData []int32,
        labelShape []int,
) (*TrainingResultOptimized, error) <span class="cov0" title="0">{
        // Convert int32 labels to LabelData for unified processing
        labels, err := NewInt32Labels(labelData, labelShape)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create label data: %v", err)
        }</span>
        
        <span class="cov0" title="0">return mt.TrainBatchUnified(inputData, inputShape, labels)</span>
}

// trainBatchPersistentWithCommandPoolInternal is the internal implementation
// that works with float32 labels for both classification and regression
func (mt *ModelTrainer) trainBatchPersistentWithCommandPoolInternal(
        inputData []float32,
        inputShape []int,
        labelData []float32,
        labelShape []int,
        labelType LabelDataType,
) (*TrainingResultOptimized, error) <span class="cov0" title="0">{
        if !mt.persistentEnabled </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("persistent buffers not enabled - call EnablePersistentBuffers() first")
        }</span>
        
        <span class="cov0" title="0">if mt.commandBufferPool == nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("command buffer pool not initialized")
        }</span>
        
        <span class="cov0" title="0">start := time.Now()
        defer func() </span><span class="cov0" title="0">{
                mt.lastStepTime = time.Since(start)
        }</span>()
        
        // Get a command buffer from the pool
        <span class="cov0" title="0">commandBuffer, err := mt.commandBufferPool.GetBuffer()
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to get command buffer from pool: %v", err)
        }</span>
        
        // Ensure command buffer is returned to pool on completion
        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                if commandBuffer != nil </span><span class="cov0" title="0">{
                        mt.commandBufferPool.ReturnBuffer(commandBuffer)
                }</span>
        }()
        
        // Setup autorelease pool for proper Metal resource management
        <span class="cov0" title="0">cgo_bridge.SetupAutoreleasePool()
        defer cgo_bridge.DrainAutoreleasePool()
        
        // PERFORMANCE FIX: Handle variable batch sizes dynamically
        currentBatchSize := inputShape[0]
        persistentBatchSize := mt.persistentInputTensor.Shape()[0]
        
        if currentBatchSize &gt; persistentBatchSize </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("batch size %d exceeds persistent buffer size %d - use smaller batches", 
                        currentBatchSize, persistentBatchSize)
        }</span>
        
        // Handle labels based on problem type
        <span class="cov0" title="0">var processedLabels []float32
        
        if mt.trainerConfig.ProblemType == Classification </span><span class="cov0" title="0">{
                // Convert labels to one-hot format for classification
                if labelType == LabelTypeInt32 </span><span class="cov0" title="0">{
                        // Labels are int32, convert back from float32 to int32 for one-hot encoding
                        int32Labels := make([]int32, len(labelData))
                        for i, v := range labelData </span><span class="cov0" title="0">{
                                int32Labels[i] = int32(v)
                        }</span>
                        <span class="cov0" title="0">oneHotShape := []int{labelShape[0], mt.getOutputSize()}
                        processedLabels = mt.labelsToOneHot(int32Labels, oneHotShape)</span>
                } else<span class="cov0" title="0"> {
                        // This shouldn't happen with proper validation, but handle it
                        return nil, fmt.Errorf("classification requires int32 labels")
                }</span>
        } else<span class="cov0" title="0"> {
                // For regression, use float32 labels directly
                processedLabels = labelData
        }</span>
        
        // Copy data to persistent GPU tensors
        <span class="cov0" title="0">err = cgo_bridge.CopyFloat32ArrayToMetalBuffer(mt.persistentInputTensor.MetalBuffer(), inputData)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to copy input data to GPU: %v", err)
        }</span>
        
        <span class="cov0" title="0">err = cgo_bridge.CopyFloat32ArrayToMetalBuffer(mt.persistentLabelTensor.MetalBuffer(), processedLabels)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to copy label data to GPU: %v", err)
        }</span>
        
        // PERFORMANCE OPTIMIZATION: Smart accuracy calculation
        <span class="cov0" title="0">calculateAccuracy := mt.shouldCalculateAccuracy()
        
        // Execute training step with persistent tensors and pooled command buffers
        // This combines both optimizations for maximum performance
        var loss float32
        if mt.config.OptimizerType == cgo_bridge.Adam </span><span class="cov0" title="0">{
                loss, err = mt.modelEngine.ExecuteModelTrainingStepWithAdam(mt.persistentInputTensor, mt.persistentLabelTensor)
        }</span> else<span class="cov0" title="0"> {
                loss, err = mt.modelEngine.ExecuteModelTrainingStep(mt.persistentInputTensor, mt.persistentLabelTensor, mt.config.LearningRate)
        }</span>
        
        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("persistent training step with command pool failed: %v", err)
        }</span>
        
        // Calculate accuracy if requested
        <span class="cov0" title="0">var accuracy float64
        var hasAccuracy bool
        if calculateAccuracy </span><span class="cov0" title="0">{
                // Perform inference using persistent tensors
                inferenceResult, inferErr := mt.modelEngine.ExecuteInference(mt.persistentInputTensor, currentBatchSize)
                if inferErr == nil </span><span class="cov0" title="0">{
                        accuracy = mt.CalculateAccuracyUnified(
                                inferenceResult.Predictions, 
                                labelData, 
                                currentBatchSize, 
                                mt.getOutputSize(),
                                labelType,
                        )
                        mt.lastAccuracy = accuracy
                        hasAccuracy = true
                }</span> else<span class="cov0" title="0"> {
                        // Log inference error but don't fail the training step
                        if mt.currentStep % 100 == 0 </span><span class="cov0" title="0">{ // Log occasionally to avoid spam
                                fmt.Printf("Warning: Training accuracy inference failed at step %d: %v\n", mt.currentStep, inferErr)
                        }</span>
                        <span class="cov0" title="0">accuracy = 0.0
                        hasAccuracy = false</span>
                }
        } else<span class="cov0" title="0"> {
                accuracy = mt.lastAccuracy
                hasAccuracy = false
        }</span>
        
        // Update statistics
        <span class="cov0" title="0">mt.currentStep++
        mt.totalSteps++
        mt.totalLoss += float64(loss)
        mt.averageLoss = float32(mt.totalLoss / float64(mt.totalSteps))
        
        // VISUALIZATION: Record training step data (CPU-only scalar access)
        // This follows GPU-resident architecture - only CPU access for final metrics
        if hasAccuracy </span><span class="cov0" title="0">{
                mt.recordTrainingStep(mt.currentStep, float64(loss), accuracy)
        }</span>
        
        <span class="cov0" title="0">return &amp;TrainingResultOptimized{
                Loss:         loss,
                Accuracy:     accuracy,
                HasAccuracy:  hasAccuracy, // Use the actual result of accuracy calculation
                BatchSize:    mt.batchSize,
                StepTime:     mt.lastStepTime,
                Success:      true,
                BatchRate:    float64(mt.batchSize) / mt.lastStepTime.Seconds(),
        }, nil</span>
}

// Cleanup releases all resources
func (mt *ModelTrainer) Cleanup() <span class="cov8" title="1">{
        // RESOURCE LEAK FIX: Cleanup command buffer pool first to ensure proper resource cleanup
        if mt.commandBufferPool != nil </span><span class="cov8" title="1">{
                mt.commandBufferPool.Cleanup()
                mt.commandBufferPool = nil
        }</span>
        
        // Release command queue
        <span class="cov8" title="1">if mt.commandQueue != nil </span><span class="cov8" title="1">{
                cgo_bridge.ReleaseCommandQueue(mt.commandQueue)
                mt.commandQueue = nil
        }</span>
        
        // Release persistent tensors if allocated
        <span class="cov8" title="1">if mt.persistentInputTensor != nil </span><span class="cov0" title="0">{
                mt.persistentInputTensor.Release()
                mt.persistentInputTensor = nil
        }</span>
        <span class="cov8" title="1">if mt.persistentLabelTensor != nil </span><span class="cov0" title="0">{
                mt.persistentLabelTensor.Release()
                mt.persistentLabelTensor = nil
        }</span>
        // CRITICAL: Release pre-allocated gradient tensors
        <span class="cov8" title="1">for _, gradTensor := range mt.persistentGradientTensors </span><span class="cov0" title="0">{
                if gradTensor != nil </span><span class="cov0" title="0">{
                        gradTensor.Release()
                }</span>
        }
        <span class="cov8" title="1">mt.persistentGradientTensors = nil
        mt.persistentEnabled = false
        
        if mt.modelEngine != nil </span><span class="cov8" title="1">{
                mt.modelEngine.Cleanup()
                mt.modelEngine = nil
        }</span>
}

// ModelTrainingStats provides comprehensive statistics for model-based training
type ModelTrainingStats struct {
        CurrentStep      int
        TotalSteps       int64
        BatchSize        int
        OptimizerType    cgo_bridge.OptimizerType
        LearningRate     float32
        AverageLoss      float32
        LastStepTime     time.Duration
        ModelSummary     string
        MemoryPoolStats  map[memory.PoolKey]string
        ModelParameters  int64
        LayerCount       int64
}

// ModelTrainerFactory provides methods to create model trainers with different configurations
type ModelTrainerFactory struct{}

// NewModelFactory creates a new model trainer factory
func NewModelFactory() *ModelTrainerFactory <span class="cov0" title="0">{
        return &amp;ModelTrainerFactory{}
}</span>

// CreateModelTrainer creates a model trainer with full configuration control
func (mtf *ModelTrainerFactory) CreateModelTrainer(
        modelSpec *layers.ModelSpec,
        config TrainerConfig,
) (*ModelTrainer, error) <span class="cov0" title="0">{
        return NewModelTrainer(modelSpec, config)
}</span>

// CreateCNNTrainer creates a CNN trainer with typical architecture
func (mtf *ModelTrainerFactory) CreateCNNTrainer(
        inputShape []int,
        numClasses int,
        config TrainerConfig,
) (*ModelTrainer, error) <span class="cov0" title="0">{
        // Build a typical CNN model
        builder := layers.NewModelBuilder(inputShape)
        
        // Add layers
        model, err := builder.
                AddConv2D(8, 3, 1, 1, true, "conv1").    // 8 filters, 3x3 kernel, stride=1, padding=1
                AddReLU("relu1").
                AddDense(numClasses, true, "fc1").       // Fully connected to output classes
                AddSoftmax(-1, "softmax").               // Softmax on last dimension
                Compile()
        
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to compile CNN model: %v", err)
        }</span>
        
        <span class="cov0" title="0">return mtf.CreateModelTrainer(model, config)</span>
}

// CreateMLPTrainer creates a multi-layer perceptron trainer
func (mtf *ModelTrainerFactory) CreateMLPTrainer(
        inputSize int,
        hiddenSizes []int,
        outputSize int,
        config TrainerConfig,
) (*ModelTrainer, error) <span class="cov0" title="0">{
        // Build MLP model
        inputShape := []int{config.BatchSize, inputSize}
        builder := layers.NewModelBuilder(inputShape)
        
        // Add hidden layers
        for i, hiddenSize := range hiddenSizes </span><span class="cov0" title="0">{
                layerName := fmt.Sprintf("hidden_%d", i+1)
                builder.AddDense(hiddenSize, true, layerName)
                
                reluName := fmt.Sprintf("relu_%d", i+1)
                builder.AddReLU(reluName)
        }</span>
        
        // Add output layer
        <span class="cov0" title="0">builder.AddDense(outputSize, true, "output")
        builder.AddSoftmax(-1, "softmax")
        
        model, err := builder.Compile()
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to compile MLP model: %v", err)
        }</span>
        
        <span class="cov0" title="0">return mtf.CreateModelTrainer(model, config)</span>
}

// validateTrainerConfig validates the trainer configuration (reusing existing validation)
func validateTrainerConfig(config TrainerConfig) error <span class="cov8" title="1">{
        if config.BatchSize &lt;= 0 </span><span class="cov0" title="0">{
                return fmt.Errorf("batch size must be positive, got %d", config.BatchSize)
        }</span>
        
        <span class="cov8" title="1">if config.LearningRate &lt;= 0 </span><span class="cov0" title="0">{
                return fmt.Errorf("learning rate must be positive, got %f", config.LearningRate)
        }</span>
        
        <span class="cov8" title="1">if config.OptimizerType == cgo_bridge.Adam </span><span class="cov0" title="0">{
                if config.Beta1 &lt;= 0 || config.Beta1 &gt;= 1 </span><span class="cov0" title="0">{
                        return fmt.Errorf("Adam beta1 must be in (0, 1), got %f", config.Beta1)
                }</span>
                <span class="cov0" title="0">if config.Beta2 &lt;= 0 || config.Beta2 &gt;= 1 </span><span class="cov0" title="0">{
                        return fmt.Errorf("Adam beta2 must be in (0, 1), got %f", config.Beta2)
                }</span>
                <span class="cov0" title="0">if config.Epsilon &lt;= 0 </span><span class="cov0" title="0">{
                        return fmt.Errorf("Adam epsilon must be positive, got %f", config.Epsilon)
                }</span>
        }
        
        <span class="cov8" title="1">if config.OptimizerType == cgo_bridge.LBFGS </span><span class="cov0" title="0">{
                if config.LearningRate &lt;= 0 </span><span class="cov0" title="0">{
                        return fmt.Errorf("L-BFGS learning rate must be positive, got %f", config.LearningRate)
                }</span>
                // L-BFGS is suitable for full-batch or large-batch training
                // For very small batches, recommend Adam or SGD instead
                <span class="cov0" title="0">if config.BatchSize &lt; 32 </span><span class="cov0" title="0">{
                        fmt.Printf("⚠️  Warning: L-BFGS with small batch size (%d) may be inefficient. Consider Adam or SGD for mini-batch training.\n", config.BatchSize)
                }</span>
        }
        
        <span class="cov8" title="1">if config.WeightDecay &lt; 0 </span><span class="cov0" title="0">{
                return fmt.Errorf("weight decay must be non-negative, got %f", config.WeightDecay)
        }</span>
        
        <span class="cov8" title="1">return nil</span>
}

// InferBatch performs inference on a batch of data
// Conforms to design requirements: single CGO call, GPU-resident, shared resources
func (mt *ModelTrainer) InferBatch(
        inputData []float32,
        inputShape []int,
) (*cgo_bridge.InferenceResult, error) <span class="cov0" title="0">{
        // Validate inputs
        if len(inputData) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("input data is empty")
        }</span>
        
        <span class="cov0" title="0">if len(inputShape) &lt; 2 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("input shape must have at least 2 dimensions, got %v", inputShape)
        }</span>
        
        <span class="cov0" title="0">batchSize := inputShape[0]
        if batchSize &lt;= 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("invalid batch size: %d", batchSize)
        }</span>
        
        // Create input tensor and copy data to GPU (GPU-resident everything principle)
        <span class="cov0" title="0">inputTensor, err := memory.NewTensor(inputShape, memory.Float32, memory.GPU)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create input tensor: %v", err)
        }</span>
        <span class="cov0" title="0">defer inputTensor.Release()
        
        // Copy input data to GPU (minimal CPU-GPU transfers)
        err = cgo_bridge.CopyFloat32ArrayToMetalBuffer(
                inputTensor.MetalBuffer(), 
                inputData,
        )
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to copy input data to GPU: %v", err)
        }</span>
        
        // Execute inference using single CGO call (design compliant)
        <span class="cov0" title="0">return mt.modelEngine.ExecuteInference(inputTensor, batchSize)</span>
}

// CalculateAccuracyUnified calculates accuracy for both classification and regression
// For classification: returns percentage of correct predictions
// For regression: returns 1 - normalized mean absolute error
func (mt *ModelTrainer) CalculateAccuracyUnified(
        predictions []float32,
        trueLabels []float32,
        batchSize int,
        outputSize int,
        labelType LabelDataType,
) float64 <span class="cov0" title="0">{
        if mt.trainerConfig.ProblemType == Classification </span><span class="cov0" title="0">{
                // Convert float32 labels back to int32 for classification
                int32Labels := make([]int32, len(trueLabels))
                for i, v := range trueLabels </span><span class="cov0" title="0">{
                        int32Labels[i] = int32(v)
                }</span>
                <span class="cov0" title="0">return mt.CalculateAccuracy(predictions, int32Labels, batchSize, outputSize)</span>
        } else<span class="cov0" title="0"> {
                // For regression, calculate R² or 1-NMAE
                return mt.CalculateRegressionMetric(predictions, trueLabels, batchSize)
        }</span>
}

// CalculateRegressionMetric calculates a metric for regression
// Returns 1 - normalized mean absolute error (closer to 1 is better)
func (mt *ModelTrainer) CalculateRegressionMetric(
        predictions []float32,
        trueLabels []float32,
        batchSize int,
) float64 <span class="cov0" title="0">{
        if len(predictions) &lt; batchSize || len(trueLabels) &lt; batchSize </span><span class="cov0" title="0">{
                return 0.0
        }</span>
        
        <span class="cov0" title="0">var sumAbsError float64
        var sumTrue float64
        
        for i := 0; i &lt; batchSize; i++ </span><span class="cov0" title="0">{
                pred := float64(predictions[i])
                true := float64(trueLabels[i])
                sumAbsError += math.Abs(pred - true)
                sumTrue += math.Abs(true)
        }</span>
        
        <span class="cov0" title="0">if sumTrue == 0 </span><span class="cov0" title="0">{
                return 0.0
        }</span>
        
        // Normalized mean absolute error
        <span class="cov0" title="0">nmae := sumAbsError / sumTrue
        
        // Return 1 - NMAE so higher is better (like accuracy)
        return math.Max(0, 1.0 - nmae)</span>
}

// CalculateAccuracy computes accuracy from inference results and true labels
// Uses CPU-based argmax for final scalar metric (design compliant)
func (mt *ModelTrainer) CalculateAccuracy(
        predictions []float32,
        trueLabels []int32,
        batchSize int,
        numClasses int,
) float64 <span class="cov0" title="0">{
        if len(predictions) != batchSize*numClasses </span><span class="cov0" title="0">{
                return 0.0 // Invalid predictions array
        }</span>
        
        <span class="cov0" title="0">if len(trueLabels) != batchSize </span><span class="cov0" title="0">{
                return 0.0 // Invalid labels array
        }</span>
        
        <span class="cov0" title="0">correctPredictions := 0
        
        for i := 0; i &lt; batchSize; i++ </span><span class="cov0" title="0">{
                // Find predicted class (argmax) - CPU computation for scalar result
                maxIdx := 0
                maxVal := predictions[i*numClasses]
                
                for j := 1; j &lt; numClasses; j++ </span><span class="cov0" title="0">{
                        if predictions[i*numClasses+j] &gt; maxVal </span><span class="cov0" title="0">{
                                maxVal = predictions[i*numClasses+j]
                                maxIdx = j
                        }</span>
                }
                
                // Check if prediction matches true label
                <span class="cov0" title="0">if int32(maxIdx) == trueLabels[i] </span><span class="cov0" title="0">{
                        correctPredictions++
                }</span>
        }
        
        <span class="cov0" title="0">return float64(correctPredictions) / float64(batchSize)</span>
}

// TrainingResultOptimized represents the result of an optimized training step
// Includes optional accuracy calculation to reduce CGO overhead
type TrainingResultOptimized struct {
        Loss        float32
        Accuracy    float64  // Only valid if HasAccuracy is true
        HasAccuracy bool     // Whether accuracy was calculated this step
        BatchSize   int
        StepTime    time.Duration
        Success     bool
        BatchRate   float64  // Batches per second
}

// shapesEqual compares two tensor shapes for equality
func shapesEqual(a, b []int) bool <span class="cov0" title="0">{
        if len(a) != len(b) </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov0" title="0">for i, v := range a </span><span class="cov0" title="0">{
                if v != b[i] </span><span class="cov0" title="0">{
                        return false
                }</span>
        }
        <span class="cov0" title="0">return true</span>
}

// SetLRScheduler sets a learning rate scheduler for the trainer
// This maintains GPU-resident principles by only updating LR between epochs
func (mt *ModelTrainer) SetLRScheduler(scheduler LRScheduler) <span class="cov0" title="0">{
        mt.lrScheduler = scheduler
}</span>

// GetCurrentLearningRate returns the current learning rate based on scheduler
// This is a pure computation - no GPU operations
func (mt *ModelTrainer) GetCurrentLearningRate() float32 <span class="cov0" title="0">{
        if mt.lrScheduler == nil </span><span class="cov0" title="0">{
                return mt.config.LearningRate
        }</span>
        
        // Get scheduled learning rate
        <span class="cov0" title="0">scheduledLR := mt.lrScheduler.GetLR(mt.currentEpoch, mt.currentStep, float64(mt.baseLearningRate))
        return float32(scheduledLR)</span>
}

// SetEpoch updates the current epoch for learning rate scheduling
// Call this at the start of each epoch
func (mt *ModelTrainer) SetEpoch(epoch int) <span class="cov0" title="0">{
        mt.currentEpoch = epoch
        
        // Update the learning rate in the config for next training steps
        mt.config.LearningRate = mt.GetCurrentLearningRate()
}</span>

// StepSchedulerWithMetric updates schedulers that depend on validation metrics
// For ReduceLROnPlateauScheduler - call this after validation
func (mt *ModelTrainer) StepSchedulerWithMetric(metric float64) <span class="cov0" title="0">{
        if scheduler, ok := mt.lrScheduler.(*ReduceLROnPlateauScheduler); ok </span><span class="cov0" title="0">{
                // Update the scheduler's internal state
                newLR := scheduler.Step(metric, float64(mt.config.LearningRate))
                mt.config.LearningRate = float32(newLR)
        }</span>
}

// GetSchedulerInfo returns current scheduler information for logging
func (mt *ModelTrainer) GetSchedulerInfo() string <span class="cov0" title="0">{
        if mt.lrScheduler == nil </span><span class="cov0" title="0">{
                return "No scheduler (constant LR)"
        }</span>
        
        <span class="cov0" title="0">currentLR := mt.GetCurrentLearningRate()
        return fmt.Sprintf("%s scheduler: LR=%.6f (epoch=%d, step=%d)", 
                mt.lrScheduler.GetName(), 
                currentLR, 
                mt.currentEpoch,
                mt.currentStep,
        )</span>
}

// GetParameterTensors returns the parameter tensors for weight extraction
func (mt *ModelTrainer) GetParameterTensors() []*memory.Tensor <span class="cov0" title="0">{
        if mt.modelEngine == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">return mt.modelEngine.GetParameterTensors()</span>
}

// GetLRScheduler returns the learning rate scheduler if available
func (mt *ModelTrainer) GetLRScheduler() interface{} <span class="cov0" title="0">{
        return mt.lrScheduler
}</span>

// SetLearningRate sets the learning rate
func (mt *ModelTrainer) SetLearningRate(lr float32) <span class="cov0" title="0">{
        mt.config.LearningRate = lr
        if mt.lrScheduler != nil </span>{<span class="cov0" title="0">
                // For dynamic LR changes, we'd need to implement this in the scheduler
                // For now, just update the config
        }</span>
}

// GetOptimizerState returns the optimizer state for checkpoint saving
func (mt *ModelTrainer) GetOptimizerState() *OptimizerStateData <span class="cov0" title="0">{
        // For now, return nil as we don't have optimizer state extraction implemented
        // This would need to be implemented based on the specific optimizer being used
        return nil
}</span>

// SetOptimizerState restores optimizer state from checkpoint
func (mt *ModelTrainer) SetOptimizerState(state interface{}) error <span class="cov0" title="0">{
        // For now, return an error as optimizer state restoration is not implemented
        // This would need to be implemented based on the specific optimizer being used
        return fmt.Errorf("optimizer state restoration not yet implemented")
}</span>

// Predict provides a lightweight inference method for backward compatibility
// For optimal inference performance, use ModelInferencer instead
func (mt *ModelTrainer) Predict(
        inputData []float32,
        inputShape []int,
) (*cgo_bridge.InferenceResult, error) <span class="cov0" title="0">{
        // Use the existing InferBatch method for compatibility
        // This maintains the proven single-CGO-call architecture
        return mt.InferBatch(inputData, inputShape)
}</span>

// ================================================================
// EVALUATION METRICS SYSTEM - GPU-RESIDENT ARCHITECTURE COMPLIANT
// ================================================================

// EnableEvaluationMetrics enables comprehensive evaluation metrics collection
// Metrics are calculated from GPU-resident tensors with CPU-only scalar results
func (mt *ModelTrainer) EnableEvaluationMetrics() <span class="cov0" title="0">{
        mt.metricsEnabled = true
        mt.confusionMatrix.Reset()
        mt.metricHistory = make(map[MetricType][]float64)
}</span>

// DisableEvaluationMetrics disables evaluation metrics for performance
func (mt *ModelTrainer) DisableEvaluationMetrics() <span class="cov0" title="0">{
        mt.metricsEnabled = false
}</span>

// IsEvaluationMetricsEnabled returns whether comprehensive metrics are enabled
func (mt *ModelTrainer) IsEvaluationMetricsEnabled() bool <span class="cov0" title="0">{
        return mt.metricsEnabled
}</span>

// UpdateMetricsFromInference updates evaluation metrics from inference results
// GPU-resident architecture: operates on GPU tensor data, stores CPU scalars only
func (mt *ModelTrainer) UpdateMetricsFromInference(
        predictions []float32,
        trueLabels interface{}, // []int32 for classification, []float32 for regression
        batchSize int,
) error <span class="cov0" title="0">{
        if !mt.metricsEnabled </span><span class="cov0" title="0">{
                return nil // Metrics disabled, skip computation
        }</span>
        
        <span class="cov0" title="0">outputSize := mt.getOutputSize()
        
        if mt.trainerConfig.ProblemType == Classification </span><span class="cov0" title="0">{
                // Handle classification metrics
                var int32Labels []int32
                switch labels := trueLabels.(type) </span>{
                case []int32:<span class="cov0" title="0">
                        int32Labels = labels</span>
                case []float32:<span class="cov0" title="0">
                        // Convert float32 labels to int32
                        int32Labels = make([]int32, len(labels))
                        for i, v := range labels </span><span class="cov0" title="0">{
                                int32Labels[i] = int32(v)
                        }</span>
                default:<span class="cov0" title="0">
                        return fmt.Errorf("invalid label type for classification: %T", trueLabels)</span>
                }
                
                // Update confusion matrix (use number of classes, not output size)
                <span class="cov0" title="0">numClasses := mt.confusionMatrix.NumClasses
                err := mt.confusionMatrix.UpdateFromPredictions(predictions, int32Labels, batchSize, numClasses)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to update confusion matrix: %v", err)
                }</span>
                
                // Collect probabilities for PR/ROC curves if visualization is enabled
                <span class="cov0" title="0">mt.collectValidationProbabilities(predictions, int32Labels, batchSize, numClasses)
                
                // For binary classification, also calculate AUC-ROC if we have raw scores
                if outputSize == 2 || outputSize == 1 </span><span class="cov0" title="0">{
                        var scores []float32
                        if outputSize == 1 </span><span class="cov0" title="0">{
                                // Single output (BCEWithLogits or sigmoid output)
                                scores = predictions[:batchSize]
                        }</span> else<span class="cov0" title="0"> {
                                // Two outputs, use positive class probability
                                scores = make([]float32, batchSize)
                                for i := 0; i &lt; batchSize; i++ </span><span class="cov0" title="0">{
                                        scores[i] = predictions[i*2+1] // Positive class score
                                }</span>
                        }
                        
                        <span class="cov0" title="0">auc := CalculateAUCROC(scores, int32Labels, batchSize)
                        mt.addToHistory(AUCROC, auc)</span>
                }
                
        } else<span class="cov0" title="0"> {
                // Handle regression metrics
                var float32Labels []float32
                switch labels := trueLabels.(type) </span>{
                case []float32:<span class="cov0" title="0">
                        float32Labels = labels</span>
                case []int32:<span class="cov0" title="0">
                        // Convert int32 to float32 (unusual but handle it)
                        float32Labels = make([]float32, len(labels))
                        for i, v := range labels </span><span class="cov0" title="0">{
                                float32Labels[i] = float32(v)
                        }</span>
                default:<span class="cov0" title="0">
                        return fmt.Errorf("invalid label type for regression: %T", trueLabels)</span>
                }
                
                // Calculate comprehensive regression metrics
                <span class="cov0" title="0">mt.lastRegressionMetrics = CalculateRegressionMetrics(predictions, float32Labels, batchSize)
                
                // Add to history for plotting
                mt.addToHistory(MAE, mt.lastRegressionMetrics.MAE)
                mt.addToHistory(MSE, mt.lastRegressionMetrics.MSE)
                mt.addToHistory(RMSE, mt.lastRegressionMetrics.RMSE)
                mt.addToHistory(R2, mt.lastRegressionMetrics.R2)
                mt.addToHistory(NMAE, mt.lastRegressionMetrics.NMAE)</span>
        }
        
        <span class="cov0" title="0">return nil</span>
}

// GetMetric returns the current value of a specific metric
// CPU-only scalar result (GPU-resident architecture compliant)
func (mt *ModelTrainer) GetMetric(metric MetricType) float64 <span class="cov0" title="0">{
        if !mt.metricsEnabled </span><span class="cov0" title="0">{
                return 0.0
        }</span>
        
        <span class="cov0" title="0">if mt.trainerConfig.ProblemType == Classification </span><span class="cov0" title="0">{
                return mt.confusionMatrix.GetMetric(metric)
        }</span> else<span class="cov0" title="0"> {
                // Regression metrics
                switch metric </span>{
                case MAE:<span class="cov0" title="0">
                        return mt.lastRegressionMetrics.MAE</span>
                case MSE:<span class="cov0" title="0">
                        return mt.lastRegressionMetrics.MSE</span>
                case RMSE:<span class="cov0" title="0">
                        return mt.lastRegressionMetrics.RMSE</span>
                case R2:<span class="cov0" title="0">
                        return mt.lastRegressionMetrics.R2</span>
                case NMAE:<span class="cov0" title="0">
                        return mt.lastRegressionMetrics.NMAE</span>
                default:<span class="cov0" title="0">
                        return 0.0</span>
                }
        }
}

// GetClassificationMetrics returns all classification metrics for the current confusion matrix
func (mt *ModelTrainer) GetClassificationMetrics() map[string]float64 <span class="cov0" title="0">{
        if !mt.metricsEnabled || mt.trainerConfig.ProblemType != Classification </span><span class="cov0" title="0">{
                return make(map[string]float64)
        }</span>
        
        <span class="cov0" title="0">metrics := make(map[string]float64)
        metrics["accuracy"] = mt.confusionMatrix.GetAccuracy()
        
        if mt.confusionMatrix.NumClasses == 2 </span><span class="cov0" title="0">{
                // Binary classification metrics
                metrics["precision"] = mt.confusionMatrix.GetMetric(Precision)
                metrics["recall"] = mt.confusionMatrix.GetMetric(Recall)
                metrics["f1_score"] = mt.confusionMatrix.GetMetric(F1Score)
                metrics["specificity"] = mt.confusionMatrix.GetMetric(Specificity)
                metrics["npv"] = mt.confusionMatrix.GetMetric(NPV)
                
                // Add AUC if available
                if history, exists := mt.metricHistory[AUCROC]; exists &amp;&amp; len(history) &gt; 0 </span><span class="cov0" title="0">{
                        metrics["auc_roc"] = history[len(history)-1]
                }</span>
        } else<span class="cov0" title="0"> {
                // Multi-class metrics
                metrics["macro_precision"] = mt.confusionMatrix.GetMetric(MacroPrecision)
                metrics["macro_recall"] = mt.confusionMatrix.GetMetric(MacroRecall)
                metrics["macro_f1"] = mt.confusionMatrix.GetMetric(MacroF1)
                metrics["micro_precision"] = mt.confusionMatrix.GetMetric(MicroPrecision)
                metrics["micro_recall"] = mt.confusionMatrix.GetMetric(MicroRecall)
                metrics["micro_f1"] = mt.confusionMatrix.GetMetric(MicroF1)
        }</span>
        
        <span class="cov0" title="0">return metrics</span>
}

// GetRegressionMetrics returns all regression metrics
func (mt *ModelTrainer) GetRegressionMetrics() map[string]float64 <span class="cov0" title="0">{
        if !mt.metricsEnabled || mt.trainerConfig.ProblemType != Regression </span><span class="cov0" title="0">{
                return make(map[string]float64)
        }</span>
        
        <span class="cov0" title="0">metrics := make(map[string]float64)
        metrics["mae"] = mt.lastRegressionMetrics.MAE
        metrics["mse"] = mt.lastRegressionMetrics.MSE
        metrics["rmse"] = mt.lastRegressionMetrics.RMSE
        metrics["r2"] = mt.lastRegressionMetrics.R2
        metrics["nmae"] = mt.lastRegressionMetrics.NMAE
        
        return metrics</span>
}

// GetConfusionMatrix returns a copy of the current confusion matrix
func (mt *ModelTrainer) GetConfusionMatrix() [][]int <span class="cov0" title="0">{
        if !mt.metricsEnabled || mt.trainerConfig.ProblemType != Classification </span><span class="cov0" title="0">{
                return nil
        }</span>
        
        // Return a copy to prevent external modification
        <span class="cov0" title="0">matrix := make([][]int, mt.confusionMatrix.NumClasses)
        for i := range matrix </span><span class="cov0" title="0">{
                matrix[i] = make([]int, mt.confusionMatrix.NumClasses)
                copy(matrix[i], mt.confusionMatrix.Matrix[i])
        }</span>
        
        <span class="cov0" title="0">return matrix</span>
}

// GetMetricHistory returns the history of a specific metric for plotting
func (mt *ModelTrainer) GetMetricHistory(metric MetricType) []float64 <span class="cov0" title="0">{
        if !mt.metricsEnabled </span><span class="cov0" title="0">{
                return nil
        }</span>
        
        <span class="cov0" title="0">if history, exists := mt.metricHistory[metric]; exists </span><span class="cov0" title="0">{
                // Return a copy to prevent external modification
                result := make([]float64, len(history))
                copy(result, history)
                return result
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// ResetMetrics clears all accumulated metrics and history
func (mt *ModelTrainer) ResetMetrics() <span class="cov0" title="0">{
        if mt.confusionMatrix != nil </span><span class="cov0" title="0">{
                mt.confusionMatrix.Reset()
        }</span>
        <span class="cov0" title="0">mt.lastRegressionMetrics = &amp;RegressionMetrics{}
        mt.metricHistory = make(map[MetricType][]float64)</span>
}

// addToHistory adds a metric value to the history for plotting
func (mt *ModelTrainer) addToHistory(metric MetricType, value float64) <span class="cov0" title="0">{
        if mt.metricHistory == nil </span><span class="cov0" title="0">{
                mt.metricHistory = make(map[MetricType][]float64)
        }</span>
        
        <span class="cov0" title="0">mt.metricHistory[metric] = append(mt.metricHistory[metric], value)</span>
}

// VISUALIZATION METHODS - GPU-resident architecture compliance
// All visualization methods follow the four core requirements:
// 1. Only CPU access for final scalar metrics collection
// 2. Minimal CGO overhead by batching data collection
// 3. GPU-resident tensors throughout training
// 4. Proper memory management with buffer reuse

// EnableVisualization enables visualization data collection
func (mt *ModelTrainer) EnableVisualization() <span class="cov0" title="0">{
        mt.visualizationEnabled = true
        mt.visualizationCollector.Enable()
        // Reset probability collection when enabling visualization
        mt.resetProbabilityCollection()
}</span>

// DisableVisualization disables visualization data collection
func (mt *ModelTrainer) DisableVisualization() <span class="cov0" title="0">{
        mt.visualizationEnabled = false
        mt.visualizationCollector.Disable()
        // Clear probability buffers to free memory
        mt.validationProbabilities = nil
        mt.validationLabels = nil
        mt.probabilityBatchCount = 0
}</span>

// IsVisualizationEnabled returns whether visualization is enabled
func (mt *ModelTrainer) IsVisualizationEnabled() bool <span class="cov0" title="0">{
        return mt.visualizationEnabled
}</span>

// EnablePlottingService enables the plotting service for sidecar communication
func (mt *ModelTrainer) EnablePlottingService() <span class="cov0" title="0">{
        mt.plottingService.Enable()
}</span>

// DisablePlottingService disables the plotting service
func (mt *ModelTrainer) DisablePlottingService() <span class="cov0" title="0">{
        mt.plottingService.Disable()
}</span>

// ConfigurePlottingService configures the plotting service with custom settings
func (mt *ModelTrainer) ConfigurePlottingService(config PlottingServiceConfig) <span class="cov0" title="0">{
        mt.plottingService = NewPlottingService(config)
}</span>

// CheckPlottingServiceHealth checks if the plotting service is available
func (mt *ModelTrainer) CheckPlottingServiceHealth() error <span class="cov0" title="0">{
        return mt.plottingService.CheckHealth()
}</span>

// RecordTrainingStep records training metrics for visualization
// This method is called internally during training and follows GPU-resident principles
func (mt *ModelTrainer) recordTrainingStep(step int, loss, accuracy float64) <span class="cov0" title="0">{
        if !mt.visualizationEnabled </span><span class="cov0" title="0">{
                return
        }</span>
        
        // Get current learning rate for plotting
        <span class="cov0" title="0">currentLR := float64(mt.getCurrentLearningRate())
        
        // Record step data (CPU-only scalar values)
        mt.visualizationCollector.RecordTrainingStep(step, loss, accuracy, currentLR)</span>
}

// RecordValidationStep records validation metrics for visualization
// This method is called internally during validation and follows GPU-resident principles
func (mt *ModelTrainer) recordValidationStep(step int, loss, accuracy float64) <span class="cov0" title="0">{
        if !mt.visualizationEnabled </span><span class="cov0" title="0">{
                return
        }</span>
        
        // Record validation data (CPU-only scalar values)
        <span class="cov0" title="0">mt.visualizationCollector.RecordValidationStep(step, loss, accuracy)</span>
}

// RecordEpochMetrics records epoch-level metrics for visualization
func (mt *ModelTrainer) RecordEpochMetrics(epoch int, trainLoss, trainAcc, valLoss, valAcc float64) <span class="cov0" title="0">{
        if !mt.visualizationEnabled </span><span class="cov0" title="0">{
                return
        }</span>
        
        <span class="cov0" title="0">mt.visualizationCollector.RecordEpoch(epoch, trainLoss, trainAcc, valLoss, valAcc)</span>
}

// StartValidationPhase prepares for validation by resetting probability collection
func (mt *ModelTrainer) StartValidationPhase() <span class="cov0" title="0">{
        if mt.visualizationEnabled </span><span class="cov0" title="0">{
                mt.resetProbabilityCollection()
        }</span>
}

// RecordMetricsForVisualization records comprehensive metrics for visualization
// This method integrates with the evaluation metrics system
func (mt *ModelTrainer) RecordMetricsForVisualization() <span class="cov0" title="0">{
        if !mt.visualizationEnabled || !mt.metricsEnabled </span><span class="cov0" title="0">{
                return
        }</span>
        
        // Record classification metrics
        <span class="cov0" title="0">if mt.trainerConfig.ProblemType == Classification </span><span class="cov0" title="0">{
                // Record confusion matrix
                confMatrix := mt.GetConfusionMatrix()
                if confMatrix != nil </span><span class="cov0" title="0">{
                        classNames := mt.getClassNames()
                        mt.visualizationCollector.RecordConfusionMatrix(confMatrix, classNames)
                }</span>
                
                // Record ROC data if available
                <span class="cov0" title="0">if mt.confusionMatrix.NumClasses == 2 </span><span class="cov0" title="0">{
                        rocPoints := mt.generateROCPoints()
                        if len(rocPoints) &gt; 0 </span><span class="cov0" title="0">{
                                mt.visualizationCollector.RecordROCData(rocPoints)
                        }</span>
                        
                        // Record Precision-Recall data
                        <span class="cov0" title="0">prPoints := mt.generatePRPoints()
                        if len(prPoints) &gt; 0 </span><span class="cov0" title="0">{
                                mt.visualizationCollector.RecordPRData(prPoints)
                        }</span>
                }
        }
        
        // Record regression metrics
        <span class="cov0" title="0">if mt.trainerConfig.ProblemType == Regression </span>{<span class="cov0" title="0">
                // Note: Regression predictions would need to be stored during training
                // This is a placeholder for when regression visualization is needed
                // mt.visualizationCollector.RecordRegressionData(predictions, trueValues)
        }</span>
}

// GenerateTrainingCurvesPlot generates and returns training curves plot data
func (mt *ModelTrainer) GenerateTrainingCurvesPlot() PlotData <span class="cov0" title="0">{
        return mt.visualizationCollector.GenerateTrainingCurvesPlot()
}</span>

// GenerateLearningRateSchedulePlot generates and returns learning rate schedule plot data
func (mt *ModelTrainer) GenerateLearningRateSchedulePlot() PlotData <span class="cov0" title="0">{
        return mt.visualizationCollector.GenerateLearningRateSchedulePlot()
}</span>

// GenerateROCCurvePlot generates and returns ROC curve plot data
func (mt *ModelTrainer) GenerateROCCurvePlot() PlotData <span class="cov0" title="0">{
        return mt.visualizationCollector.GenerateROCCurvePlot()
}</span>

// GeneratePrecisionRecallPlot generates and returns Precision-Recall curve plot data
func (mt *ModelTrainer) GeneratePrecisionRecallPlot() PlotData <span class="cov0" title="0">{
        return mt.visualizationCollector.GeneratePrecisionRecallPlot()
}</span>

// GenerateConfusionMatrixPlot generates and returns confusion matrix plot data
func (mt *ModelTrainer) GenerateConfusionMatrixPlot() PlotData <span class="cov0" title="0">{
        return mt.visualizationCollector.GenerateConfusionMatrixPlot()
}</span>

// GenerateAllPlots generates all available plots and returns them
func (mt *ModelTrainer) GenerateAllPlots() map[PlotType]PlotData <span class="cov0" title="0">{
        plots := make(map[PlotType]PlotData)
        
        if !mt.visualizationEnabled </span><span class="cov0" title="0">{
                return plots
        }</span>
        
        // Generate all available plots
        <span class="cov0" title="0">plots[TrainingCurves] = mt.visualizationCollector.GenerateTrainingCurvesPlot()
        plots[LearningRateSchedule] = mt.visualizationCollector.GenerateLearningRateSchedulePlot()
        
        if mt.trainerConfig.ProblemType == Classification </span><span class="cov0" title="0">{
                plots[ROCCurve] = mt.visualizationCollector.GenerateROCCurvePlot()
                plots[PrecisionRecall] = mt.visualizationCollector.GeneratePrecisionRecallPlot()
                plots[ConfusionMatrixPlot] = mt.visualizationCollector.GenerateConfusionMatrixPlot()
        }</span>
        
        <span class="cov0" title="0">if mt.trainerConfig.ProblemType == Regression </span><span class="cov0" title="0">{
                plots[RegressionScatter] = mt.visualizationCollector.GenerateRegressionScatterPlot()
                plots[ResidualPlot] = mt.visualizationCollector.GenerateResidualPlot()
        }</span>
        
        <span class="cov0" title="0">return plots</span>
}

// SendPlotToSidecar sends a specific plot to the sidecar plotting service
func (mt *ModelTrainer) SendPlotToSidecar(plotType PlotType) (*PlottingResponse, error) <span class="cov0" title="0">{
        if !mt.visualizationEnabled </span><span class="cov0" title="0">{
                return &amp;PlottingResponse{
                        Success: false,
                        Message: "Visualization is disabled",
                }, nil
        }</span>
        
        <span class="cov0" title="0">return mt.plottingService.GenerateAndSendPlot(mt.visualizationCollector, plotType)</span>
}

// SendAllPlotsToSidecar sends all available plots to the sidecar plotting service
func (mt *ModelTrainer) SendAllPlotsToSidecar() map[PlotType]*PlottingResponse <span class="cov0" title="0">{
        if !mt.visualizationEnabled </span><span class="cov0" title="0">{
                return make(map[PlotType]*PlottingResponse)
        }</span>
        
        <span class="cov0" title="0">return mt.plottingService.GenerateAndSendAllPlots(mt.visualizationCollector)</span>
}

// ClearVisualizationData clears all collected visualization data
func (mt *ModelTrainer) ClearVisualizationData() <span class="cov0" title="0">{
        if mt.visualizationCollector != nil </span><span class="cov0" title="0">{
                mt.visualizationCollector.Clear()
        }</span>
}

// GetVisualizationCollector returns the visualization collector for advanced usage
func (mt *ModelTrainer) GetVisualizationCollector() *VisualizationCollector <span class="cov0" title="0">{
        return mt.visualizationCollector
}</span>

// resetProbabilityCollection resets the probability collection buffers
func (mt *ModelTrainer) resetProbabilityCollection() <span class="cov0" title="0">{
        mt.validationProbabilities = nil
        mt.validationLabels = nil
        mt.probabilityBatchCount = 0
}</span>

// collectValidationProbabilities collects probabilities and labels for PR/ROC curves
// This is GPU-resident compliant: only copies final results from GPU once
func (mt *ModelTrainer) collectValidationProbabilities(predictions []float32, labels []int32, batchSize int, numClasses int) <span class="cov0" title="0">{
        // Only collect if visualization is enabled and we haven't exceeded max batches
        if !mt.visualizationEnabled || mt.probabilityBatchCount &gt;= mt.maxProbabilityBatches </span><span class="cov0" title="0">{
                return
        }</span>
        
        // For binary classification, we need probabilities for the positive class
        // For multi-class, we store all probabilities
        <span class="cov0" title="0">if numClasses == 2 </span><span class="cov0" title="0">{
                // Extract positive class probabilities (class 1)
                positiveProbabilities := make([]float32, batchSize)
                for i := 0; i &lt; batchSize; i++ </span><span class="cov0" title="0">{
                        positiveProbabilities[i] = predictions[i*numClasses + 1]
                }</span>
                <span class="cov0" title="0">mt.validationProbabilities = append(mt.validationProbabilities, positiveProbabilities...)</span>
        } else<span class="cov0" title="0"> {
                // Store all probabilities for multi-class
                mt.validationProbabilities = append(mt.validationProbabilities, predictions[:batchSize*numClasses]...)
        }</span>
        
        // Store corresponding labels
        <span class="cov0" title="0">mt.validationLabels = append(mt.validationLabels, labels[:batchSize]...)
        mt.probabilityBatchCount++</span>
}

// Helper methods for visualization integration

// getClassNames returns class names for visualization
func (mt *ModelTrainer) getClassNames() []string <span class="cov0" title="0">{
        // For binary classification, use standard names
        if mt.confusionMatrix.NumClasses == 2 </span><span class="cov0" title="0">{
                return []string{"Class 0", "Class 1"}
        }</span>
        
        // For multi-class, generate class names
        <span class="cov0" title="0">classNames := make([]string, mt.confusionMatrix.NumClasses)
        for i := range classNames </span><span class="cov0" title="0">{
                classNames[i] = fmt.Sprintf("Class %d", i)
        }</span>
        
        <span class="cov0" title="0">return classNames</span>
}

// generateROCPoints generates ROC curve points from collected probabilities
func (mt *ModelTrainer) generateROCPoints() []ROCPointViz <span class="cov0" title="0">{
        if mt.confusionMatrix.NumClasses != 2 || len(mt.validationProbabilities) == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>
        
        // Create a slice of probability-label pairs for sorting
        <span class="cov0" title="0">type probLabel struct {
                prob  float32
                label int32
        }
        
        pairs := make([]probLabel, len(mt.validationLabels))
        for i := range pairs </span><span class="cov0" title="0">{
                pairs[i] = probLabel{
                        prob:  mt.validationProbabilities[i],
                        label: mt.validationLabels[i],
                }
        }</span>
        
        // Sort by probability in descending order
        <span class="cov0" title="0">sort.Slice(pairs, func(i, j int) bool </span><span class="cov0" title="0">{
                return pairs[i].prob &gt; pairs[j].prob
        }</span>)
        
        // Count total positives and negatives
        <span class="cov0" title="0">totalPositives := 0
        totalNegatives := 0
        for _, pair := range pairs </span><span class="cov0" title="0">{
                if pair.label == 1 </span><span class="cov0" title="0">{
                        totalPositives++
                }</span> else<span class="cov0" title="0"> {
                        totalNegatives++
                }</span>
        }
        
        <span class="cov0" title="0">if totalPositives == 0 || totalNegatives == 0 </span><span class="cov0" title="0">{
                // All samples are of one class
                return nil
        }</span>
        
        // Generate ROC curve points
        <span class="cov0" title="0">var rocPoints []ROCPointViz
        
        // Add the starting point (threshold = 1.0+epsilon)
        rocPoints = append(rocPoints, ROCPointViz{
                FPR:       0.0,
                TPR:       0.0,
                Threshold: 1.0,
        })
        
        truePositives := 0
        falsePositives := 0
        
        // Calculate points at different thresholds
        for i, pair := range pairs </span><span class="cov0" title="0">{
                if pair.label == 1 </span><span class="cov0" title="0">{
                        truePositives++
                }</span> else<span class="cov0" title="0"> {
                        falsePositives++
                }</span>
                
                // Calculate TPR and FPR at this threshold
                <span class="cov0" title="0">tpr := float64(truePositives) / float64(totalPositives)
                fpr := float64(falsePositives) / float64(totalNegatives)
                
                // Add point at regular intervals or when there's a significant change
                if i%10 == 0 || i == len(pairs)-1 || 
                   (i &gt; 0 &amp;&amp; math.Abs(float64(pair.prob - pairs[i-1].prob)) &gt; 0.05) ||
                   (len(rocPoints) &gt; 0 &amp;&amp; (math.Abs(tpr - rocPoints[len(rocPoints)-1].TPR) &gt; 0.01 || 
                                          math.Abs(fpr - rocPoints[len(rocPoints)-1].FPR) &gt; 0.01)) </span><span class="cov0" title="0">{
                        rocPoints = append(rocPoints, ROCPointViz{
                                FPR:       fpr,
                                TPR:       tpr,
                                Threshold: float64(pair.prob),
                        })
                }</span>
        }
        
        // Ensure we have the end point (threshold = 0.0)
        <span class="cov0" title="0">if rocPoints[len(rocPoints)-1].FPR &lt; 1.0 || rocPoints[len(rocPoints)-1].TPR &lt; 1.0 </span><span class="cov0" title="0">{
                rocPoints = append(rocPoints, ROCPointViz{
                        FPR:       1.0,
                        TPR:       1.0,
                        Threshold: 0.0,
                })
        }</span>
        
        <span class="cov0" title="0">return rocPoints</span>
}

// generatePRPoints generates Precision-Recall curve points from collected probabilities
func (mt *ModelTrainer) generatePRPoints() []PRPoint <span class="cov0" title="0">{
        if mt.confusionMatrix.NumClasses != 2 || len(mt.validationProbabilities) == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>
        
        // Create a slice of probability-label pairs for sorting
        <span class="cov0" title="0">type probLabel struct {
                prob  float32
                label int32
        }
        
        pairs := make([]probLabel, len(mt.validationLabels))
        for i := range pairs </span><span class="cov0" title="0">{
                pairs[i] = probLabel{
                        prob:  mt.validationProbabilities[i],
                        label: mt.validationLabels[i],
                }
        }</span>
        
        // Sort by probability in descending order
        <span class="cov0" title="0">sort.Slice(pairs, func(i, j int) bool </span><span class="cov0" title="0">{
                return pairs[i].prob &gt; pairs[j].prob
        }</span>)
        
        // Generate PR curve points at different thresholds
        <span class="cov0" title="0">var prPoints []PRPoint
        totalPositives := 0
        for _, pair := range pairs </span><span class="cov0" title="0">{
                if pair.label == 1 </span><span class="cov0" title="0">{
                        totalPositives++
                }</span>
        }
        
        <span class="cov0" title="0">if totalPositives == 0 || totalPositives == len(pairs) </span><span class="cov0" title="0">{
                // All samples are of one class
                return nil
        }</span>
        
        // Add the starting point (threshold = 1.0)
        <span class="cov0" title="0">prPoints = append(prPoints, PRPoint{
                Precision: 1.0,
                Recall:    0.0,
                Threshold: 1.0,
        })
        
        // Generate points at regular intervals and significant changes
        truePositives := 0
        falsePositives := 0
        
        // Calculate points at different thresholds
        for i, pair := range pairs </span><span class="cov0" title="0">{
                if pair.label == 1 </span><span class="cov0" title="0">{
                        truePositives++
                }</span> else<span class="cov0" title="0"> {
                        falsePositives++
                }</span>
                
                // Calculate precision and recall at this threshold
                <span class="cov0" title="0">predictedPositives := i + 1
                precision := float64(truePositives) / float64(predictedPositives)
                recall := float64(truePositives) / float64(totalPositives)
                
                // Add point at regular intervals or when there's a significant change
                if i%10 == 0 || i == len(pairs)-1 || 
                   (i &gt; 0 &amp;&amp; math.Abs(float64(pair.prob - pairs[i-1].prob)) &gt; 0.05) </span><span class="cov0" title="0">{
                        prPoints = append(prPoints, PRPoint{
                                Precision: precision,
                                Recall:    recall,
                                Threshold: float64(pair.prob),
                        })
                }</span>
        }
        
        // Ensure we have the end point
        <span class="cov0" title="0">if prPoints[len(prPoints)-1].Recall &lt; 1.0 </span><span class="cov0" title="0">{
                prPoints = append(prPoints, PRPoint{
                        Precision: float64(totalPositives) / float64(len(pairs)),
                        Recall:    1.0,
                        Threshold: 0.0,
                })
        }</span>
        
        <span class="cov0" title="0">return prPoints</span>
}

// getCurrentLearningRate returns the current learning rate considering scheduling
func (mt *ModelTrainer) getCurrentLearningRate() float32 <span class="cov0" title="0">{
        if mt.lrScheduler != nil </span><span class="cov0" title="0">{
                return float32(mt.lrScheduler.GetLR(mt.currentEpoch, mt.currentStep, float64(mt.baseLearningRate)))
        }</span>
        <span class="cov0" title="0">return mt.baseLearningRate</span>
}</pre>
		
		<pre class="file" id="file5" style="display: none">package training

import (
        "bytes"
        "encoding/json"
        "fmt"
        "io"
        "net/http"
        "os/exec"
        "runtime"
        "time"
)

// PlottingService handles communication with the sidecar plotting application
type PlottingService struct {
        baseURL    string
        httpClient *http.Client
        enabled    bool
}

// PlottingServiceConfig contains configuration for the plotting service
type PlottingServiceConfig struct {
        BaseURL        string        `json:"base_url"`
        Timeout        time.Duration `json:"timeout"`
        RetryAttempts  int          `json:"retry_attempts"`
        RetryDelay     time.Duration `json:"retry_delay"`
}

// PlottingResponse represents the response from the plotting service
type PlottingResponse struct {
        Success      bool   `json:"success"`
        Message      string `json:"message"`
        PlotURL      string `json:"plot_url,omitempty"`
        ViewURL      string `json:"view_url,omitempty"`
        PlotID       string `json:"plot_id,omitempty"`
        BatchID      string `json:"batch_id,omitempty"`
        DashboardURL string `json:"dashboard_url,omitempty"`
        ErrorCode    string `json:"error_code,omitempty"`
}

// BatchPlottingResponse represents the response from the batch plotting endpoint
type BatchPlottingResponse struct {
        Success      bool                       `json:"success"`
        Message      string                     `json:"message"`
        BatchID      string                     `json:"batch_id,omitempty"`
        Results      []BatchPlotResult          `json:"results,omitempty"`
        DashboardURL string                     `json:"dashboard_url,omitempty"`
        Summary      BatchSummary               `json:"summary,omitempty"`
}

// BatchPlotResult represents a single plot result within a batch response
type BatchPlotResult struct {
        Success   bool   `json:"success"`
        PlotID    string `json:"plot_id,omitempty"`
        PlotURL   string `json:"plot_url,omitempty"`
        ViewURL   string `json:"view_url,omitempty"`
        PlotType  string `json:"plot_type,omitempty"`
        Message   string `json:"message,omitempty"`
        ErrorCode string `json:"error_code,omitempty"`
}

// BatchSummary represents the summary of a batch operation
type BatchSummary struct {
        TotalPlots int `json:"total_plots"`
        Successful int `json:"successful"`
        Failed     int `json:"failed"`
}

// DefaultPlottingServiceConfig returns default configuration for the plotting service
func DefaultPlottingServiceConfig() PlottingServiceConfig <span class="cov8" title="1">{
        return PlottingServiceConfig{
                BaseURL:       "http://localhost:8080",
                Timeout:       30 * time.Second,
                RetryAttempts: 3,
                RetryDelay:    1 * time.Second,
        }
}</span>

// NewPlottingService creates a new plotting service client
func NewPlottingService(config PlottingServiceConfig) *PlottingService <span class="cov8" title="1">{
        return &amp;PlottingService{
                baseURL: config.BaseURL,
                httpClient: &amp;http.Client{
                        Timeout: config.Timeout,
                },
                enabled: false,
        }
}</span>

// Enable enables the plotting service
func (ps *PlottingService) Enable() <span class="cov0" title="0">{
        ps.enabled = true
}</span>

// Disable disables the plotting service
func (ps *PlottingService) Disable() <span class="cov0" title="0">{
        ps.enabled = false
}</span>

// IsEnabled returns whether the plotting service is enabled
func (ps *PlottingService) IsEnabled() bool <span class="cov0" title="0">{
        return ps.enabled
}</span>

// SendPlotData sends plot data to the sidecar plotting service
func (ps *PlottingService) SendPlotData(plotData PlotData) (*PlottingResponse, error) <span class="cov0" title="0">{
        if !ps.enabled </span><span class="cov0" title="0">{
                return &amp;PlottingResponse{
                        Success: false,
                        Message: "Plotting service is disabled",
                }, nil
        }</span>
        
        // Convert plot data to JSON
        <span class="cov0" title="0">jsonData, err := json.Marshal(plotData)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to marshal plot data: %w", err)
        }</span>
        
        // Create HTTP request
        <span class="cov0" title="0">url := fmt.Sprintf("%s/api/plot", ps.baseURL)
        req, err := http.NewRequest("POST", url, bytes.NewBuffer(jsonData))
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create HTTP request: %w", err)
        }</span>
        
        <span class="cov0" title="0">req.Header.Set("Content-Type", "application/json")
        req.Header.Set("User-Agent", "go-metal-training")
        
        // Send request
        resp, err := ps.httpClient.Do(req)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to send HTTP request: %w", err)
        }</span>
        <span class="cov0" title="0">defer resp.Body.Close()
        
        // Read response
        respBody, err := io.ReadAll(resp.Body)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to read response body: %w", err)
        }</span>
        
        // Parse response
        <span class="cov0" title="0">var plotResponse PlottingResponse
        if err := json.Unmarshal(respBody, &amp;plotResponse); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to parse response JSON: %w", err)
        }</span>
        
        // Check HTTP status
        <span class="cov0" title="0">if resp.StatusCode != http.StatusOK </span><span class="cov0" title="0">{
                return &amp;plotResponse, fmt.Errorf("HTTP request failed with status %d: %s", resp.StatusCode, plotResponse.Message)
        }</span>
        
        <span class="cov0" title="0">return &amp;plotResponse, nil</span>
}

// SendPlotDataWithRetry sends plot data with retry logic
func (ps *PlottingService) SendPlotDataWithRetry(plotData PlotData, config PlottingServiceConfig) (*PlottingResponse, error) <span class="cov0" title="0">{
        if !ps.enabled </span><span class="cov0" title="0">{
                return &amp;PlottingResponse{
                        Success: false,
                        Message: "Plotting service is disabled",
                }, nil
        }</span>
        
        <span class="cov0" title="0">var lastErr error
        
        for attempt := 0; attempt &lt; config.RetryAttempts; attempt++ </span><span class="cov0" title="0">{
                resp, err := ps.SendPlotData(plotData)
                if err == nil </span><span class="cov0" title="0">{
                        return resp, nil
                }</span>
                
                <span class="cov0" title="0">lastErr = err
                
                // Wait before retry (except for the last attempt)
                if attempt &lt; config.RetryAttempts-1 </span><span class="cov0" title="0">{
                        time.Sleep(config.RetryDelay)
                }</span>
        }
        
        <span class="cov0" title="0">return nil, fmt.Errorf("failed to send plot data after %d attempts: %w", config.RetryAttempts, lastErr)</span>
}

// CheckHealth checks if the plotting service is available
func (ps *PlottingService) CheckHealth() error <span class="cov0" title="0">{
        if !ps.enabled </span><span class="cov0" title="0">{
                return fmt.Errorf("plotting service is disabled")
        }</span>
        
        <span class="cov0" title="0">url := fmt.Sprintf("%s/health", ps.baseURL)
        req, err := http.NewRequest("GET", url, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create health check request: %w", err)
        }</span>
        
        <span class="cov0" title="0">resp, err := ps.httpClient.Do(req)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to send health check request: %w", err)
        }</span>
        <span class="cov0" title="0">defer resp.Body.Close()
        
        if resp.StatusCode != http.StatusOK </span><span class="cov0" title="0">{
                return fmt.Errorf("health check failed with status %d", resp.StatusCode)
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// GenerateAndSendPlot generates a plot and sends it to the sidecar service
func (ps *PlottingService) GenerateAndSendPlot(collector *VisualizationCollector, plotType PlotType) (*PlottingResponse, error) <span class="cov0" title="0">{
        if !ps.enabled </span><span class="cov0" title="0">{
                return &amp;PlottingResponse{
                        Success: false,
                        Message: "Plotting service is disabled",
                }, nil
        }</span>
        
        <span class="cov0" title="0">var plotData PlotData
        
        switch plotType </span>{
        case TrainingCurves:<span class="cov0" title="0">
                plotData = collector.GenerateTrainingCurvesPlot()</span>
        case LearningRateSchedule:<span class="cov0" title="0">
                plotData = collector.GenerateLearningRateSchedulePlot()</span>
        case ROCCurve:<span class="cov0" title="0">
                plotData = collector.GenerateROCCurvePlot()</span>
        case PrecisionRecall:<span class="cov0" title="0">
                plotData = collector.GeneratePrecisionRecallPlot()</span>
        case ConfusionMatrixPlot:<span class="cov0" title="0">
                plotData = collector.GenerateConfusionMatrixPlot()</span>
        case RegressionScatter:<span class="cov0" title="0">
                plotData = collector.GenerateRegressionScatterPlot()</span>
        case ResidualPlot:<span class="cov0" title="0">
                plotData = collector.GenerateResidualPlot()</span>
        case QQPlot:<span class="cov0" title="0">
                plotData = collector.GenerateQQPlot()</span>
        case FeatureImportancePlot:<span class="cov0" title="0">
                plotData = collector.GenerateFeatureImportancePlot()</span>
        case LearningCurvePlot:<span class="cov0" title="0">
                plotData = collector.GenerateLearningCurvePlot()</span>
        case ValidationCurvePlot:<span class="cov0" title="0">
                plotData = collector.GenerateValidationCurvePlot()</span>
        case PredictionIntervalPlot:<span class="cov0" title="0">
                plotData = collector.GeneratePredictionIntervalPlot()</span>
        case FeatureCorrelationPlot:<span class="cov0" title="0">
                plotData = collector.GenerateFeatureCorrelationPlot()</span>
        case PartialDependencePlot:<span class="cov0" title="0">
                plotData = collector.GeneratePartialDependencePlot()</span>
        default:<span class="cov0" title="0">
                return nil, fmt.Errorf("unsupported plot type: %s", plotType)</span>
        }
        
        // Check if plot data is valid
        <span class="cov0" title="0">if len(plotData.Series) == 0 </span><span class="cov0" title="0">{
                return &amp;PlottingResponse{
                        Success: false,
                        Message: fmt.Sprintf("No data available for plot type: %s", plotType),
                }, nil
        }</span>
        
        <span class="cov0" title="0">return ps.SendPlotData(plotData)</span>
}

// GenerateAndSendAllPlots generates all available plots and sends them to the sidecar service
func (ps *PlottingService) GenerateAndSendAllPlots(collector *VisualizationCollector) map[PlotType]*PlottingResponse <span class="cov0" title="0">{
        results := make(map[PlotType]*PlottingResponse)
        
        if !ps.enabled </span><span class="cov0" title="0">{
                return results
        }</span>
        
        // Define plot types to generate
        <span class="cov0" title="0">plotTypes := []PlotType{
                TrainingCurves,
                LearningRateSchedule,
                ROCCurve,
                PrecisionRecall,
                ConfusionMatrixPlot,
                RegressionScatter,
                ResidualPlot,
                QQPlot,
                FeatureImportancePlot,
                LearningCurvePlot,
                ValidationCurvePlot,
        }
        
        // Generate and send each plot type
        for _, plotType := range plotTypes </span><span class="cov0" title="0">{
                resp, err := ps.GenerateAndSendPlot(collector, plotType)
                if err != nil </span><span class="cov0" title="0">{
                        results[plotType] = &amp;PlottingResponse{
                                Success: false,
                                Message: err.Error(),
                        }
                }</span> else<span class="cov0" title="0"> {
                        results[plotType] = resp
                }</span>
        }
        
        <span class="cov0" title="0">return results</span>
}

// BatchSendPlots sends multiple plots in a single request
func (ps *PlottingService) BatchSendPlots(plotDataList []PlotData) (*BatchPlottingResponse, error) <span class="cov0" title="0">{
        if !ps.enabled </span><span class="cov0" title="0">{
                return &amp;BatchPlottingResponse{
                        Success: false,
                        Message: "Plotting service is disabled",
                }, nil
        }</span>
        
        // Create batch request payload
        <span class="cov0" title="0">batchPayload := map[string]interface{}{
                "plots": plotDataList,
                "batch": true,
        }
        
        // Convert to JSON
        jsonData, err := json.Marshal(batchPayload)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to marshal batch plot data: %w", err)
        }</span>
        
        // Create HTTP request
        <span class="cov0" title="0">url := fmt.Sprintf("%s/api/batch-plot", ps.baseURL)
        req, err := http.NewRequest("POST", url, bytes.NewBuffer(jsonData))
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create batch HTTP request: %w", err)
        }</span>
        
        <span class="cov0" title="0">req.Header.Set("Content-Type", "application/json")
        req.Header.Set("User-Agent", "go-metal-training")
        
        // Send request
        resp, err := ps.httpClient.Do(req)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to send batch HTTP request: %w", err)
        }</span>
        <span class="cov0" title="0">defer resp.Body.Close()
        
        // Read response
        respBody, err := io.ReadAll(resp.Body)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to read batch response body: %w", err)
        }</span>
        
        // Debug: Print raw response
        // fmt.Printf("🔍 Debug: Raw batch response: %s\n", string(respBody))
        
        // Parse response as batch response
        <span class="cov0" title="0">var batchResponse BatchPlottingResponse
        if err := json.Unmarshal(respBody, &amp;batchResponse); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to parse batch response JSON: %w", err)
        }</span>
        
        // Check HTTP status
        <span class="cov0" title="0">if resp.StatusCode != http.StatusOK </span><span class="cov0" title="0">{
                return &amp;batchResponse, fmt.Errorf("batch HTTP request failed with status %d: %s", resp.StatusCode, batchResponse.Message)
        }</span>
        
        <span class="cov0" title="0">return &amp;batchResponse, nil</span>
}

// OpenInBrowser opens the given URL in the default web browser
// It automatically detects the operating system and uses the appropriate command
func (ps *PlottingService) OpenInBrowser(url string) error <span class="cov0" title="0">{
        var cmd string
        var args []string
        
        switch runtime.GOOS </span>{
        case "darwin":<span class="cov0" title="0"> // macOS
                cmd = "open"
                args = []string{url}</span>
        case "windows":<span class="cov0" title="0">
                cmd = "cmd"
                args = []string{"/c", "start", url}</span>
        case "linux":<span class="cov0" title="0">
                // Try xdg-open first (most common), fallback to other options
                cmd = "xdg-open"
                args = []string{url}</span>
        default:<span class="cov0" title="0">
                return fmt.Errorf("unsupported operating system: %s", runtime.GOOS)</span>
        }
        
        <span class="cov0" title="0">err := exec.Command(cmd, args...).Start()
        if err != nil &amp;&amp; runtime.GOOS == "linux" </span><span class="cov0" title="0">{
                // If xdg-open fails on Linux, try alternatives
                alternatives := []string{"gnome-open", "kde-open", "firefox", "google-chrome", "chromium"}
                for _, alt := range alternatives </span><span class="cov0" title="0">{
                        if err = exec.Command(alt, url).Start(); err == nil </span><span class="cov0" title="0">{
                                return nil
                        }</span>
                }
        }
        
        <span class="cov0" title="0">return err</span>
}

// SendPlotDataAndOpen sends plot data and automatically opens the result in browser
func (ps *PlottingService) SendPlotDataAndOpen(plotData PlotData) (*PlottingResponse, error) <span class="cov0" title="0">{
        resp, err := ps.SendPlotData(plotData)
        if err != nil </span><span class="cov0" title="0">{
                return resp, err
        }</span>
        
        <span class="cov0" title="0">if resp.Success </span><span class="cov0" title="0">{
                // Prefer ViewURL over PlotURL for better formatted display
                urlPath := resp.ViewURL
                if urlPath == "" </span><span class="cov0" title="0">{
                        urlPath = resp.PlotURL
                }</span>
                
                <span class="cov0" title="0">if urlPath != "" </span><span class="cov0" title="0">{
                        fullURL := fmt.Sprintf("%s%s", ps.baseURL, urlPath)
                        if err := ps.OpenInBrowser(fullURL); err != nil </span><span class="cov0" title="0">{
                                // Don't fail the whole operation if browser opening fails
                                fmt.Printf("Warning: Failed to open browser automatically: %v\n", err)
                                fmt.Printf("Please open manually: %s\n", fullURL)
                        }</span>
                }
        }
        
        <span class="cov0" title="0">return resp, nil</span>
}

// GenerateAndSendAllPlotsWithBrowser generates all plots using batch endpoint and opens dashboard
func (ps *PlottingService) GenerateAndSendAllPlotsWithBrowser(collector *VisualizationCollector) map[PlotType]*PlottingResponse <span class="cov0" title="0">{
        if !ps.enabled </span><span class="cov0" title="0">{
                return make(map[PlotType]*PlottingResponse)
        }</span>
        
        // Generate all plot data first
        <span class="cov0" title="0">plotTypes := []PlotType{
                TrainingCurves,
                LearningRateSchedule,
                ROCCurve,
                PrecisionRecall,
                ConfusionMatrixPlot,
                RegressionScatter,
                ResidualPlot,
                QQPlot,
                FeatureImportancePlot,
                LearningCurvePlot,
                ValidationCurvePlot,
        }
        
        var plotDataList []PlotData
        results := make(map[PlotType]*PlottingResponse)
        
        // Collect plot data for successful plots
        for _, plotType := range plotTypes </span><span class="cov0" title="0">{
                var plotData PlotData
                
                switch plotType </span>{
                case TrainingCurves:<span class="cov0" title="0">
                        plotData = collector.GenerateTrainingCurvesPlot()</span>
                case LearningRateSchedule:<span class="cov0" title="0">
                        plotData = collector.GenerateLearningRateSchedulePlot()</span>
                case ROCCurve:<span class="cov0" title="0">
                        plotData = collector.GenerateROCCurvePlot()</span>
                case PrecisionRecall:<span class="cov0" title="0">
                        plotData = collector.GeneratePrecisionRecallPlot()</span>
                case ConfusionMatrixPlot:<span class="cov0" title="0">
                        plotData = collector.GenerateConfusionMatrixPlot()</span>
                case RegressionScatter:<span class="cov0" title="0">
                        plotData = collector.GenerateRegressionScatterPlot()</span>
                case ResidualPlot:<span class="cov0" title="0">
                        plotData = collector.GenerateResidualPlot()</span>
                case QQPlot:<span class="cov0" title="0">
                        plotData = collector.GenerateQQPlot()</span>
                case FeatureImportancePlot:<span class="cov0" title="0">
                        plotData = collector.GenerateFeatureImportancePlot()</span>
                case LearningCurvePlot:<span class="cov0" title="0">
                        plotData = collector.GenerateLearningCurvePlot()</span>
                case ValidationCurvePlot:<span class="cov0" title="0">
                        plotData = collector.GenerateValidationCurvePlot()</span>
                case PredictionIntervalPlot:<span class="cov0" title="0">
                        plotData = collector.GeneratePredictionIntervalPlot()</span>
                case FeatureCorrelationPlot:<span class="cov0" title="0">
                        plotData = collector.GenerateFeatureCorrelationPlot()</span>
                case PartialDependencePlot:<span class="cov0" title="0">
                        plotData = collector.GeneratePartialDependencePlot()</span>
                default:<span class="cov0" title="0">
                        results[plotType] = &amp;PlottingResponse{
                                Success: false,
                                Message: fmt.Sprintf("Unsupported plot type: %s", plotType),
                        }
                        continue</span>
                }
                
                // Check if plot data is valid
                <span class="cov0" title="0">if len(plotData.Series) == 0 </span><span class="cov0" title="0">{
                        results[plotType] = &amp;PlottingResponse{
                                Success: false,
                                Message: fmt.Sprintf("No data available for plot type: %s", plotType),
                        }
                }</span> else<span class="cov0" title="0"> {
                        plotDataList = append(plotDataList, plotData)
                        // Don't mark as successful yet - wait for actual batch response
                        results[plotType] = &amp;PlottingResponse{
                                Success: false,
                                Message: "Prepared for batch sending",
                        }
                }</span>
        }
        
        // Send as batch if we have any plots
        <span class="cov0" title="0">if len(plotDataList) &gt; 0 </span><span class="cov0" title="0">{
                batchResp, err := ps.BatchSendPlots(plotDataList)
                if err != nil </span><span class="cov0" title="0">{
                        fmt.Printf("Failed to send batch plots: %v\n", err)
                        // Mark all prepared plots as failed
                        for plotType, result := range results </span><span class="cov0" title="0">{
                                if result.Message == "Prepared for batch sending" </span><span class="cov0" title="0">{
                                        results[plotType] = &amp;PlottingResponse{
                                                Success: false,
                                                Message: fmt.Sprintf("Batch send failed: %v", err),
                                        }
                                }</span>
                        }
                        <span class="cov0" title="0">return results</span>
                }
                
                <span class="cov0" title="0">if batchResp.Success </span><span class="cov0" title="0">{
                        fmt.Printf("✅ Successfully sent %d plots to sidecar (batch ID: %s)\n", batchResp.Summary.Successful, batchResp.BatchID)
                        fmt.Printf("🔍 Debug: Dashboard URL from response: '%s'\n", batchResp.DashboardURL)
                        
                        // Map batch results back to our plot types
                        plotTypeIndex := 0
                        for plotType, result := range results </span><span class="cov0" title="0">{
                                if result.Message == "Prepared for batch sending" </span><span class="cov0" title="0">{
                                        if plotTypeIndex &lt; len(batchResp.Results) </span><span class="cov0" title="0">{
                                                batchResult := batchResp.Results[plotTypeIndex]
                                                results[plotType] = &amp;PlottingResponse{
                                                        Success:      batchResult.Success,
                                                        Message:      "Successfully sent in batch",
                                                        PlotID:       batchResult.PlotID,
                                                        PlotURL:      batchResult.PlotURL,
                                                        ViewURL:      batchResult.ViewURL,
                                                        BatchID:      batchResp.BatchID,
                                                        DashboardURL: batchResp.DashboardURL,
                                                }
                                                plotTypeIndex++
                                        }</span>
                                }
                        }
                        
                        // Try to open dashboard if available
                        <span class="cov0" title="0">if batchResp.DashboardURL != "" </span><span class="cov0" title="0">{
                                dashboardURL := fmt.Sprintf("%s%s", ps.baseURL, batchResp.DashboardURL)
                                fmt.Printf("🔍 Debug: Full dashboard URL: '%s'\n", dashboardURL)
                                if err := ps.OpenInBrowser(dashboardURL); err != nil </span><span class="cov0" title="0">{
                                        fmt.Printf("Warning: Failed to open dashboard automatically: %v\n", err)
                                        fmt.Printf("Please open manually: %s\n", dashboardURL)
                                }</span> else<span class="cov0" title="0"> {
                                        fmt.Println("🌐 Dashboard opened in browser")
                                }</span>
                        } else<span class="cov0" title="0"> {
                                fmt.Printf("📊 No dashboard URL returned - checking individual plots\n")
                                
                                // If no dashboard, try to open the first successful individual plot
                                for _, result := range results </span><span class="cov0" title="0">{
                                        if result.Success &amp;&amp; result.ViewURL != "" </span><span class="cov0" title="0">{
                                                plotURL := fmt.Sprintf("%s%s", ps.baseURL, result.ViewURL)
                                                fmt.Printf("🔍 Debug: Opening individual plot: %s\n", plotURL)
                                                if err := ps.OpenInBrowser(plotURL); err != nil </span><span class="cov0" title="0">{
                                                        fmt.Printf("Warning: Failed to open plot automatically: %v\n", err)
                                                }</span> else<span class="cov0" title="0"> {
                                                        fmt.Println("🌐 First plot opened in browser")
                                                        break</span>
                                                }
                                        }
                                }
                        }
                } else<span class="cov0" title="0"> {
                        fmt.Printf("Failed to generate batch plots: %s\n", batchResp.Message)
                        // Mark all prepared plots as failed
                        for plotType, result := range results </span><span class="cov0" title="0">{
                                if result.Message == "Prepared for batch sending" </span><span class="cov0" title="0">{
                                        results[plotType] = &amp;PlottingResponse{
                                                Success: false,
                                                Message: fmt.Sprintf("Batch generation failed: %s", batchResp.Message),
                                        }
                                }</span>
                        }
                }
        } else<span class="cov0" title="0"> {
                fmt.Println("No valid plots to display")
        }</span>
        
        <span class="cov0" title="0">return results</span>
}</pre>
		
		<pre class="file" id="file6" style="display: none">package training

import (
        "fmt"
        "strings"
        "time"

        "github.com/tsawler/go-metal/layers"
)

// ProgressBar provides PyTorch-style training progress visualization
type ProgressBar struct {
        description string
        total       int
        current     int
        startTime   time.Time
        width       int
        showRate    bool
        showETA     bool
        metrics     map[string]float64
}

// NewProgressBar creates a new progress bar
func NewProgressBar(description string, total int) *ProgressBar <span class="cov8" title="1">{
        return &amp;ProgressBar{
                description: description,
                total:       total,
                current:     0,
                startTime:   time.Now(),
                width:       70, // Character width of progress bar
                showRate:    true,
                showETA:     true,
                metrics:     make(map[string]float64),
        }
}</span>

// Update advances the progress bar
func (pb *ProgressBar) Update(step int, metrics map[string]float64) <span class="cov8" title="1">{
        pb.current = step
        pb.metrics = metrics
        pb.render()
}</span>

// UpdateMetrics updates metrics without advancing progress
func (pb *ProgressBar) UpdateMetrics(metrics map[string]float64) <span class="cov0" title="0">{
        for k, v := range metrics </span><span class="cov0" title="0">{
                pb.metrics[k] = v
        }</span>
        <span class="cov0" title="0">pb.render()</span>
}

// Finish completes the progress bar
func (pb *ProgressBar) Finish() <span class="cov8" title="1">{
        pb.current = pb.total
        pb.render()
        fmt.Println() // New line after completion
}</span>

// render draws the progress bar
func (pb *ProgressBar) render() <span class="cov8" title="1">{
        // Calculate progress percentage
        percentage := float64(pb.current) / float64(pb.total)
        if percentage &gt; 1.0 </span><span class="cov0" title="0">{
                percentage = 1.0
        }</span>

        // Calculate filled width
        <span class="cov8" title="1">filled := int(percentage * float64(pb.width))
        if filled &gt; pb.width </span><span class="cov0" title="0">{
                filled = pb.width
        }</span>

        // Build progress bar string
        <span class="cov8" title="1">bar := strings.Repeat("█", filled) + strings.Repeat(" ", pb.width-filled)

        // Calculate timing information
        elapsed := time.Since(pb.startTime)
        var eta time.Duration
        var rate float64

        if pb.current &gt; 0 </span><span class="cov8" title="1">{
                rate = float64(pb.current) / elapsed.Seconds()
                if percentage &gt; 0 </span><span class="cov8" title="1">{
                        totalTime := time.Duration(float64(elapsed) / percentage)
                        eta = totalTime - elapsed
                }</span>
        }

        // Format the progress line
        <span class="cov8" title="1">line := fmt.Sprintf("\r%s: %3.0f%%|%s| %d/%d",
                pb.description,
                percentage*100,
                bar,
                pb.current,
                pb.total,
        )

        // Add timing information
        if pb.showETA &amp;&amp; eta &gt; 0 </span><span class="cov8" title="1">{
                line += fmt.Sprintf(" [%s&lt;%s",
                        formatDuration(elapsed),
                        formatDuration(eta),
                )
        }</span> else<span class="cov8" title="1"> {
                line += fmt.Sprintf(" [%s&lt;00:00",
                        formatDuration(elapsed),
                )
        }</span>

        // Add rate information
        <span class="cov8" title="1">if pb.showRate &amp;&amp; rate &gt; 0 </span><span class="cov8" title="1">{
                line += fmt.Sprintf(", %.2fbatch/s", rate)
        }</span>

        // Add metrics
        <span class="cov8" title="1">for key, value := range pb.metrics </span><span class="cov8" title="1">{
                if strings.Contains(key, "accuracy") || strings.Contains(key, "acc") </span><span class="cov8" title="1">{
                        line += fmt.Sprintf(", %s=%.2f%%", key, value*100)
                }</span> else<span class="cov8" title="1"> {
                        line += fmt.Sprintf(", %s=%.3f", key, value)
                }</span>
        }

        <span class="cov8" title="1">line += "]"

        // Print the line (carriage return overwrites previous line)
        fmt.Print(line)</span>
}

// formatDuration formats duration as MM:SS
func formatDuration(d time.Duration) string <span class="cov8" title="1">{
        minutes := int(d.Minutes())
        seconds := int(d.Seconds()) % 60
        return fmt.Sprintf("%02d:%02d", minutes, seconds)
}</span>

// ModelArchitecturePrinter prints PyTorch-style model architecture
type ModelArchitecturePrinter struct {
        modelName string
}

// NewModelArchitecturePrinter creates a new model architecture printer
func NewModelArchitecturePrinter(modelName string) *ModelArchitecturePrinter <span class="cov8" title="1">{
        return &amp;ModelArchitecturePrinter{
                modelName: modelName,
        }
}</span>

// PrintArchitecture prints the model architecture in PyTorch style
func (p *ModelArchitecturePrinter) PrintArchitecture(modelSpec *layers.ModelSpec) <span class="cov8" title="1">{
        fmt.Printf("Model Architecture:\n")
        fmt.Printf("%s(\n", p.modelName)

        for i, layer := range modelSpec.Layers </span><span class="cov8" title="1">{
                layerStr := p.formatLayer(layer, i)
                fmt.Printf("  %s\n", layerStr)
        }</span>

        <span class="cov8" title="1">fmt.Printf(")\n\n")

        // Print parameter summary
        fmt.Printf("Total parameters: %s\n", formatParameterCount(modelSpec.TotalParameters))
        fmt.Printf("Trainable parameters: %s\n", formatParameterCount(modelSpec.TotalParameters)) // Assuming all are trainable
        fmt.Printf("Non-trainable parameters: 0\n")
        fmt.Printf("Input size (MB): %.3f\n", calculateInputSize(modelSpec.InputShape))
        fmt.Printf("Forward/backward pass size (MB): %.3f\n", estimateForwardBackwardSize(modelSpec))
        fmt.Printf("Params size (MB): %.3f\n", float64(modelSpec.TotalParameters*4)/1024/1024) // 4 bytes per float32
        fmt.Printf("Estimated Total Size (MB): %.3f\n\n", estimateTotalSize(modelSpec))</span>
}

// formatLayer formats a single layer for display
func (p *ModelArchitecturePrinter) formatLayer(layer layers.LayerSpec, index int) string <span class="cov8" title="1">{
        switch layer.Type </span>{
        case layers.Conv2D:<span class="cov8" title="1">
                return p.formatConv2D(layer)</span>
        case layers.Dense:<span class="cov8" title="1">
                return p.formatDense(layer)</span>
        case layers.ReLU:<span class="cov8" title="1">
                return fmt.Sprintf("(%s): ReLU()", layer.Name)</span>
        case layers.Softmax:<span class="cov8" title="1">
                axis := layer.Parameters["axis"].(int)
                return fmt.Sprintf("(%s): Softmax(dim=%d)", layer.Name, axis)</span>
        default:<span class="cov0" title="0">
                return fmt.Sprintf("(%s): %s()", layer.Name, layer.Type.String())</span>
        }
}

// formatConv2D formats a Conv2D layer
func (p *ModelArchitecturePrinter) formatConv2D(layer layers.LayerSpec) string <span class="cov8" title="1">{
        inChannels := layer.Parameters["input_channels"].(int)
        outChannels := layer.Parameters["output_channels"].(int)
        kernelSize := layer.Parameters["kernel_size"].(int)
        stride := layer.Parameters["stride"].(int)
        padding := layer.Parameters["padding"].(int)
        useBias := layer.Parameters["use_bias"].(bool)

        return fmt.Sprintf("(%s): Conv2d(%d, %d, kernel_size=(%d, %d), stride=(%d, %d), padding=(%d, %d), bias=%t)",
                layer.Name, inChannels, outChannels, kernelSize, kernelSize, stride, stride, padding, padding, useBias)
}</span>

// formatDense formats a Dense/Linear layer
func (p *ModelArchitecturePrinter) formatDense(layer layers.LayerSpec) string <span class="cov8" title="1">{
        inFeatures := layer.Parameters["input_size"].(int)
        outFeatures := layer.Parameters["output_size"].(int)
        useBias := layer.Parameters["use_bias"].(bool)

        return fmt.Sprintf("(%s): Linear(in_features=%d, out_features=%d, bias=%t)",
                layer.Name, inFeatures, outFeatures, useBias)
}</span>

// formatParameterCount formats parameter count with K/M suffixes
func formatParameterCount(count int64) string <span class="cov8" title="1">{
        if count &gt;= 1000000 </span><span class="cov8" title="1">{
                return fmt.Sprintf("%.1fM", float64(count)/1000000.0)
        }</span> else<span class="cov8" title="1"> if count &gt;= 1000 </span><span class="cov8" title="1">{
                return fmt.Sprintf("%.1fK", float64(count)/1000.0)
        }</span>
        <span class="cov0" title="0">return fmt.Sprintf("%d", count)</span>
}

// calculateInputSize estimates input tensor size in MB
func calculateInputSize(inputShape []int) float64 <span class="cov8" title="1">{
        size := 1
        for _, dim := range inputShape </span><span class="cov8" title="1">{
                size *= dim
        }</span>
        <span class="cov8" title="1">return float64(size*4) / 1024 / 1024</span> // 4 bytes per float32
}

// estimateForwardBackwardSize estimates forward/backward pass memory usage
func estimateForwardBackwardSize(modelSpec *layers.ModelSpec) float64 <span class="cov8" title="1">{
        // Rough estimate: 2x forward pass memory for activations + gradients
        inputSize := calculateInputSize(modelSpec.InputShape)
        outputSize := calculateInputSize(modelSpec.OutputShape)
        
        // Estimate intermediate activations (rough heuristic)
        maxIntermediateSize := inputSize
        for _, layer := range modelSpec.Layers </span><span class="cov8" title="1">{
                if len(layer.OutputShape) &gt; 0 </span><span class="cov8" title="1">{
                        layerSize := calculateInputSize(layer.OutputShape)
                        if layerSize &gt; maxIntermediateSize </span><span class="cov8" title="1">{
                                maxIntermediateSize = layerSize
                        }</span>
                }
        }
        
        <span class="cov8" title="1">return (inputSize + outputSize + maxIntermediateSize) * 2</span> // 2x for forward + backward
}

// estimateTotalSize estimates total model memory usage
func estimateTotalSize(modelSpec *layers.ModelSpec) float64 <span class="cov8" title="1">{
        inputSize := calculateInputSize(modelSpec.InputShape)
        paramsSize := float64(modelSpec.TotalParameters*4) / 1024 / 1024
        forwardBackwardSize := estimateForwardBackwardSize(modelSpec)
        
        return inputSize + paramsSize + forwardBackwardSize
}</span>

// TrainingSession manages a complete training session with progress visualization
type TrainingSession struct {
        trainer           *ModelTrainer
        modelName         string
        epochs            int
        stepsPerEpoch     int
        validationSteps   int
        currentEpoch      int
        architecturePrinter *ModelArchitecturePrinter
        
        // Progress tracking
        trainProgress     *ProgressBar
        validationProgress *ProgressBar
        
        // Metrics tracking
        trainLoss         float64
        trainAccuracy     float64
        validationLoss    float64
        validationAccuracy float64
}

// NewTrainingSession creates a new training session with progress visualization
func NewTrainingSession(
        trainer *ModelTrainer,
        modelName string,
        epochs int,
        stepsPerEpoch int,
        validationSteps int,
) *TrainingSession <span class="cov8" title="1">{
        return &amp;TrainingSession{
                trainer:           trainer,
                modelName:         modelName,
                epochs:            epochs,
                stepsPerEpoch:     stepsPerEpoch,
                validationSteps:   validationSteps,
                currentEpoch:      0,
                architecturePrinter: NewModelArchitecturePrinter(modelName),
        }
}</span>

// StartTraining begins the training session with model architecture display
func (ts *TrainingSession) StartTraining() <span class="cov8" title="1">{
        // Print model architecture
        ts.architecturePrinter.PrintArchitecture(ts.trainer.GetModelSpec())
        
        fmt.Println("Starting training...")
}</span>

// StartEpoch begins a new epoch
func (ts *TrainingSession) StartEpoch(epoch int) <span class="cov8" title="1">{
        ts.currentEpoch = epoch
        
        // Create training progress bar
        description := fmt.Sprintf("Epoch %d/%d (Training)", epoch, ts.epochs)
        ts.trainProgress = NewProgressBar(description, ts.stepsPerEpoch)
}</span>

// UpdateTrainingProgress updates training progress
func (ts *TrainingSession) UpdateTrainingProgress(step int, loss float64, accuracy float64) <span class="cov8" title="1">{
        ts.trainLoss = loss
        ts.trainAccuracy = accuracy
        
        metrics := map[string]float64{
                "loss": loss,
        }
        
        if accuracy &gt;= 0 </span><span class="cov8" title="1">{
                metrics["accuracy"] = accuracy
        }</span>
        
        <span class="cov8" title="1">ts.trainProgress.Update(step, metrics)</span>
}

// FinishTrainingEpoch completes the training phase of an epoch
func (ts *TrainingSession) FinishTrainingEpoch() <span class="cov8" title="1">{
        ts.trainProgress.Finish()
}</span>

// StartValidation begins the validation phase
func (ts *TrainingSession) StartValidation() <span class="cov8" title="1">{
        if ts.validationSteps &lt;= 0 </span><span class="cov0" title="0">{
                return
        }</span>
        
        <span class="cov8" title="1">description := fmt.Sprintf("Epoch %d/%d (Validation)", ts.currentEpoch, ts.epochs)
        ts.validationProgress = NewProgressBar(description, ts.validationSteps)</span>
}

// UpdateValidationProgress updates validation progress
func (ts *TrainingSession) UpdateValidationProgress(step int, loss float64, accuracy float64) <span class="cov8" title="1">{
        ts.validationLoss = loss
        ts.validationAccuracy = accuracy
        
        metrics := map[string]float64{
                "loss": loss,
        }
        
        if accuracy &gt;= 0 </span><span class="cov8" title="1">{
                metrics["accuracy"] = accuracy
        }</span>
        
        <span class="cov8" title="1">ts.validationProgress.Update(step, metrics)</span>
}

// FinishValidationEpoch completes the validation phase of an epoch
func (ts *TrainingSession) FinishValidationEpoch() <span class="cov8" title="1">{
        if ts.validationProgress != nil </span><span class="cov8" title="1">{
                ts.validationProgress.Finish()
        }</span>
}

// PrintEpochSummary prints a summary of the completed epoch
func (ts *TrainingSession) PrintEpochSummary() <span class="cov8" title="1">{
        fmt.Printf("Epoch %d/%d Summary:\n", ts.currentEpoch, ts.epochs)
        fmt.Printf("  Training   - Loss: %.4f", ts.trainLoss)
        
        if ts.trainAccuracy &gt;= 0 </span><span class="cov8" title="1">{
                fmt.Printf(", Accuracy: %.2f%%", ts.trainAccuracy*100)
        }</span>
        <span class="cov8" title="1">fmt.Println()
        
        if ts.validationSteps &gt; 0 </span><span class="cov8" title="1">{
                fmt.Printf("  Validation - Loss: %.4f", ts.validationLoss)
                if ts.validationAccuracy &gt;= 0 </span><span class="cov8" title="1">{
                        fmt.Printf(", Accuracy: %.2f%%", ts.validationAccuracy*100)
                }</span>
                <span class="cov8" title="1">fmt.Println()</span>
        }
        
        <span class="cov8" title="1">fmt.Println()</span>
}</pre>
		
		<pre class="file" id="file7" style="display: none">package training

import (
        "fmt"
        "math/rand"
        "time"

        "github.com/tsawler/go-metal/cgo_bridge"
        "github.com/tsawler/go-metal/layers"
)

// TrainingExample demonstrates the PyTorch-style progress bar in action
func TrainingExample() error <span class="cov0" title="0">{
        fmt.Println("=== Go-Metal Training with Progress Visualization ===")
        
        // Create a CNN model similar to the PyTorch example
        inputShape := []int{32, 3, 32, 32} // CIFAR-10 style input
        builder := layers.NewModelBuilder(inputShape)
        
        model, err := builder.
                AddConv2D(32, 3, 1, 1, true, "conv1").
                AddConv2D(64, 3, 1, 1, true, "conv2").
                AddConv2D(128, 3, 1, 1, true, "conv3").
                AddDense(512, true, "fc1").
                AddReLU("relu").
                AddDense(2, true, "fc2"). // Binary classification (cats vs dogs)
                Compile()
        
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to compile model: %v", err)
        }</span>
        
        // Create trainer configuration
        <span class="cov0" title="0">config := TrainerConfig{
                BatchSize:       32,
                LearningRate:    0.001,
                OptimizerType:   cgo_bridge.Adam,
                UseHybridEngine: true,
                Beta1:           0.9,
                Beta2:           0.999,
                Epsilon:         1e-8,
                WeightDecay:     0.0001,
        }
        
        // Create model trainer
        trainer, err := NewModelTrainer(model, config)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create trainer: %v", err)
        }</span>
        <span class="cov0" title="0">defer trainer.Cleanup()
        
        // Training parameters
        epochs := 3
        stepsPerEpoch := 620    // Simulating CIFAR-10 training set size
        validationSteps := 155  // Simulating CIFAR-10 test set size
        
        // Create training session with progress visualization
        session := NewTrainingSession(trainer, "CatDogCNN", epochs, stepsPerEpoch, validationSteps)
        
        // Start training (displays model architecture)
        session.StartTraining()
        
        // Training loop
        for epoch := 1; epoch &lt;= epochs; epoch++ </span><span class="cov0" title="0">{
                // Start epoch
                session.StartEpoch(epoch)
                
                // Training phase
                trainLoss := 0.0
                trainAccuracy := 0.0
                
                for step := 1; step &lt;= stepsPerEpoch; step++ </span><span class="cov0" title="0">{
                        // Simulate training step
                        result, err := simulateTrainingStep(trainer, config.BatchSize)
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("training step failed: %v", err)
                        }</span>
                        
                        // Update running metrics
                        <span class="cov0" title="0">trainLoss = 0.9*trainLoss + 0.1*float64(result.Loss)
                        trainAccuracy = 0.9*trainAccuracy + 0.1*simulateAccuracy(epoch, step, stepsPerEpoch)
                        
                        // Update progress
                        session.UpdateTrainingProgress(step, trainLoss, trainAccuracy)
                        
                        // Small delay to simulate realistic training speed
                        time.Sleep(time.Millisecond * 5)</span>
                }
                
                <span class="cov0" title="0">session.FinishTrainingEpoch()
                
                // Validation phase
                session.StartValidation()
                
                validationLoss := 0.0
                validationAccuracy := 0.0
                
                for step := 1; step &lt;= validationSteps; step++ </span><span class="cov0" title="0">{
                        // Simulate validation step (faster than training)
                        validationLoss = 0.9*validationLoss + 0.1*simulateValidationLoss(epoch, step)
                        validationAccuracy = 0.9*validationAccuracy + 0.1*simulateValidationAccuracy(epoch, step, validationSteps)
                        
                        // Update progress
                        session.UpdateValidationProgress(step, validationLoss, validationAccuracy)
                        
                        // Smaller delay for validation
                        time.Sleep(time.Millisecond * 2)
                }</span>
                
                <span class="cov0" title="0">session.FinishValidationEpoch()
                
                // Print epoch summary
                session.PrintEpochSummary()</span>
        }
        
        <span class="cov0" title="0">fmt.Println("Training completed successfully!")
        
        return nil</span>
}

// simulateTrainingStep simulates a real training step
func simulateTrainingStep(trainer *ModelTrainer, batchSize int) (*TrainingResult, error) <span class="cov0" title="0">{
        // Create dummy data
        inputShape := []int{batchSize, 3, 32, 32}
        inputData := make([]float32, batchSize*3*32*32)
        labelData := make([]int32, batchSize)
        
        // Fill with random data
        for i := range inputData </span><span class="cov0" title="0">{
                inputData[i] = rand.Float32()
        }</span>
        <span class="cov0" title="0">for i := range labelData </span><span class="cov0" title="0">{
                labelData[i] = int32(rand.Intn(2))
        }</span>
        
        // Execute training step
        <span class="cov0" title="0">return trainer.TrainBatch(inputData, inputShape, labelData, []int{batchSize})</span>
}

// simulateAccuracy simulates improving accuracy over training
func simulateAccuracy(epoch, step, totalSteps int) float64 <span class="cov0" title="0">{
        // Simulate accuracy improving over time
        progress := float64(epoch-1) + float64(step)/float64(totalSteps)
        baseAccuracy := 0.5 + 0.3*progress/3.0 // Improve from 50% to 80% over 3 epochs
        
        // Add some noise
        noise := (rand.Float64() - 0.5) * 0.1
        accuracy := baseAccuracy + noise
        
        // Clamp to reasonable range
        if accuracy &lt; 0.4 </span><span class="cov0" title="0">{
                accuracy = 0.4
        }</span>
        <span class="cov0" title="0">if accuracy &gt; 0.9 </span><span class="cov0" title="0">{
                accuracy = 0.9
        }</span>
        
        <span class="cov0" title="0">return accuracy</span>
}

// simulateValidationLoss simulates validation loss
func simulateValidationLoss(epoch, step int) float64 <span class="cov0" title="0">{
        // Start higher and decrease
        baseLoss := 1.5 - 0.3*float64(epoch-1)
        noise := (rand.Float64() - 0.5) * 0.2
        loss := baseLoss + noise
        
        if loss &lt; 0.3 </span><span class="cov0" title="0">{
                loss = 0.3
        }</span>
        <span class="cov0" title="0">if loss &gt; 2.0 </span><span class="cov0" title="0">{
                loss = 2.0
        }</span>
        
        <span class="cov0" title="0">return loss</span>
}

// simulateValidationAccuracy simulates validation accuracy
func simulateValidationAccuracy(epoch, step, totalSteps int) float64 <span class="cov0" title="0">{
        // Simulate accuracy improving over epochs
        progress := float64(epoch-1) + float64(step)/float64(totalSteps)
        baseAccuracy := 0.52 + 0.25*progress/3.0 // Improve from 52% to 77% over 3 epochs
        
        // Add some noise
        noise := (rand.Float64() - 0.5) * 0.08
        accuracy := baseAccuracy + noise
        
        // Clamp to reasonable range
        if accuracy &lt; 0.45 </span><span class="cov0" title="0">{
                accuracy = 0.45
        }</span>
        <span class="cov0" title="0">if accuracy &gt; 0.85 </span><span class="cov0" title="0">{
                accuracy = 0.85
        }</span>
        
        <span class="cov0" title="0">return accuracy</span>
}

// RunProgressBarDemo runs a demonstration of the progress bar
func RunProgressBarDemo() <span class="cov0" title="0">{
        fmt.Println("Running Go-Metal Progress Bar Demo...")
        fmt.Println("This will show PyTorch-style training progress with a real model.")
        
        err := TrainingExample()
        if err != nil </span><span class="cov0" title="0">{
                fmt.Printf("Training example failed: %v\n", err)
                return
        }</span>
        
        <span class="cov0" title="0">fmt.Println("Demo completed!")</span>
}</pre>
		
		<pre class="file" id="file8" style="display: none">package training

import (
        "math"
)

// LRScheduler defines the interface for learning rate scheduling strategies
// All schedulers must be stateless and pure functions to maintain GPU-resident principles
type LRScheduler interface {
        // GetLR returns the learning rate for the current epoch/step
        // This is a pure function - no state modifications
        GetLR(epoch int, step int, baseLR float64) float64
        
        // GetName returns the scheduler name for logging
        GetName() string
}

// StepLRScheduler reduces learning rate by a factor every stepSize epochs
type StepLRScheduler struct {
        StepSize int     // Epochs between LR reductions
        Gamma    float64 // Multiplicative factor of LR decay
}

// NewStepLRScheduler creates a step learning rate scheduler
func NewStepLRScheduler(stepSize int, gamma float64) *StepLRScheduler <span class="cov8" title="1">{
        if stepSize &lt;= 0 </span><span class="cov0" title="0">{
                stepSize = 30 // Default: reduce every 30 epochs
        }</span>
        <span class="cov8" title="1">if gamma &lt;= 0 || gamma &gt;= 1 </span><span class="cov0" title="0">{
                gamma = 0.1 // Default: reduce by 10x
        }</span>
        <span class="cov8" title="1">return &amp;StepLRScheduler{
                StepSize: stepSize,
                Gamma:    gamma,
        }</span>
}

func (s *StepLRScheduler) GetLR(epoch int, step int, baseLR float64) float64 <span class="cov8" title="1">{
        // Calculate how many times to apply gamma
        times := epoch / s.StepSize
        return baseLR * math.Pow(s.Gamma, float64(times))
}</span>

func (s *StepLRScheduler) GetName() string <span class="cov8" title="1">{
        return "StepLR"
}</span>

// ExponentialLRScheduler decays learning rate exponentially
type ExponentialLRScheduler struct {
        Gamma float64 // Multiplicative factor of LR decay per epoch
}

// NewExponentialLRScheduler creates an exponential learning rate scheduler
func NewExponentialLRScheduler(gamma float64) *ExponentialLRScheduler <span class="cov8" title="1">{
        if gamma &lt;= 0 || gamma &gt;= 1 </span><span class="cov0" title="0">{
                gamma = 0.95 // Default: 5% reduction per epoch
        }</span>
        <span class="cov8" title="1">return &amp;ExponentialLRScheduler{
                Gamma: gamma,
        }</span>
}

func (s *ExponentialLRScheduler) GetLR(epoch int, step int, baseLR float64) float64 <span class="cov8" title="1">{
        return baseLR * math.Pow(s.Gamma, float64(epoch))
}</span>

func (s *ExponentialLRScheduler) GetName() string <span class="cov8" title="1">{
        return "ExponentialLR"
}</span>

// CosineAnnealingLRScheduler implements cosine annealing schedule
type CosineAnnealingLRScheduler struct {
        TMax int     // Maximum number of epochs
        EtaMin float64 // Minimum learning rate
}

// NewCosineAnnealingLRScheduler creates a cosine annealing scheduler
func NewCosineAnnealingLRScheduler(tMax int, etaMin float64) *CosineAnnealingLRScheduler <span class="cov8" title="1">{
        if tMax &lt;= 0 </span><span class="cov0" title="0">{
                tMax = 100 // Default: 100 epochs
        }</span>
        <span class="cov8" title="1">if etaMin &lt; 0 </span><span class="cov0" title="0">{
                etaMin = 0 // Default: anneal to 0
        }</span>
        <span class="cov8" title="1">return &amp;CosineAnnealingLRScheduler{
                TMax: tMax,
                EtaMin: etaMin,
        }</span>
}

func (s *CosineAnnealingLRScheduler) GetLR(epoch int, step int, baseLR float64) float64 <span class="cov8" title="1">{
        if epoch &gt;= s.TMax </span><span class="cov8" title="1">{
                return s.EtaMin
        }</span>
        
        // Cosine annealing formula
        <span class="cov8" title="1">return s.EtaMin + (baseLR-s.EtaMin) * (1 + math.Cos(math.Pi*float64(epoch)/float64(s.TMax))) / 2</span>
}

func (s *CosineAnnealingLRScheduler) GetName() string <span class="cov8" title="1">{
        return "CosineAnnealingLR"
}</span>

// ReduceLROnPlateauScheduler reduces LR when a metric has stopped improving
// This scheduler requires state tracking, so it's handled differently
type ReduceLROnPlateauScheduler struct {
        Factor    float64 // Factor by which the learning rate will be reduced
        Patience  int     // Number of epochs with no improvement after which LR will be reduced
        Threshold float64 // Threshold for measuring the new optimum
        Mode      string  // One of "min" or "max"
        
        // Internal state - these are CPU-side only for scheduling decisions
        bestMetric   float64
        badEpochs    int
        currentLR    float64
        initialized  bool
}

// NewReduceLROnPlateauScheduler creates a plateau-based scheduler
func NewReduceLROnPlateauScheduler(factor float64, patience int, threshold float64, mode string) *ReduceLROnPlateauScheduler <span class="cov8" title="1">{
        if factor &lt;= 0 || factor &gt;= 1 </span><span class="cov0" title="0">{
                factor = 0.1
        }</span>
        <span class="cov8" title="1">if patience &lt;= 0 </span><span class="cov0" title="0">{
                patience = 10
        }</span>
        <span class="cov8" title="1">if threshold &lt; 0 </span><span class="cov0" title="0">{
                threshold = 1e-4
        }</span>
        <span class="cov8" title="1">if mode != "min" &amp;&amp; mode != "max" </span><span class="cov0" title="0">{
                mode = "min" // Default: minimize loss
        }</span>
        
        <span class="cov8" title="1">return &amp;ReduceLROnPlateauScheduler{
                Factor:    factor,
                Patience:  patience,
                Threshold: threshold,
                Mode:      mode,
        }</span>
}

// Step checks if LR should be reduced based on metric
// This is called once per epoch with the validation metric
func (s *ReduceLROnPlateauScheduler) Step(metric float64, currentLR float64) float64 <span class="cov8" title="1">{
        if !s.initialized </span><span class="cov8" title="1">{
                s.bestMetric = metric
                s.currentLR = currentLR
                s.initialized = true
                return currentLR
        }</span>
        
        <span class="cov8" title="1">improved := false
        if s.Mode == "min" </span><span class="cov8" title="1">{
                improved = metric &lt; s.bestMetric - s.Threshold
        }</span> else<span class="cov0" title="0"> {
                improved = metric &gt; s.bestMetric + s.Threshold
        }</span>
        
        <span class="cov8" title="1">if improved </span><span class="cov8" title="1">{
                s.bestMetric = metric
                s.badEpochs = 0
        }</span> else<span class="cov8" title="1"> {
                s.badEpochs++
                if s.badEpochs &gt;= s.Patience </span><span class="cov8" title="1">{
                        s.currentLR *= s.Factor
                        s.badEpochs = 0
                }</span>
        }
        
        <span class="cov8" title="1">return s.currentLR</span>
}

func (s *ReduceLROnPlateauScheduler) GetLR(epoch int, step int, baseLR float64) float64 <span class="cov0" title="0">{
        // For plateau scheduler, we return the internally tracked LR
        // The actual reduction happens in Step() based on metrics
        if s.initialized </span><span class="cov0" title="0">{
                return s.currentLR
        }</span>
        <span class="cov0" title="0">return baseLR</span>
}

func (s *ReduceLROnPlateauScheduler) GetName() string <span class="cov8" title="1">{
        return "ReduceLROnPlateau"
}</span>

// NoOpScheduler maintains constant learning rate (default behavior)
type NoOpScheduler struct{}

func (s *NoOpScheduler) GetLR(epoch int, step int, baseLR float64) float64 <span class="cov0" title="0">{
        return baseLR
}</span>

func (s *NoOpScheduler) GetName() string <span class="cov8" title="1">{
        return "ConstantLR"
}</pre>
		
		<pre class="file" id="file9" style="display: none">package training

import (
        "context"
        "fmt"
        "net/http"
        "os"
        "os/exec"
        "path/filepath"
        "runtime"
        "strings"
        "time"
)

// SidecarManager handles automatic sidecar service management
type SidecarManager struct {
        sidecarPath   string
        port          int
        autoStart     bool
        dockerMode    bool
        process       *exec.Cmd
        isRunning     bool
}

// SidecarConfig contains configuration for the sidecar service
type SidecarConfig struct {
        Port       int    `json:"port"`
        AutoStart  bool   `json:"auto_start"`
        DockerMode bool   `json:"docker_mode"`
        SidecarDir string `json:"sidecar_dir"`
}

// DefaultSidecarConfig returns default configuration for the sidecar
func DefaultSidecarConfig() SidecarConfig <span class="cov0" title="0">{
        return SidecarConfig{
                Port:       8080,
                AutoStart:  true,
                DockerMode: false,
                SidecarDir: "", // Will be auto-detected
        }
}</span>

// NewSidecarManager creates a new sidecar manager
func NewSidecarManager(config SidecarConfig) (*SidecarManager, error) <span class="cov0" title="0">{
        // Auto-detect sidecar directory if not provided
        sidecarPath := config.SidecarDir
        if sidecarPath == "" </span><span class="cov0" title="0">{
                detected, err := detectSidecarPath()
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to detect sidecar path: %w", err)
                }</span>
                <span class="cov0" title="0">sidecarPath = detected</span>
        }
        
        // Verify sidecar exists
        <span class="cov0" title="0">if !fileExists(filepath.Join(sidecarPath, "app.py")) </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("sidecar app.py not found at %s", sidecarPath)
        }</span>
        
        <span class="cov0" title="0">return &amp;SidecarManager{
                sidecarPath: sidecarPath,
                port:        config.Port,
                autoStart:   config.AutoStart,
                dockerMode:  config.DockerMode,
                isRunning:   false,
        }, nil</span>
}

// Start starts the sidecar service
func (sm *SidecarManager) Start() error <span class="cov0" title="0">{
        if sm.isRunning </span><span class="cov0" title="0">{
                return nil // Already running
        }</span>
        
        // Check if service is already running elsewhere
        <span class="cov0" title="0">if sm.isServiceRunning() </span><span class="cov0" title="0">{
                sm.isRunning = true
                return nil
        }</span>
        
        <span class="cov0" title="0">if !sm.autoStart </span><span class="cov0" title="0">{
                return fmt.Errorf("sidecar service not running and auto-start is disabled")
        }</span>
        
        // Start the service
        <span class="cov0" title="0">if sm.dockerMode </span><span class="cov0" title="0">{
                return sm.startDockerService()
        }</span>
        <span class="cov0" title="0">return sm.startPythonService()</span>
}

// Stop stops the sidecar service
func (sm *SidecarManager) Stop() error <span class="cov0" title="0">{
        if !sm.isRunning </span><span class="cov0" title="0">{
                return nil
        }</span>
        
        <span class="cov0" title="0">if sm.dockerMode </span><span class="cov0" title="0">{
                return sm.stopDockerService()
        }</span>
        <span class="cov0" title="0">return sm.stopPythonService()</span>
}

// IsRunning checks if the sidecar service is running
func (sm *SidecarManager) IsRunning() bool <span class="cov0" title="0">{
        return sm.isServiceRunning()
}</span>

// GetBaseURL returns the base URL for the sidecar service
func (sm *SidecarManager) GetBaseURL() string <span class="cov0" title="0">{
        return fmt.Sprintf("http://localhost:%d", sm.port)
}</span>

// EnsureRunning ensures the sidecar service is running
func (sm *SidecarManager) EnsureRunning() error <span class="cov0" title="0">{
        if sm.isServiceRunning() </span><span class="cov0" title="0">{
                return nil
        }</span>
        
        <span class="cov0" title="0">fmt.Printf("🚀 Starting Go-Metal visualization sidecar...\n")
        
        if err := sm.Start(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start sidecar service: %w", err)
        }</span>
        
        // Wait for service to be ready
        <span class="cov0" title="0">ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
        defer cancel()
        
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        return fmt.Errorf("timeout waiting for sidecar service to start")</span>
                default:<span class="cov0" title="0">
                        if sm.isServiceRunning() </span><span class="cov0" title="0">{
                                fmt.Printf("✅ Sidecar service is running at %s\n", sm.GetBaseURL())
                                return nil
                        }</span>
                        <span class="cov0" title="0">time.Sleep(500 * time.Millisecond)</span>
                }
        }
}

// startPythonService starts the Python development server
func (sm *SidecarManager) startPythonService() error <span class="cov0" title="0">{
        // Check if Python is available
        pythonCmd := "python3"
        if runtime.GOOS == "windows" </span><span class="cov0" title="0">{
                pythonCmd = "python"
        }</span>
        
        // Check if start_sidecar.py exists
        <span class="cov0" title="0">startScript := filepath.Join(sm.sidecarPath, "start_sidecar.py")
        if fileExists(startScript) </span><span class="cov0" title="0">{
                // Use the startup script
                cmd := exec.Command(pythonCmd, "start_sidecar.py", "--dev", "--port", fmt.Sprintf("%d", sm.port))
                cmd.Dir = sm.sidecarPath
                cmd.Stdout = os.Stdout
                cmd.Stderr = os.Stderr
                
                sm.process = cmd
                sm.isRunning = true
                
                return cmd.Start()
        }</span>
        
        // Fallback to direct app.py execution
        <span class="cov0" title="0">cmd := exec.Command(pythonCmd, "app.py")
        cmd.Dir = sm.sidecarPath
        cmd.Env = append(os.Environ(), fmt.Sprintf("PORT=%d", sm.port))
        cmd.Stdout = os.Stdout
        cmd.Stderr = os.Stderr
        
        sm.process = cmd
        sm.isRunning = true
        
        return cmd.Start()</span>
}

// startDockerService starts the Docker Compose service
func (sm *SidecarManager) startDockerService() error <span class="cov0" title="0">{
        // Check if Docker Compose is available
        if !commandExists("docker-compose") </span><span class="cov0" title="0">{
                return fmt.Errorf("docker-compose command not found")
        }</span>
        
        // Start with Docker Compose
        <span class="cov0" title="0">cmd := exec.Command("docker-compose", "up", "-d")
        cmd.Dir = sm.sidecarPath
        
        output, err := cmd.CombinedOutput()
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start Docker service: %w\nOutput: %s", err, string(output))
        }</span>
        
        <span class="cov0" title="0">sm.isRunning = true
        return nil</span>
}

// stopPythonService stops the Python development server
func (sm *SidecarManager) stopPythonService() error <span class="cov0" title="0">{
        if sm.process != nil </span><span class="cov0" title="0">{
                if err := sm.process.Process.Kill(); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to stop Python service: %w", err)
                }</span>
                <span class="cov0" title="0">sm.process = nil</span>
        }
        
        <span class="cov0" title="0">sm.isRunning = false
        return nil</span>
}

// stopDockerService stops the Docker Compose service
func (sm *SidecarManager) stopDockerService() error <span class="cov0" title="0">{
        cmd := exec.Command("docker-compose", "down")
        cmd.Dir = sm.sidecarPath
        
        output, err := cmd.CombinedOutput()
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to stop Docker service: %w\nOutput: %s", err, string(output))
        }</span>
        
        <span class="cov0" title="0">sm.isRunning = false
        return nil</span>
}

// isServiceRunning checks if the sidecar service is responding
func (sm *SidecarManager) isServiceRunning() bool <span class="cov0" title="0">{
        client := &amp;http.Client{
                Timeout: 2 * time.Second,
        }
        
        resp, err := client.Get(fmt.Sprintf("%s/health", sm.GetBaseURL()))
        if err != nil </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov0" title="0">defer resp.Body.Close()
        
        return resp.StatusCode == http.StatusOK</span>
}

// detectSidecarPath attempts to find the sidecar directory
func detectSidecarPath() (string, error) <span class="cov0" title="0">{
        // Common locations to check
        candidates := []string{
                "./app/sidecar",
                "../sidecar",
                "../../app/sidecar",
                "./sidecar",
        }
        
        // Get current working directory
        cwd, err := os.Getwd()
        if err != nil </span><span class="cov0" title="0">{
                return "", err
        }</span>
        
        // Check candidates relative to current directory
        <span class="cov0" title="0">for _, candidate := range candidates </span><span class="cov0" title="0">{
                fullPath := filepath.Join(cwd, candidate)
                if fileExists(filepath.Join(fullPath, "app.py")) </span><span class="cov0" title="0">{
                        abs, err := filepath.Abs(fullPath)
                        if err == nil </span><span class="cov0" title="0">{
                                return abs, nil
                        }</span>
                }
        }
        
        // Try to find in Go module structure
        // Look for go.mod and then find sidecar relative to it
        <span class="cov0" title="0">dir := cwd
        for </span><span class="cov0" title="0">{
                goMod := filepath.Join(dir, "go.mod")
                if fileExists(goMod) </span><span class="cov0" title="0">{
                        // Found go.mod, check for sidecar
                        sidecarPath := filepath.Join(dir, "app", "sidecar")
                        if fileExists(filepath.Join(sidecarPath, "app.py")) </span><span class="cov0" title="0">{
                                return sidecarPath, nil
                        }</span>
                        <span class="cov0" title="0">break</span>
                }
                
                <span class="cov0" title="0">parent := filepath.Dir(dir)
                if parent == dir </span><span class="cov0" title="0">{
                        break</span> // Reached root
                }
                <span class="cov0" title="0">dir = parent</span>
        }
        
        <span class="cov0" title="0">return "", fmt.Errorf("sidecar directory not found in common locations")</span>
}

// fileExists checks if a file exists
func fileExists(path string) bool <span class="cov0" title="0">{
        _, err := os.Stat(path)
        return err == nil
}</span>

// commandExists checks if a command exists in PATH
func commandExists(cmd string) bool <span class="cov0" title="0">{
        _, err := exec.LookPath(cmd)
        return err == nil
}</span>

// Helper methods for ModelTrainer integration

// EnableSidecarWithAutoStart enables plotting service with automatic sidecar management
func (mt *ModelTrainer) EnableSidecarWithAutoStart(config ...SidecarConfig) error <span class="cov0" title="0">{
        // Use default config if none provided
        sidecarConfig := DefaultSidecarConfig()
        if len(config) &gt; 0 </span><span class="cov0" title="0">{
                sidecarConfig = config[0]
        }</span>
        
        // Create sidecar manager
        <span class="cov0" title="0">manager, err := NewSidecarManager(sidecarConfig)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create sidecar manager: %w", err)
        }</span>
        
        // Ensure sidecar is running
        <span class="cov0" title="0">if err := manager.EnsureRunning(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start sidecar: %w", err)
        }</span>
        
        // Configure plotting service to use the sidecar
        <span class="cov0" title="0">mt.ConfigurePlottingService(PlottingServiceConfig{
                BaseURL: manager.GetBaseURL(),
                Timeout: 30 * time.Second,
        })
        
        // Enable services
        mt.EnableVisualization()
        mt.EnablePlottingService()
        
        return nil</span>
}

// GenerateAndOpenPlot generates a plot and opens it in the browser
func (mt *ModelTrainer) GenerateAndOpenPlot(plotType PlotType) error <span class="cov0" title="0">{
        // Generate plot
        response, err := mt.SendPlotToSidecar(plotType)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to generate plot: %w", err)
        }</span>
        
        <span class="cov0" title="0">if !response.Success </span><span class="cov0" title="0">{
                return fmt.Errorf("plot generation failed: %s", response.Message)
        }</span>
        
        // Open in browser
        <span class="cov0" title="0">baseURL := strings.TrimSuffix(mt.plottingService.baseURL, "/")
        openURL := fmt.Sprintf("%s/api/open/%s", baseURL, response.PlotURL[6:]) // Remove "/plot/" prefix
        
        client := &amp;http.Client{Timeout: 5 * time.Second}
        resp, err := client.Get(openURL)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to open plot in browser: %w", err)
        }</span>
        <span class="cov0" title="0">defer resp.Body.Close()
        
        fmt.Printf("🌐 Plot opened in browser: %s\n", response.PlotURL)
        return nil</span>
}

// GenerateAndOpenAllPlots generates all plots and opens them in a dashboard
func (mt *ModelTrainer) GenerateAndOpenAllPlots() error <span class="cov0" title="0">{
        // Generate all plots
        responses := mt.SendAllPlotsToSidecar()
        
        // Count successful plots
        successCount := 0
        var firstBatchID string
        
        for plotType, response := range responses </span><span class="cov0" title="0">{
                if response.Success </span><span class="cov0" title="0">{
                        successCount++
                        if firstBatchID == "" </span><span class="cov0" title="0">{
                                // Extract batch ID from the first successful response
                                // This is a simplified approach - in practice you'd want to implement proper batch handling
                                firstBatchID = fmt.Sprintf("batch_%d", time.Now().Unix())
                        }</span>
                        <span class="cov0" title="0">fmt.Printf("✅ Generated %s plot\n", plotType)</span>
                } else<span class="cov0" title="0"> {
                        fmt.Printf("❌ Failed to generate %s plot: %s\n", plotType, response.Message)
                }</span>
        }
        
        <span class="cov0" title="0">if successCount == 0 </span><span class="cov0" title="0">{
                return fmt.Errorf("no plots were generated successfully")
        }</span>
        
        <span class="cov0" title="0">fmt.Printf("🎉 Generated %d plots successfully\n", successCount)
        return nil</span>
}</pre>
		
		<pre class="file" id="file10" style="display: none">package training

import (
        "fmt"
        "time"

        "github.com/tsawler/go-metal/cgo_bridge"
        "github.com/tsawler/go-metal/engine"
        "github.com/tsawler/go-metal/layers"
        "github.com/tsawler/go-metal/memory"
)

// EngineType represents the training engine selection strategy
// Maintains GPU-resident architecture compliance across all engine types
type EngineType int

const (
        // Auto automatically selects the optimal engine based on model architecture
        // - 4D input + Conv layers → Hybrid Engine (20k+ batches/sec performance)
        // - 2D input + Dense-only → Dynamic Engine (flexibility for MLPs)
        // - Complex architectures → Dynamic Engine (any architecture support)
        Auto EngineType = iota
        
        // Hybrid uses MPS for convolutions + MPSGraph for other operations
        // - Optimized for CNN architectures (3 conv + 2 FC pattern)
        // - Hardcoded optimizations for maximum performance
        // - Requires 4D input and Conv+Dense layer combination
        Hybrid
        
        // Dynamic builds MPSGraph dynamically for any architecture
        // - Supports any input dimensionality (2D, 4D, etc.)
        // - Supports any layer combination
        // - More flexible but slightly slower than Hybrid
        Dynamic
)

func (et EngineType) String() string <span class="cov8" title="1">{
        switch et </span>{
        case Auto:<span class="cov0" title="0">
                return "Auto"</span>
        case Hybrid:<span class="cov8" title="1">
                return "Hybrid"</span>
        case Dynamic:<span class="cov0" title="0">
                return "Dynamic"</span>
        default:<span class="cov0" title="0">
                return "Unknown"</span>
        }
}

// ProblemType represents the type of machine learning problem
type ProblemType int

const (
        // Classification for discrete class prediction
        Classification ProblemType = iota
        // Regression for continuous value prediction
        Regression
)

func (pt ProblemType) String() string <span class="cov0" title="0">{
        switch pt </span>{
        case Classification:<span class="cov0" title="0">
                return "Classification"</span>
        case Regression:<span class="cov0" title="0">
                return "Regression"</span>
        default:<span class="cov0" title="0">
                return fmt.Sprintf("Unknown(%d)", pt)</span>
        }
}

// LossFunction represents the loss function for training
type LossFunction int

const (
        // Classification losses
        CrossEntropy       LossFunction = iota // Softmax cross-entropy for multi-class
        SparseCrossEntropy                     // Sparse categorical cross-entropy
        BinaryCrossEntropy                     // Binary cross-entropy for binary classification
        BCEWithLogits                          // Binary cross-entropy with logits (more numerically stable)
        CategoricalCrossEntropy                // Categorical cross-entropy without softmax
        
        // Regression losses
        MeanSquaredError  // 5 - MSE for regression
        MeanAbsoluteError // 6 - MAE for regression
        Huber             // 7 - Huber loss for robust regression
)

func (lf LossFunction) String() string <span class="cov0" title="0">{
        switch lf </span>{
        case CrossEntropy:<span class="cov0" title="0">
                return "CrossEntropy"</span>
        case SparseCrossEntropy:<span class="cov0" title="0">
                return "SparseCrossEntropy"</span>
        case BinaryCrossEntropy:<span class="cov0" title="0">
                return "BinaryCrossEntropy"</span>
        case BCEWithLogits:<span class="cov0" title="0">
                return "BCEWithLogits"</span>
        case CategoricalCrossEntropy:<span class="cov0" title="0">
                return "CategoricalCrossEntropy"</span>
        case MeanSquaredError:<span class="cov0" title="0">
                return "MeanSquaredError"</span>
        case MeanAbsoluteError:<span class="cov0" title="0">
                return "MeanAbsoluteError"</span>
        case Huber:<span class="cov0" title="0">
                return "Huber"</span>
        default:<span class="cov0" title="0">
                return fmt.Sprintf("Unknown(%d)", lf)</span>
        }
}

// SimpleTrainer provides a basic training interface for testing Phase 1
type SimpleTrainer struct {
        batchTrainer *engine.BatchTrainer
        batchSize    int
        config       cgo_bridge.TrainingConfig
}

// NewSimpleTrainer creates a new simple trainer (legacy function - use factory for production)
// DEPRECATED: Use NewSGDTrainer, NewAdamTrainer, or the factory system for production code
func NewSimpleTrainer(batchSize int, learningRate float32) (*SimpleTrainer, error) <span class="cov0" title="0">{
        // Use the new factory system internally for consistency
        factory := NewFactory()
        return factory.CreateSGDTrainer(batchSize, learningRate, 0.0)
}</span>

// TrainBatch trains on a single batch with timing (full training loop)
func (st *SimpleTrainer) TrainBatch(
        inputData []float32,
        inputShape []int,
        labelData []int32,
        labelShape []int,
        weights []*memory.Tensor,
) (*TrainingResult, error) <span class="cov0" title="0">{
        
        start := time.Now()
        
        // Create input tensor
        inputTensor, err := memory.NewTensor(inputShape, memory.Float32, memory.GPU)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create input tensor: %v", err)
        }</span>
        <span class="cov0" title="0">defer inputTensor.Release()
        
        // Copy input data to GPU tensor
        err = cgo_bridge.CopyFloat32ArrayToMetalBuffer(inputTensor.MetalBuffer(), inputData)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to copy input data to GPU: %v", err)
        }</span>
        
        // Create label tensor (one-hot encoded for hybrid approach)
        // Convert int32 labels to one-hot float32 format
        <span class="cov0" title="0">oneHotShape := []int{labelShape[0], 2} // Assuming 2 classes for this test
        labelTensor, err := memory.NewTensor(oneHotShape, memory.Float32, memory.GPU)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create label tensor: %v", err)
        }</span>
        <span class="cov0" title="0">defer labelTensor.Release()
        
        // Convert int32 labels to one-hot float32 format and copy to GPU
        oneHotData := make([]float32, oneHotShape[0]*oneHotShape[1])
        for i, label := range labelData </span><span class="cov0" title="0">{
                // Zero-out the row first
                baseIdx := i * oneHotShape[1]
                for j := 0; j &lt; oneHotShape[1]; j++ </span><span class="cov0" title="0">{
                        oneHotData[baseIdx+j] = 0.0
                }</span>
                // Set the correct class to 1.0
                <span class="cov0" title="0">if int(label) &lt; oneHotShape[1] </span><span class="cov0" title="0">{
                        oneHotData[baseIdx+int(label)] = 1.0
                }</span>
        }
        
        <span class="cov0" title="0">err = cgo_bridge.CopyFloat32ArrayToMetalBuffer(labelTensor.MetalBuffer(), oneHotData)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to copy label data to GPU: %v", err)
        }</span>
        
        // Execute hybrid full training step (forward + backward + optimizer)
        <span class="cov0" title="0">learningRate := st.config.LearningRate
        result, err := st.batchTrainer.TrainBatchHybridFull(inputTensor, labelTensor, weights, learningRate)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("batch training failed: %v", err)
        }</span>
        
        <span class="cov0" title="0">totalTime := time.Since(start)
        
        return &amp;TrainingResult{
                Loss:       result.Loss,
                BatchSize:  result.BatchSize,
                StepTime:   totalTime,
                Success:    result.Success,
                BatchRate:  float64(result.BatchSize) / totalTime.Seconds(),
        }, nil</span>
}

// GetStats returns training statistics
func (st *SimpleTrainer) GetStats() *TrainingStats <span class="cov0" title="0">{
        memStats := memory.GetGlobalMemoryManager().Stats()
        
        return &amp;TrainingStats{
                CurrentStep:    st.batchTrainer.GetCurrentStep(),
                BatchSize:      st.batchSize,
                OptimizerType:  st.config.OptimizerType,
                LearningRate:   st.config.LearningRate,
                MemoryPoolStats: memStats,
        }
}</span>

// Cleanup releases resources
func (st *SimpleTrainer) Cleanup() <span class="cov0" title="0">{
        if st.batchTrainer != nil </span><span class="cov0" title="0">{
                st.batchTrainer.Cleanup()
        }</span>
}

// TrainingResult represents the result of a training step
type TrainingResult struct {
        Loss      float32
        BatchSize int
        StepTime  time.Duration
        Success   bool
        BatchRate float64 // batches per second
}

// TrainingStats provides training statistics
type TrainingStats struct {
        CurrentStep     int
        BatchSize       int
        OptimizerType   cgo_bridge.OptimizerType
        LearningRate    float32
        MemoryPoolStats map[memory.PoolKey]string
}

// CreateDummyWeights creates dummy weight tensors for testing (hybrid approach)
func CreateDummyWeights() ([]*memory.Tensor, error) <span class="cov0" title="0">{
        weights := make([]*memory.Tensor, 0)
        
        // Create weight tensors for hybrid approach (only FC layer - conv is built-in)
        shapes := [][]int{
                {8, 2},           // FC layer weights (8 inputs, 2 outputs)
                {2},              // FC layer bias
        }
        
        for i, shape := range shapes </span><span class="cov0" title="0">{
                tensor, err := memory.NewTensor(shape, memory.Float32, memory.GPU)
                if err != nil </span><span class="cov0" title="0">{
                        // Cleanup previously created tensors
                        for _, w := range weights </span><span class="cov0" title="0">{
                                w.Release()
                        }</span>
                        <span class="cov0" title="0">return nil, fmt.Errorf("failed to create weight tensor %d: %v", i, err)</span>
                }
                <span class="cov0" title="0">weights = append(weights, tensor)</span>
        }
        
        <span class="cov0" title="0">return weights, nil</span>
}

// TestPhase1 runs a basic test of Phase 1 implementation
func TestPhase1() error <span class="cov0" title="0">{
        fmt.Println("Testing Phase 1 implementation...")
        
        // Create trainer
        trainer, err := NewSimpleTrainer(32, 0.01)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create trainer: %v", err)
        }</span>
        <span class="cov0" title="0">defer trainer.Cleanup()
        
        // Create dummy weights
        weights, err := CreateDummyWeights()
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create weights: %v", err)
        }</span>
        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                for _, w := range weights </span><span class="cov0" title="0">{
                        w.Release()
                }</span>
        }()
        
        // Create dummy input data for intermediate CNN 
        <span class="cov0" title="0">inputShape := []int{32, 3, 32, 32}    // Batch of 32 RGB 32x32 images (smaller)
        labelShape := []int{32}               // 32 labels
        
        inputData := make([]float32, 32*3*32*32)
        labelData := make([]int32, 32)
        
        // Fill with dummy data
        for i := range inputData </span><span class="cov0" title="0">{
                inputData[i] = float32(i % 100) / 100.0
        }</span>
        <span class="cov0" title="0">for i := range labelData </span><span class="cov0" title="0">{
                labelData[i] = int32(i % 2) // Binary classification
        }</span>
        
        // Run a few training steps
        <span class="cov0" title="0">for step := 0; step &lt; 3; step++ </span><span class="cov0" title="0">{
                result, err := trainer.TrainBatch(inputData, inputShape, labelData, labelShape, weights)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("training step %d failed: %v", step, err)
                }</span>
                
                <span class="cov0" title="0">fmt.Printf("Step %d: Loss=%.4f, BatchRate=%.2f batch/s, Time=%v\n",
                        step, result.Loss, result.BatchRate, result.StepTime)</span>
        }
        
        // Print statistics
        <span class="cov0" title="0">stats := trainer.GetStats()
        fmt.Printf("\nTraining Stats:\n")
        fmt.Printf("  Current Step: %d\n", stats.CurrentStep)
        fmt.Printf("  Batch Size: %d\n", stats.BatchSize)
        fmt.Printf("  Learning Rate: %.4f\n", stats.LearningRate)
        fmt.Printf("  Memory Pools: %d active\n", len(stats.MemoryPoolStats))
        
        fmt.Println("Phase 1 test completed successfully!")
        return nil</span>
}

// ================================================================
// PRODUCTION TRAINER FACTORY SYSTEM
// ================================================================

// ModelArchitectureInfo provides architecture analysis for engine selection
type ModelArchitectureInfo struct {
        InputDimensions int          // Number of input dimensions (2D, 4D, etc.)
        HasConvLayers   bool         // Whether model contains Conv2D layers
        HasDenseLayers  bool         // Whether model contains Dense layers
        IsMLPOnly       bool         // Whether model is MLP-only (Dense + activations)
        IsCNNPattern    bool         // Whether model follows CNN pattern (Conv + Dense)
        LayerCount      int          // Total number of layers
        ParameterCount  int64        // Total trainable parameters
        Complexity      string       // "Simple", "Standard", "Complex"
}

// TrainerConfig provides comprehensive configuration for training
type TrainerConfig struct {
        // Training parameters
        BatchSize    int     `json:"batch_size"`
        LearningRate float32 `json:"learning_rate"`
        
        // Optimizer configuration
        OptimizerType cgo_bridge.OptimizerType `json:"optimizer_type"`
        
        // Optimizer-specific parameters
        Beta1       float32 `json:"beta1"`        // Adam momentum decay (default: 0.9) / RMSProp momentum (default: 0.0)
        Beta2       float32 `json:"beta2"`        // Adam variance decay (default: 0.999) - unused for RMSProp
        Epsilon     float32 `json:"epsilon"`      // Numerical stability (default: 1e-8)
        WeightDecay float32 `json:"weight_decay"` // L2 regularization (default: 0.0)
        
        // RMSProp-specific parameters
        Alpha       float32 `json:"alpha"`        // RMSProp smoothing constant (default: 0.99)
        Momentum    float32 `json:"momentum"`     // RMSProp momentum (default: 0.0)
        Centered    bool    `json:"centered"`     // RMSProp centered variant (default: false)
        
        // Engine selection (GPU-resident architecture compliance)
        EngineType       EngineType `json:"engine_type"`       // Engine selection: Auto, Hybrid, Dynamic (default: Auto)
        
        // Problem type and loss function configuration
        ProblemType  ProblemType  `json:"problem_type"`  // Classification or Regression (default: Classification)
        LossFunction LossFunction `json:"loss_function"` // Loss function for the problem type (default: CrossEntropy)
        UseHybridEngine  bool       `json:"use_hybrid_engine"`  // DEPRECATED: Use EngineType instead
        UseDynamicEngine bool       `json:"use_dynamic_engine"` // DEPRECATED: Use EngineType instead
        InferenceOnly    bool       `json:"inference_only"`     // Skip training setup, optimize for inference (forward-pass only)
        
        // Mixed Precision Training Configuration
        UseMixedPrecision  bool    `json:"use_mixed_precision"`   // Enable FP16 training with FP32 master weights
        InitialLossScale   float32 `json:"initial_loss_scale"`    // Initial loss scale for gradient scaling (default: 65536.0)
        LossScaleGrowthFactor float32 `json:"loss_scale_growth_factor"` // Loss scale growth factor (default: 2.0)
        LossScaleBackoffFactor float32 `json:"loss_scale_backoff_factor"` // Loss scale reduction factor on overflow (default: 0.5)
        LossScaleGrowthInterval int `json:"loss_scale_growth_interval"` // Steps between loss scale increases (default: 2000)
}

// Validate ensures the problem type and loss function are compatible
func (tc *TrainerConfig) Validate() error <span class="cov0" title="0">{
        // Validate problem type and loss function compatibility
        switch tc.ProblemType </span>{
        case Classification:<span class="cov0" title="0">
                if tc.LossFunction != CrossEntropy &amp;&amp; tc.LossFunction != SparseCrossEntropy </span><span class="cov0" title="0">{
                        return fmt.Errorf("classification requires CrossEntropy or SparseCrossEntropy loss, got %v", tc.LossFunction)
                }</span>
        case Regression:<span class="cov0" title="0">
                if tc.LossFunction != MeanSquaredError &amp;&amp; tc.LossFunction != MeanAbsoluteError &amp;&amp; tc.LossFunction != Huber </span><span class="cov0" title="0">{
                        return fmt.Errorf("regression requires MSE, MAE, or Huber loss, got %v", tc.LossFunction)
                }</span>
        default:<span class="cov0" title="0">
                return fmt.Errorf("unsupported problem type: %v", tc.ProblemType)</span>
        }
        
        // Validate other parameters
        <span class="cov0" title="0">if tc.BatchSize &lt;= 0 </span><span class="cov0" title="0">{
                return fmt.Errorf("batch size must be positive, got %d", tc.BatchSize)
        }</span>
        
        <span class="cov0" title="0">if tc.LearningRate &lt;= 0 </span><span class="cov0" title="0">{
                return fmt.Errorf("learning rate must be positive, got %f", tc.LearningRate)
        }</span>
        
        // Validate optimizer-specific parameters
        <span class="cov0" title="0">if tc.OptimizerType == cgo_bridge.Adam </span><span class="cov0" title="0">{
                if tc.Beta1 &lt; 0 || tc.Beta1 &gt;= 1 </span><span class="cov0" title="0">{
                        return fmt.Errorf("Adam beta1 must be in [0, 1), got %f", tc.Beta1)
                }</span>
                <span class="cov0" title="0">if tc.Beta2 &lt; 0 || tc.Beta2 &gt;= 1 </span><span class="cov0" title="0">{
                        return fmt.Errorf("Adam beta2 must be in [0, 1), got %f", tc.Beta2)
                }</span>
        }
        
        <span class="cov0" title="0">if tc.OptimizerType == cgo_bridge.RMSProp </span><span class="cov0" title="0">{
                if tc.Alpha &lt; 0 || tc.Alpha &gt;= 1 </span><span class="cov0" title="0">{
                        return fmt.Errorf("RMSProp alpha must be in [0, 1), got %f", tc.Alpha)
                }</span>
        }
        
        <span class="cov0" title="0">if tc.Epsilon &lt;= 0 </span><span class="cov0" title="0">{
                return fmt.Errorf("epsilon must be positive, got %f", tc.Epsilon)
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// OptimizerConfig provides optimizer-specific configurations
type OptimizerConfig struct {
        Type        cgo_bridge.OptimizerType
        LearningRate float32
        Beta1       float32 // Adam only
        Beta2       float32 // Adam only
        Epsilon     float32 // Adam only
        WeightDecay float32
}

// TrainerFactory provides methods to create different types of trainers
type TrainerFactory struct{}

// NewFactory creates a new trainer factory
func NewFactory() *TrainerFactory <span class="cov0" title="0">{
        return &amp;TrainerFactory{}
}</span>

// CreateTrainer creates a trainer with full configuration control
func (tf *TrainerFactory) CreateTrainer(config TrainerConfig) (*SimpleTrainer, error) <span class="cov0" title="0">{
        // Validate configuration
        if err := tf.validateConfig(config); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("invalid configuration: %v", err)
        }</span>
        
        // Convert to CGO bridge config (GPU-resident parameter passing)
        <span class="cov0" title="0">bridgeConfig := cgo_bridge.TrainingConfig{
                LearningRate:  config.LearningRate,
                Beta1:         config.Beta1,
                Beta2:         config.Beta2,
                WeightDecay:   config.WeightDecay,
                Epsilon:       config.Epsilon,
                Alpha:         config.Alpha,
                Momentum:      config.Momentum,
                Centered:      config.Centered,
                OptimizerType: config.OptimizerType,
        }
        
        // Create batch trainer using legacy approach (DEPRECATED)
        // This function maintains backward compatibility but is limited
        var batchTrainer *engine.BatchTrainer
        var err error
        
        // Handle deprecated configuration options
        if config.UseHybridEngine </span><span class="cov0" title="0">{
                batchTrainer, err = engine.NewBatchTrainerHybrid(bridgeConfig, config.BatchSize)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to create hybrid batch trainer: %v", err)
                }</span>
        } else<span class="cov0" title="0"> if config.UseDynamicEngine </span><span class="cov0" title="0">{
                // NOTE: This path doesn't exist in legacy BatchTrainer
                // Users should use NewModelTrainer for smart routing
                return nil, fmt.Errorf("dynamic engine not supported in legacy SimpleTrainer (use NewModelTrainer instead)")
        }</span> else<span class="cov0" title="0"> {
                return nil, fmt.Errorf("no engine specified (use UseHybridEngine: true or switch to NewModelTrainer for smart routing)")
        }</span>
        
        <span class="cov0" title="0">return &amp;SimpleTrainer{
                batchTrainer: batchTrainer,
                batchSize:    config.BatchSize,
                config:       bridgeConfig,
        }, nil</span>
}

// CreateSGDTrainer creates an SGD trainer with specified parameters
func (tf *TrainerFactory) CreateSGDTrainer(batchSize int, learningRate float32, weightDecay float32) (*SimpleTrainer, error) <span class="cov0" title="0">{
        config := TrainerConfig{
                BatchSize:       batchSize,
                LearningRate:    learningRate,
                OptimizerType:   cgo_bridge.SGD,
                WeightDecay:     weightDecay,
                // Smart routing: Auto-select optimal engine
                EngineType:      Auto,
                UseHybridEngine: true, // Deprecated: kept for compatibility
                // Optimizer parameters (Adam/RMSProp params ignored for SGD)
                Beta1:    0.9,
                Beta2:    0.999,
                Epsilon:  1e-8,
                Alpha:    0.99,
                Momentum: 0.0,
                Centered: false,
        }
        
        return tf.CreateTrainer(config)
}</span>

// CreateAdamTrainer creates an Adam trainer with specified parameters
func (tf *TrainerFactory) CreateAdamTrainer(batchSize int, learningRate float32, beta1, beta2, epsilon, weightDecay float32) (*SimpleTrainer, error) <span class="cov0" title="0">{
        config := TrainerConfig{
                BatchSize:       batchSize,
                LearningRate:    learningRate,
                OptimizerType:   cgo_bridge.Adam,
                Beta1:           beta1,
                Beta2:           beta2,
                Epsilon:         epsilon,
                WeightDecay:     weightDecay,
                // Smart routing: Auto-select optimal engine
                EngineType:      Auto,
                UseHybridEngine: true, // Deprecated: kept for compatibility
                // RMSProp parameters (ignored for Adam)
                Alpha:    0.99,
                Momentum: 0.0,
                Centered: false,
        }
        
        return tf.CreateTrainer(config)
}</span>

// CreateAdamTrainerWithDefaults creates an Adam trainer with sensible defaults
func (tf *TrainerFactory) CreateAdamTrainerWithDefaults(batchSize int, learningRate float32) (*SimpleTrainer, error) <span class="cov0" title="0">{
        return tf.CreateAdamTrainer(batchSize, learningRate, 0.9, 0.999, 1e-8, 0.0)
}</span>

// CreateRMSPropTrainer creates an RMSProp trainer with specified parameters
func (tf *TrainerFactory) CreateRMSPropTrainer(batchSize int, learningRate, alpha, epsilon, weightDecay, momentum float32, centered bool) (*SimpleTrainer, error) <span class="cov0" title="0">{
        config := TrainerConfig{
                BatchSize:       batchSize,
                LearningRate:    learningRate,
                OptimizerType:   cgo_bridge.RMSProp,
                Alpha:           alpha,
                Epsilon:         epsilon,
                WeightDecay:     weightDecay,
                Momentum:        momentum,
                Centered:        centered,
                // Smart routing: Auto-select optimal engine
                EngineType:      Auto,
                UseHybridEngine: true, // Deprecated: kept for compatibility
                // Adam parameters are ignored for RMSProp
                Beta1:   0.9,
                Beta2:   0.999,
        }
        
        return tf.CreateTrainer(config)
}</span>

// CreateRMSPropTrainerWithDefaults creates an RMSProp trainer with sensible defaults
func (tf *TrainerFactory) CreateRMSPropTrainerWithDefaults(batchSize int, learningRate float32) (*SimpleTrainer, error) <span class="cov0" title="0">{
        return tf.CreateRMSPropTrainer(batchSize, learningRate, 0.99, 1e-8, 0.0, 0.0, false)
}</span>

// CreateProductionTrainer creates a trainer optimized for production use
func (tf *TrainerFactory) CreateProductionTrainer(batchSize int, optimizerConfig OptimizerConfig) (*SimpleTrainer, error) <span class="cov0" title="0">{
        config := TrainerConfig{
                BatchSize:       batchSize,
                LearningRate:    optimizerConfig.LearningRate,
                OptimizerType:   optimizerConfig.Type,
                Beta1:           optimizerConfig.Beta1,
                Beta2:           optimizerConfig.Beta2,
                Epsilon:         optimizerConfig.Epsilon,
                WeightDecay:     optimizerConfig.WeightDecay,
                // Smart routing: Auto-select optimal engine for production
                EngineType:      Auto,
                UseHybridEngine: true, // Deprecated: kept for compatibility
                // RMSProp parameters (set to defaults, override in specific configs)
                Alpha:    0.99,
                Momentum: 0.0,
                Centered: false,
        }
        
        return tf.CreateTrainer(config)
}</span>

// GetDefaultSGDConfig returns default SGD configuration
func (tf *TrainerFactory) GetDefaultSGDConfig(learningRate float32) OptimizerConfig <span class="cov0" title="0">{
        return OptimizerConfig{
                Type:         cgo_bridge.SGD,
                LearningRate: learningRate,
                WeightDecay:  0.0,
                // Optimizer parameters are ignored for SGD but set for completeness
                Beta1:   0.9,
                Beta2:   0.999,
                Epsilon: 1e-8,
        }
}</span>

// GetDefaultAdamConfig returns default Adam configuration
func (tf *TrainerFactory) GetDefaultAdamConfig(learningRate float32) OptimizerConfig <span class="cov0" title="0">{
        return OptimizerConfig{
                Type:         cgo_bridge.Adam,
                LearningRate: learningRate,
                Beta1:        0.9,
                Beta2:        0.999,
                Epsilon:      1e-8,
                WeightDecay:  0.0,
        }
}</span>

// GetDefaultRMSPropConfig returns default RMSProp configuration
func (tf *TrainerFactory) GetDefaultRMSPropConfig(learningRate float32) OptimizerConfig <span class="cov0" title="0">{
        return OptimizerConfig{
                Type:         cgo_bridge.RMSProp,
                LearningRate: learningRate,
                WeightDecay:  0.0,
                // Adam parameters are ignored for RMSProp but set for completeness
                Beta1:   0.9,
                Beta2:   0.999,
                Epsilon: 1e-8,
        }
}</span>

// AnalyzeModelArchitecture analyzes model architecture for optimal engine selection
// Maintains GPU-resident principles by analyzing layer specifications only
func AnalyzeModelArchitecture(modelSpec *layers.ModelSpec) *ModelArchitectureInfo <span class="cov8" title="1">{
        if modelSpec == nil || !modelSpec.Compiled </span><span class="cov0" title="0">{
                return &amp;ModelArchitectureInfo{
                        Complexity: "Invalid",
                }
        }</span>
        
        <span class="cov8" title="1">info := &amp;ModelArchitectureInfo{
                InputDimensions: len(modelSpec.InputShape),
                LayerCount:      len(modelSpec.Layers),
                ParameterCount:  modelSpec.TotalParameters,
        }
        
        // Analyze layer composition (CPU-only analysis, no GPU operations)
        for _, layer := range modelSpec.Layers </span><span class="cov8" title="1">{
                switch layer.Type </span>{
                case layers.Conv2D:<span class="cov8" title="1">
                        info.HasConvLayers = true</span>
                case layers.Dense:<span class="cov8" title="1">
                        info.HasDenseLayers = true</span>
                }
        }
        
        // Determine architecture patterns
        <span class="cov8" title="1">info.IsMLPOnly = info.HasDenseLayers &amp;&amp; !info.HasConvLayers
        info.IsCNNPattern = info.HasConvLayers &amp;&amp; info.HasDenseLayers &amp;&amp; info.InputDimensions == 4
        
        // Classify complexity for engine selection
        if info.LayerCount &lt;= 3 </span><span class="cov0" title="0">{
                info.Complexity = "Simple"
        }</span> else<span class="cov8" title="1"> if info.LayerCount &lt;= 10 </span><span class="cov8" title="1">{
                info.Complexity = "Standard"
        }</span> else<span class="cov0" title="0"> {
                info.Complexity = "Complex"
        }</span>
        
        <span class="cov8" title="1">return info</span>
}

// SelectOptimalEngine selects the best engine based on architecture analysis
// Maintains GPU-resident architecture compliance for all engine types
func SelectOptimalEngine(modelSpec *layers.ModelSpec, config TrainerConfig) EngineType <span class="cov8" title="1">{
        // Handle explicit engine selection (skip auto-detection)
        if config.EngineType != Auto </span><span class="cov0" title="0">{
                return config.EngineType
        }</span>
        
        // Handle deprecated config options for backward compatibility
        <span class="cov8" title="1">if config.UseHybridEngine &amp;&amp; !config.UseDynamicEngine </span><span class="cov8" title="1">{
                return Hybrid
        }</span>
        <span class="cov0" title="0">if config.UseDynamicEngine &amp;&amp; !config.UseHybridEngine </span><span class="cov0" title="0">{
                return Dynamic
        }</span>
        
        // Smart routing based on architecture analysis
        <span class="cov0" title="0">archInfo := AnalyzeModelArchitecture(modelSpec)
        
        // CNN Pattern: Use Hybrid Engine for maximum performance
        // - 4D input [batch, channels, height, width]
        // - Conv2D + Dense layer combination
        // - Optimized for 20k+ batches/second performance
        if archInfo.IsCNNPattern </span><span class="cov0" title="0">{
                return Hybrid
        }</span>
        
        // MLP Pattern: Use Dynamic Engine for flexibility
        // - 2D input [batch, features]
        // - Dense-only or Dense + activation layers
        // - Better flexibility for regression, classification
        <span class="cov0" title="0">if archInfo.IsMLPOnly &amp;&amp; archInfo.InputDimensions == 2 </span><span class="cov0" title="0">{
                return Dynamic
        }</span>
        
        // Complex/Custom Architectures: Use Dynamic Engine
        // - Non-standard input dimensions
        // - Complex layer combinations
        // - Custom architectures requiring flexibility
        <span class="cov0" title="0">return Dynamic</span>
}

// validateConfig validates trainer configuration
func (tf *TrainerFactory) validateConfig(config TrainerConfig) error <span class="cov0" title="0">{
        if config.BatchSize &lt;= 0 </span><span class="cov0" title="0">{
                return fmt.Errorf("batch size must be positive, got %d", config.BatchSize)
        }</span>
        
        <span class="cov0" title="0">if config.LearningRate &lt;= 0 </span><span class="cov0" title="0">{
                return fmt.Errorf("learning rate must be positive, got %f", config.LearningRate)
        }</span>
        
        <span class="cov0" title="0">if config.OptimizerType == cgo_bridge.Adam </span><span class="cov0" title="0">{
                if config.Beta1 &lt;= 0 || config.Beta1 &gt;= 1 </span><span class="cov0" title="0">{
                        return fmt.Errorf("Adam beta1 must be in (0, 1), got %f", config.Beta1)
                }</span>
                <span class="cov0" title="0">if config.Beta2 &lt;= 0 || config.Beta2 &gt;= 1 </span><span class="cov0" title="0">{
                        return fmt.Errorf("Adam beta2 must be in (0, 1), got %f", config.Beta2)
                }</span>
                <span class="cov0" title="0">if config.Epsilon &lt;= 0 </span><span class="cov0" title="0">{
                        return fmt.Errorf("Adam epsilon must be positive, got %f", config.Epsilon)
                }</span>
        }
        
        <span class="cov0" title="0">if config.OptimizerType == cgo_bridge.RMSProp </span><span class="cov0" title="0">{
                if config.Alpha &lt;= 0 || config.Alpha &gt;= 1 </span><span class="cov0" title="0">{
                        return fmt.Errorf("RMSProp alpha must be in (0, 1), got %f", config.Alpha)
                }</span>
                <span class="cov0" title="0">if config.Epsilon &lt;= 0 </span><span class="cov0" title="0">{
                        return fmt.Errorf("RMSProp epsilon must be positive, got %f", config.Epsilon)
                }</span>
                <span class="cov0" title="0">if config.Momentum &lt; 0 || config.Momentum &gt;= 1 </span><span class="cov0" title="0">{
                        return fmt.Errorf("RMSProp momentum must be in [0, 1), got %f", config.Momentum)
                }</span>
        }
        
        <span class="cov0" title="0">if config.WeightDecay &lt; 0 </span><span class="cov0" title="0">{
                return fmt.Errorf("weight decay must be non-negative, got %f", config.WeightDecay)
        }</span>
        
        <span class="cov0" title="0">return nil</span>
}

// ================================================================
// CONVENIENCE FUNCTIONS FOR BACKWARD COMPATIBILITY
// ================================================================

// NewSGDTrainer creates an SGD trainer (convenience function)
func NewSGDTrainer(batchSize int, learningRate float32) (*SimpleTrainer, error) <span class="cov0" title="0">{
        factory := NewFactory()
        return factory.CreateSGDTrainer(batchSize, learningRate, 0.0)
}</span>

// NewAdamTrainer creates an Adam trainer with defaults (convenience function) 
func NewAdamTrainer(batchSize int, learningRate float32) (*SimpleTrainer, error) <span class="cov0" title="0">{
        factory := NewFactory()
        return factory.CreateAdamTrainerWithDefaults(batchSize, learningRate)
}</span>

// NewRMSPropTrainer creates an RMSProp trainer with defaults (convenience function)
func NewRMSPropTrainer(batchSize int, learningRate float32) (*SimpleTrainer, error) <span class="cov0" title="0">{
        factory := NewFactory()
        return factory.CreateRMSPropTrainerWithDefaults(batchSize, learningRate)
}</span>

// NewTrainerWithConfig creates a trainer with full configuration (convenience function)
func NewTrainerWithConfig(config TrainerConfig) (*SimpleTrainer, error) <span class="cov0" title="0">{
        factory := NewFactory()
        return factory.CreateTrainer(config)
}</pre>
		
		<pre class="file" id="file11" style="display: none">package training

import (
        "encoding/json"
        "fmt"
        "math"
        "sort"
        "time"
)

// PlotType represents different types of plots that can be generated
type PlotType string

const (
        // Training plots
        TrainingCurves     PlotType = "training_curves"
        LearningRateSchedule PlotType = "learning_rate_schedule"
        
        // Evaluation plots
        ROCCurve           PlotType = "roc_curve"
        PrecisionRecall    PlotType = "precision_recall"
        ConfusionMatrixPlot PlotType = "confusion_matrix"
        
        // Model analysis plots
        ParameterDistribution PlotType = "parameter_distribution"
        GradientHistogram     PlotType = "gradient_histogram"
        ActivationPattern     PlotType = "activation_pattern"
        
        // Regression plots
        RegressionScatter     PlotType = "regression_scatter"
        ResidualPlot          PlotType = "residual_plot"
        QQPlot               PlotType = "qq_plot"
        FeatureImportancePlot PlotType = "feature_importance"
        LearningCurvePlot     PlotType = "learning_curve"
        ValidationCurvePlot   PlotType = "validation_curve"
        PredictionIntervalPlot PlotType = "prediction_interval"
        FeatureCorrelationPlot PlotType = "feature_correlation"
        PartialDependencePlot  PlotType = "partial_dependence"
)

// PlotData represents the universal JSON format for the sidecar plotting service
type PlotData struct {
        // Metadata
        PlotType    PlotType  `json:"plot_type"`
        Title       string    `json:"title"`
        Timestamp   time.Time `json:"timestamp"`
        ModelName   string    `json:"model_name"`
        
        // Data series - flexible structure for different plot types
        Series []SeriesData `json:"series"`
        
        // Plot configuration
        Config PlotConfig `json:"config"`
        
        // Metrics metadata
        Metrics map[string]interface{} `json:"metrics,omitempty"`
}

// SeriesData represents a single data series in a plot
type SeriesData struct {
        Name   string                 `json:"name"`
        Type   string                 `json:"type"`   // "line", "scatter", "histogram", "heatmap", "bar"
        Data   []DataPoint            `json:"data"`
        Style  map[string]interface{} `json:"style,omitempty"`
}

// DataPoint represents a single data point - flexible for different plot types
type DataPoint struct {
        X     interface{} `json:"x"`
        Y     interface{} `json:"y"`
        Z     interface{} `json:"z,omitempty"`     // For heatmaps, 3D plots
        Label string      `json:"label,omitempty"` // For categorical data
        Color string      `json:"color,omitempty"` // For custom coloring
}

// PlotConfig contains plot-specific configuration
type PlotConfig struct {
        XAxisLabel    string                 `json:"x_axis_label"`
        YAxisLabel    string                 `json:"y_axis_label"`
        ZAxisLabel    string                 `json:"z_axis_label,omitempty"`
        XAxisScale    string                 `json:"x_axis_scale"`    // "linear", "log"
        YAxisScale    string                 `json:"y_axis_scale"`    // "linear", "log"
        ShowLegend    bool                   `json:"show_legend"`
        ShowGrid      bool                   `json:"show_grid"`
        Width         int                    `json:"width"`
        Height        int                    `json:"height"`
        Interactive   bool                   `json:"interactive"`
        CustomOptions map[string]interface{} `json:"custom_options,omitempty"`
}

// VisualizationCollector handles data collection for plotting
type VisualizationCollector struct {
        modelName string
        enabled   bool
        
        // Training data
        trainingLoss     []float64
        trainingAccuracy []float64
        validationLoss   []float64
        validationAccuracy []float64
        epochs           []int
        steps            []int
        learningRates    []float64
        
        // Evaluation data
        rocPoints        []ROCPointViz
        prPoints         []PRPoint
        confusionMatrix  [][]int
        classNames       []string
        
        // Regression data
        predictions      []float64
        trueValues       []float64
        residuals        []float64
        featureNames     []string
        coefficients     []float64
        featureStdErrors []float64
        
        // Learning curve data
        trainingSizes     []int
        trainingScores    []float64
        validationScores  []float64
        trainingStdErrors []float64
        validationStdErrors []float64
        
        // Validation curve data
        parameterName         string
        parameterValues       []float64
        validationCurveTraining   []float64
        validationCurveValidation []float64
        validationCurveTrainingStd []float64
        validationCurveValidationStd []float64
        
        // Prediction interval data
        predictionIntervalX          []float64
        predictionIntervalY          []float64
        confidenceIntervalLower      []float64
        confidenceIntervalUpper      []float64
        predictionIntervalLower      []float64
        predictionIntervalUpper      []float64
        predictionStandardErrors     []float64
        
        // Feature correlation data
        correlationMatrix    [][]float64
        correlationFeatures  []string
        
        // Partial dependence data
        partialDependenceFeatures []string
        partialDependenceValues   [][]float64  // [feature_index][value_index]
        partialDependenceEffects  [][]float64  // [feature_index][value_index]
        
        // Model analysis data
        parameterStats   map[string]ParameterStats
        gradientStats    map[string]GradientStats
        activationStats  map[string]ActivationStats
}

// ROCPointViz represents a point on the ROC curve for visualization
type ROCPointViz struct {
        FPR       float64 `json:"fpr"`
        TPR       float64 `json:"tpr"`
        Threshold float64 `json:"threshold"`
}

// PRPoint represents a point on the Precision-Recall curve
type PRPoint struct {
        Precision float64 `json:"precision"`
        Recall    float64 `json:"recall"`
        Threshold float64 `json:"threshold"`
}

// ParameterStats represents parameter distribution statistics
type ParameterStats struct {
        LayerName string    `json:"layer_name"`
        ParamType string    `json:"param_type"` // "weight", "bias"
        Mean      float64   `json:"mean"`
        Std       float64   `json:"std"`
        Min       float64   `json:"min"`
        Max       float64   `json:"max"`
        Histogram []float64 `json:"histogram"`
        Bins      []float64 `json:"bins"`
}

// GradientStats represents gradient statistics
type GradientStats struct {
        LayerName     string    `json:"layer_name"`
        ParamType     string    `json:"param_type"`
        GradientNorm  float64   `json:"gradient_norm"`
        Mean          float64   `json:"mean"`
        Std           float64   `json:"std"`
        Histogram     []float64 `json:"histogram"`
        Bins          []float64 `json:"bins"`
}

// ActivationStats represents activation pattern statistics
type ActivationStats struct {
        LayerName     string    `json:"layer_name"`
        ActivationType string   `json:"activation_type"`
        Mean          float64   `json:"mean"`
        Std           float64   `json:"std"`
        SparsityRatio float64   `json:"sparsity_ratio"`
        Histogram     []float64 `json:"histogram"`
        Bins          []float64 `json:"bins"`
}

// NewVisualizationCollector creates a new visualization collector
func NewVisualizationCollector(modelName string) *VisualizationCollector <span class="cov8" title="1">{
        return &amp;VisualizationCollector{
                modelName:       modelName,
                enabled:         false,
                trainingLoss:    make([]float64, 0),
                trainingAccuracy: make([]float64, 0),
                validationLoss:  make([]float64, 0),
                validationAccuracy: make([]float64, 0),
                epochs:          make([]int, 0),
                steps:           make([]int, 0),
                learningRates:   make([]float64, 0),
                rocPoints:       make([]ROCPointViz, 0),
                prPoints:        make([]PRPoint, 0),
                predictions:     make([]float64, 0),
                trueValues:      make([]float64, 0),
                residuals:       make([]float64, 0),
                parameterStats:  make(map[string]ParameterStats),
                gradientStats:   make(map[string]GradientStats),
                activationStats: make(map[string]ActivationStats),
        }
}</span>

// Enable enables visualization data collection
func (vc *VisualizationCollector) Enable() <span class="cov0" title="0">{
        vc.enabled = true
}</span>

// Disable disables visualization data collection
func (vc *VisualizationCollector) Disable() <span class="cov0" title="0">{
        vc.enabled = false
}</span>

// IsEnabled returns whether visualization is enabled
func (vc *VisualizationCollector) IsEnabled() bool <span class="cov0" title="0">{
        return vc.enabled
}</span>

// RecordTrainingStep records training metrics for a single step
func (vc *VisualizationCollector) RecordTrainingStep(step int, loss, accuracy, learningRate float64) <span class="cov0" title="0">{
        if !vc.enabled </span><span class="cov0" title="0">{
                return
        }</span>
        
        <span class="cov0" title="0">vc.steps = append(vc.steps, step)
        vc.trainingLoss = append(vc.trainingLoss, loss)
        vc.trainingAccuracy = append(vc.trainingAccuracy, accuracy)
        vc.learningRates = append(vc.learningRates, learningRate)</span>
}

// RecordValidationStep records validation metrics for a single step
func (vc *VisualizationCollector) RecordValidationStep(step int, loss, accuracy float64) <span class="cov0" title="0">{
        if !vc.enabled </span><span class="cov0" title="0">{
                return
        }</span>
        
        <span class="cov0" title="0">vc.validationLoss = append(vc.validationLoss, loss)
        vc.validationAccuracy = append(vc.validationAccuracy, accuracy)</span>
}

// RecordEpoch records epoch-level metrics
func (vc *VisualizationCollector) RecordEpoch(epoch int, trainLoss, trainAcc, valLoss, valAcc float64) <span class="cov0" title="0">{
        if !vc.enabled </span><span class="cov0" title="0">{
                return
        }</span>
        
        <span class="cov0" title="0">vc.epochs = append(vc.epochs, epoch)</span>
        // Note: These will be used for epoch-level plots, separate from step-level data
}

// RecordROCData records ROC curve data points
func (vc *VisualizationCollector) RecordROCData(rocPoints []ROCPointViz) <span class="cov0" title="0">{
        if !vc.enabled </span><span class="cov0" title="0">{
                return
        }</span>
        
        <span class="cov0" title="0">vc.rocPoints = rocPoints</span>
}

// RecordPRData records Precision-Recall curve data points
func (vc *VisualizationCollector) RecordPRData(prPoints []PRPoint) <span class="cov0" title="0">{
        if !vc.enabled </span><span class="cov0" title="0">{
                return
        }</span>
        
        <span class="cov0" title="0">vc.prPoints = prPoints</span>
}

// RecordConfusionMatrix records confusion matrix data
func (vc *VisualizationCollector) RecordConfusionMatrix(matrix [][]int, classNames []string) <span class="cov0" title="0">{
        if !vc.enabled </span><span class="cov0" title="0">{
                return
        }</span>
        
        <span class="cov0" title="0">vc.confusionMatrix = matrix
        vc.classNames = classNames</span>
}

// RecordRegressionData records regression predictions and true values
func (vc *VisualizationCollector) RecordRegressionData(predictions, trueValues []float64) <span class="cov0" title="0">{
        if !vc.enabled </span><span class="cov0" title="0">{
                return
        }</span>
        
        <span class="cov0" title="0">vc.predictions = predictions
        vc.trueValues = trueValues
        
        // Calculate residuals
        vc.residuals = make([]float64, len(predictions))
        for i := range predictions </span><span class="cov0" title="0">{
                vc.residuals[i] = predictions[i] - trueValues[i]
        }</span>
}

// RecordFeatureImportance records feature names and their coefficients for regression models
func (vc *VisualizationCollector) RecordFeatureImportance(featureNames []string, coefficients []float64, stdErrors []float64) <span class="cov0" title="0">{
        if !vc.enabled </span><span class="cov0" title="0">{
                return
        }</span>
        
        <span class="cov0" title="0">vc.featureNames = featureNames
        vc.coefficients = coefficients
        vc.featureStdErrors = stdErrors</span>
}

// RecordLearningCurve records learning curve data showing performance vs training set size
func (vc *VisualizationCollector) RecordLearningCurve(trainingSizes []int, trainingScores, validationScores []float64, trainingStdErrors, validationStdErrors []float64) <span class="cov0" title="0">{
        if !vc.enabled </span><span class="cov0" title="0">{
                return
        }</span>
        
        <span class="cov0" title="0">vc.trainingSizes = trainingSizes
        vc.trainingScores = trainingScores
        vc.validationScores = validationScores
        vc.trainingStdErrors = trainingStdErrors
        vc.validationStdErrors = validationStdErrors</span>
}

// RecordValidationCurve records validation curve data showing performance vs hyperparameter values
func (vc *VisualizationCollector) RecordValidationCurve(parameterName string, parameterValues []float64, trainingScores, validationScores []float64, trainingStdErrors, validationStdErrors []float64) <span class="cov0" title="0">{
        if !vc.enabled </span><span class="cov0" title="0">{
                return
        }</span>
        
        <span class="cov0" title="0">vc.parameterName = parameterName
        vc.parameterValues = parameterValues
        vc.validationCurveTraining = trainingScores
        vc.validationCurveValidation = validationScores
        vc.validationCurveTrainingStd = trainingStdErrors
        vc.validationCurveValidationStd = validationStdErrors</span>
}

// RecordPredictionInterval records prediction interval data for regression uncertainty visualization
func (vc *VisualizationCollector) RecordPredictionInterval(x, y []float64, confidenceLower, confidenceUpper, predictionLower, predictionUpper, standardErrors []float64) <span class="cov0" title="0">{
        if !vc.enabled </span><span class="cov0" title="0">{
                return
        }</span>
        
        <span class="cov0" title="0">vc.predictionIntervalX = x
        vc.predictionIntervalY = y
        vc.confidenceIntervalLower = confidenceLower
        vc.confidenceIntervalUpper = confidenceUpper
        vc.predictionIntervalLower = predictionLower
        vc.predictionIntervalUpper = predictionUpper
        vc.predictionStandardErrors = standardErrors</span>
}

// RecordFeatureCorrelation records feature correlation matrix for multicollinearity analysis
func (vc *VisualizationCollector) RecordFeatureCorrelation(correlationMatrix [][]float64, featureNames []string) <span class="cov0" title="0">{
        if !vc.enabled </span><span class="cov0" title="0">{
                return
        }</span>
        
        <span class="cov0" title="0">vc.correlationMatrix = correlationMatrix
        vc.correlationFeatures = featureNames</span>
}

// RecordPartialDependence records partial dependence data for individual feature effect analysis
func (vc *VisualizationCollector) RecordPartialDependence(featureNames []string, featureValues [][]float64, partialEffects [][]float64) <span class="cov0" title="0">{
        if !vc.enabled </span><span class="cov0" title="0">{
                return
        }</span>
        
        <span class="cov0" title="0">vc.partialDependenceFeatures = featureNames
        vc.partialDependenceValues = featureValues
        vc.partialDependenceEffects = partialEffects</span>
}

// RecordParameterStats records parameter distribution statistics
func (vc *VisualizationCollector) RecordParameterStats(layerName, paramType string, stats ParameterStats) <span class="cov0" title="0">{
        if !vc.enabled </span><span class="cov0" title="0">{
                return
        }</span>
        
        <span class="cov0" title="0">key := fmt.Sprintf("%s_%s", layerName, paramType)
        vc.parameterStats[key] = stats</span>
}

// RecordGradientStats records gradient statistics
func (vc *VisualizationCollector) RecordGradientStats(layerName, paramType string, stats GradientStats) <span class="cov0" title="0">{
        if !vc.enabled </span><span class="cov0" title="0">{
                return
        }</span>
        
        <span class="cov0" title="0">key := fmt.Sprintf("%s_%s", layerName, paramType)
        vc.gradientStats[key] = stats</span>
}

// RecordActivationStats records activation pattern statistics
func (vc *VisualizationCollector) RecordActivationStats(layerName, activationType string, stats ActivationStats) <span class="cov0" title="0">{
        if !vc.enabled </span><span class="cov0" title="0">{
                return
        }</span>
        
        <span class="cov0" title="0">key := fmt.Sprintf("%s_%s", layerName, activationType)
        vc.activationStats[key] = stats</span>
}

// GenerateTrainingCurvesPlot generates training curves plot data
func (vc *VisualizationCollector) GenerateTrainingCurvesPlot() PlotData <span class="cov0" title="0">{
        series := []SeriesData{
                {
                        Name: "Training Loss",
                        Type: "line",
                        Data: make([]DataPoint, len(vc.trainingLoss)),
                        Style: map[string]interface{}{
                                "color": "#FF6B6B",
                                "line_width": 2,
                        },
                },
                {
                        Name: "Training Accuracy",
                        Type: "line",
                        Data: make([]DataPoint, len(vc.trainingAccuracy)),
                        Style: map[string]interface{}{
                                "color": "#4ECDC4",
                                "line_width": 2,
                        },
                },
        }
        
        // Add training loss data
        for i, loss := range vc.trainingLoss </span><span class="cov0" title="0">{
                series[0].Data[i] = DataPoint{
                        X: vc.steps[i],
                        Y: loss,
                }
        }</span>
        
        // Add training accuracy data
        <span class="cov0" title="0">for i, acc := range vc.trainingAccuracy </span><span class="cov0" title="0">{
                series[1].Data[i] = DataPoint{
                        X: vc.steps[i],
                        Y: acc,
                }
        }</span>
        
        // Add validation data if available
        <span class="cov0" title="0">if len(vc.validationLoss) &gt; 0 </span><span class="cov0" title="0">{
                valLossSeries := SeriesData{
                        Name: "Validation Loss",
                        Type: "line",
                        Data: make([]DataPoint, len(vc.validationLoss)),
                        Style: map[string]interface{}{
                                "color": "#FF9F43",
                                "line_width": 2,
                                "line_style": "dashed",
                        },
                }
                
                valAccSeries := SeriesData{
                        Name: "Validation Accuracy",
                        Type: "line",
                        Data: make([]DataPoint, len(vc.validationAccuracy)),
                        Style: map[string]interface{}{
                                "color": "#5F27CD",
                                "line_width": 2,
                                "line_style": "dashed",
                        },
                }
                
                for i, loss := range vc.validationLoss </span><span class="cov0" title="0">{
                        valLossSeries.Data[i] = DataPoint{
                                X: i + 1, // Validation step numbers
                                Y: loss,
                        }
                }</span>
                
                <span class="cov0" title="0">for i, acc := range vc.validationAccuracy </span><span class="cov0" title="0">{
                        valAccSeries.Data[i] = DataPoint{
                                X: i + 1, // Validation step numbers
                                Y: acc,
                        }
                }</span>
                
                <span class="cov0" title="0">series = append(series, valLossSeries, valAccSeries)</span>
        }
        
        <span class="cov0" title="0">return PlotData{
                PlotType:  TrainingCurves,
                Title:     fmt.Sprintf("Training Curves - %s", vc.modelName),
                Timestamp: time.Now(),
                ModelName: vc.modelName,
                Series:    series,
                Config: PlotConfig{
                        XAxisLabel:  "Step",
                        YAxisLabel:  "Loss / Accuracy",
                        XAxisScale:  "linear",
                        YAxisScale:  "linear",
                        ShowLegend:  true,
                        ShowGrid:    true,
                        Width:       800,
                        Height:      600,
                        Interactive: true,
                },
        }</span>
}

// GenerateLearningRateSchedulePlot generates learning rate schedule plot data
func (vc *VisualizationCollector) GenerateLearningRateSchedulePlot() PlotData <span class="cov0" title="0">{
        series := []SeriesData{
                {
                        Name: "Learning Rate",
                        Type: "line",
                        Data: make([]DataPoint, len(vc.learningRates)),
                        Style: map[string]interface{}{
                                "color": "#6C5CE7",
                                "line_width": 2,
                        },
                },
        }
        
        for i, lr := range vc.learningRates </span><span class="cov0" title="0">{
                series[0].Data[i] = DataPoint{
                        X: vc.steps[i],
                        Y: lr,
                }
        }</span>
        
        <span class="cov0" title="0">return PlotData{
                PlotType:  LearningRateSchedule,
                Title:     fmt.Sprintf("Learning Rate Schedule - %s", vc.modelName),
                Timestamp: time.Now(),
                ModelName: vc.modelName,
                Series:    series,
                Config: PlotConfig{
                        XAxisLabel:  "Step",
                        YAxisLabel:  "Learning Rate",
                        XAxisScale:  "linear",
                        YAxisScale:  "log",
                        ShowLegend:  true,
                        ShowGrid:    true,
                        Width:       800,
                        Height:      400,
                        Interactive: true,
                },
        }</span>
}

// GenerateROCCurvePlot generates ROC curve plot data
func (vc *VisualizationCollector) GenerateROCCurvePlot() PlotData <span class="cov0" title="0">{
        series := []SeriesData{
                {
                        Name: "ROC Curve",
                        Type: "line",
                        Data: make([]DataPoint, len(vc.rocPoints)),
                        Style: map[string]interface{}{
                                "color": "#FF6B6B",
                                "line_width": 2,
                        },
                },
                {
                        Name: "Random Classifier",
                        Type: "line",
                        Data: []DataPoint{
                                {X: 0.0, Y: 0.0},
                                {X: 1.0, Y: 1.0},
                        },
                        Style: map[string]interface{}{
                                "color": "#95A5A6",
                                "line_width": 1,
                                "line_style": "dashed",
                        },
                },
        }
        
        for i, point := range vc.rocPoints </span><span class="cov0" title="0">{
                series[0].Data[i] = DataPoint{
                        X: point.FPR,
                        Y: point.TPR,
                }
        }</span>
        
        <span class="cov0" title="0">return PlotData{
                PlotType:  ROCCurve,
                Title:     fmt.Sprintf("ROC Curve - %s", vc.modelName),
                Timestamp: time.Now(),
                ModelName: vc.modelName,
                Series:    series,
                Config: PlotConfig{
                        XAxisLabel:  "False Positive Rate",
                        YAxisLabel:  "True Positive Rate",
                        XAxisScale:  "linear",
                        YAxisScale:  "linear",
                        ShowLegend:  true,
                        ShowGrid:    true,
                        Width:       600,
                        Height:      600,
                        Interactive: true,
                },
        }</span>
}

// GeneratePrecisionRecallPlot generates Precision-Recall curve plot data
func (vc *VisualizationCollector) GeneratePrecisionRecallPlot() PlotData <span class="cov0" title="0">{
        series := []SeriesData{
                {
                        Name: "Precision-Recall Curve",
                        Type: "line",
                        Data: make([]DataPoint, len(vc.prPoints)),
                        Style: map[string]interface{}{
                                "color": "#4ECDC4",
                                "line_width": 2,
                        },
                },
        }
        
        for i, point := range vc.prPoints </span><span class="cov0" title="0">{
                series[0].Data[i] = DataPoint{
                        X: point.Recall,
                        Y: point.Precision,
                }
        }</span>
        
        <span class="cov0" title="0">return PlotData{
                PlotType:  PrecisionRecall,
                Title:     fmt.Sprintf("Precision-Recall Curve - %s", vc.modelName),
                Timestamp: time.Now(),
                ModelName: vc.modelName,
                Series:    series,
                Config: PlotConfig{
                        XAxisLabel:  "Recall",
                        YAxisLabel:  "Precision",
                        XAxisScale:  "linear",
                        YAxisScale:  "linear",
                        ShowLegend:  true,
                        ShowGrid:    true,
                        Width:       600,
                        Height:      600,
                        Interactive: true,
                },
        }</span>
}

// GenerateConfusionMatrixPlot generates confusion matrix plot data
func (vc *VisualizationCollector) GenerateConfusionMatrixPlot() PlotData <span class="cov0" title="0">{
        if len(vc.confusionMatrix) == 0 </span><span class="cov0" title="0">{
                return PlotData{}
        }</span>
        
        <span class="cov0" title="0">var data []DataPoint
        for i, row := range vc.confusionMatrix </span><span class="cov0" title="0">{
                for j, value := range row </span><span class="cov0" title="0">{
                        data = append(data, DataPoint{
                                X: j,
                                Y: i,
                                Z: value,
                                Label: fmt.Sprintf("True: %s, Pred: %s", vc.classNames[i], vc.classNames[j]),
                        })
                }</span>
        }
        
        <span class="cov0" title="0">series := []SeriesData{
                {
                        Name: "Confusion Matrix",
                        Type: "heatmap",
                        Data: data,
                        Style: map[string]interface{}{
                                "colorscale": "Blues",
                        },
                },
        }
        
        return PlotData{
                PlotType:  ConfusionMatrixPlot,
                Title:     fmt.Sprintf("Confusion Matrix - %s", vc.modelName),
                Timestamp: time.Now(),
                ModelName: vc.modelName,
                Series:    series,
                Config: PlotConfig{
                        XAxisLabel:  "Predicted Class",
                        YAxisLabel:  "True Class",
                        XAxisScale:  "linear",
                        YAxisScale:  "linear",
                        ShowLegend:  false,
                        ShowGrid:    false,
                        Width:       600,
                        Height:      600,
                        Interactive: true,
                        CustomOptions: map[string]interface{}{
                                "class_names": vc.classNames,
                        },
                },
        }</span>
}

// GenerateRegressionScatterPlot generates regression scatter plot data
func (vc *VisualizationCollector) GenerateRegressionScatterPlot() PlotData <span class="cov0" title="0">{
        if len(vc.predictions) == 0 </span><span class="cov0" title="0">{
                return PlotData{}
        }</span>
        
        // Scatter plot data
        <span class="cov0" title="0">scatterData := make([]DataPoint, len(vc.predictions))
        for i := range vc.predictions </span><span class="cov0" title="0">{
                scatterData[i] = DataPoint{
                        X: vc.trueValues[i],
                        Y: vc.predictions[i],
                }
        }</span>
        
        // Perfect prediction line
        <span class="cov0" title="0">minVal := vc.trueValues[0]
        maxVal := vc.trueValues[0]
        for _, val := range vc.trueValues </span><span class="cov0" title="0">{
                if val &lt; minVal </span><span class="cov0" title="0">{
                        minVal = val
                }</span>
                <span class="cov0" title="0">if val &gt; maxVal </span><span class="cov0" title="0">{
                        maxVal = val
                }</span>
        }
        
        <span class="cov0" title="0">perfectLine := []DataPoint{
                {X: minVal, Y: minVal},
                {X: maxVal, Y: maxVal},
        }
        
        series := []SeriesData{
                {
                        Name: "Predictions",
                        Type: "scatter",
                        Data: scatterData,
                        Style: map[string]interface{}{
                                "color": "#4ECDC4",
                                "alpha": 0.6,
                        },
                },
                {
                        Name: "Perfect Prediction",
                        Type: "line",
                        Data: perfectLine,
                        Style: map[string]interface{}{
                                "color": "#FF6B6B",
                                "line_width": 2,
                                "line_style": "dashed",
                        },
                },
        }
        
        return PlotData{
                PlotType:  RegressionScatter,
                Title:     fmt.Sprintf("Regression Scatter Plot - %s", vc.modelName),
                Timestamp: time.Now(),
                ModelName: vc.modelName,
                Series:    series,
                Config: PlotConfig{
                        XAxisLabel:  "True Values",
                        YAxisLabel:  "Predicted Values",
                        XAxisScale:  "linear",
                        YAxisScale:  "linear",
                        ShowLegend:  true,
                        ShowGrid:    true,
                        Width:       600,
                        Height:      600,
                        Interactive: true,
                },
        }</span>
}

// GenerateResidualPlot generates residual plot data
func (vc *VisualizationCollector) GenerateResidualPlot() PlotData <span class="cov0" title="0">{
        if len(vc.residuals) == 0 </span><span class="cov0" title="0">{
                return PlotData{}
        }</span>
        
        <span class="cov0" title="0">residualData := make([]DataPoint, len(vc.residuals))
        for i := range vc.residuals </span><span class="cov0" title="0">{
                residualData[i] = DataPoint{
                        X: vc.predictions[i],
                        Y: vc.residuals[i],
                }
        }</span>
        
        // Zero line
        <span class="cov0" title="0">minPred := vc.predictions[0]
        maxPred := vc.predictions[0]
        for _, pred := range vc.predictions </span><span class="cov0" title="0">{
                if pred &lt; minPred </span><span class="cov0" title="0">{
                        minPred = pred
                }</span>
                <span class="cov0" title="0">if pred &gt; maxPred </span><span class="cov0" title="0">{
                        maxPred = pred
                }</span>
        }
        
        <span class="cov0" title="0">zeroLine := []DataPoint{
                {X: minPred, Y: 0.0},
                {X: maxPred, Y: 0.0},
        }
        
        series := []SeriesData{
                {
                        Name: "Residuals",
                        Type: "scatter",
                        Data: residualData,
                        Style: map[string]interface{}{
                                "color": "#FF9F43",
                                "alpha": 0.6,
                        },
                },
                {
                        Name: "Zero Line",
                        Type: "line",
                        Data: zeroLine,
                        Style: map[string]interface{}{
                                "color": "#95A5A6",
                                "line_width": 1,
                                "line_style": "dashed",
                        },
                },
        }
        
        return PlotData{
                PlotType:  ResidualPlot,
                Title:     fmt.Sprintf("Residual Plot - %s", vc.modelName),
                Timestamp: time.Now(),
                ModelName: vc.modelName,
                Series:    series,
                Config: PlotConfig{
                        XAxisLabel:  "Predicted Values",
                        YAxisLabel:  "Residuals",
                        XAxisScale:  "linear",
                        YAxisScale:  "linear",
                        ShowLegend:  true,
                        ShowGrid:    true,
                        Width:       600,
                        Height:      600,
                        Interactive: true,
                },
        }</span>
}

// GenerateQQPlot generates Q-Q plot data for validating normal distribution of residuals
func (vc *VisualizationCollector) GenerateQQPlot() PlotData <span class="cov0" title="0">{
        if len(vc.residuals) == 0 </span><span class="cov0" title="0">{
                return PlotData{}
        }</span>
        
        // Sort residuals
        <span class="cov0" title="0">sortedResiduals := make([]float64, len(vc.residuals))
        copy(sortedResiduals, vc.residuals)
        sort.Float64s(sortedResiduals)
        
        n := len(sortedResiduals)
        qqData := make([]DataPoint, n)
        
        // Calculate sample quantiles and theoretical normal quantiles
        for i := 0; i &lt; n; i++ </span><span class="cov0" title="0">{
                // Sample quantile (sorted residuals)
                sampleQuantile := sortedResiduals[i]
                
                // Theoretical quantile for standard normal distribution
                // Using approximation for normal quantiles
                p := float64(i+1) / float64(n+1) // Plotting position
                theoreticalQuantile := normalQuantile(p)
                
                qqData[i] = DataPoint{
                        X: theoreticalQuantile,
                        Y: sampleQuantile,
                }
        }</span>
        
        // Create reference line (perfect normal distribution)
        // Line goes from min to max of theoretical quantiles
        <span class="cov0" title="0">minTheoreticalQ := normalQuantile(1.0 / float64(n+1))
        maxTheoreticalQ := normalQuantile(float64(n) / float64(n+1))
        
        // Calculate slope and intercept for reference line
        // Use sample standard deviation and mean for scaling
        mean, stddev := calculateMeanAndStd(vc.residuals)
        
        referenceLine := []DataPoint{
                {X: minTheoreticalQ, Y: mean + stddev*minTheoreticalQ},
                {X: maxTheoreticalQ, Y: mean + stddev*maxTheoreticalQ},
        }
        
        series := []SeriesData{
                {
                        Name: "Sample Quantiles",
                        Type: "scatter",
                        Data: qqData,
                        Style: map[string]interface{}{
                                "color": "#4ECDC4",
                                "alpha": 0.7,
                                "size":  6,
                        },
                },
                {
                        Name: "Normal Reference Line",
                        Type: "line",
                        Data: referenceLine,
                        Style: map[string]interface{}{
                                "color": "#FF6B6B",
                                "line_width": 2,
                                "line_style": "dashed",
                        },
                },
        }
        
        return PlotData{
                PlotType:  QQPlot,
                Title:     fmt.Sprintf("Q-Q Plot - %s", vc.modelName),
                Timestamp: time.Now(),
                ModelName: vc.modelName,
                Series:    series,
                Config: PlotConfig{
                        XAxisLabel:  "Theoretical Quantiles",
                        YAxisLabel:  "Sample Quantiles",
                        XAxisScale:  "linear",
                        YAxisScale:  "linear",
                        ShowLegend:  true,
                        ShowGrid:    true,
                        Width:       600,
                        Height:      600,
                        Interactive: true,
                        CustomOptions: map[string]interface{}{
                                "subtitle": "Normal Q-Q Plot for Residuals - Tests normality assumption",
                        },
                },
                Metrics: map[string]interface{}{
                        "sample_mean": mean,
                        "sample_std":  stddev,
                        "sample_size": n,
                },
        }</span>
}

// GenerateFeatureImportancePlot generates feature importance plot data
func (vc *VisualizationCollector) GenerateFeatureImportancePlot() PlotData <span class="cov0" title="0">{
        if len(vc.coefficients) == 0 || len(vc.featureNames) == 0 </span><span class="cov0" title="0">{
                return PlotData{}
        }</span>
        
        // Calculate absolute importance (abs coefficient values)
        <span class="cov0" title="0">n := len(vc.coefficients)
        importanceData := make([]DataPoint, n)
        
        // Create pairs of (feature, importance) for sorting
        type featureImportance struct {
                name       string
                coefficient float64
                absValue   float64
                stdError   float64
        }
        
        features := make([]featureImportance, n)
        for i := 0; i &lt; n; i++ </span><span class="cov0" title="0">{
                stdErr := float64(0)
                if len(vc.featureStdErrors) &gt; i </span><span class="cov0" title="0">{
                        stdErr = vc.featureStdErrors[i]
                }</span>
                
                <span class="cov0" title="0">features[i] = featureImportance{
                        name:       vc.featureNames[i],
                        coefficient: vc.coefficients[i],
                        absValue:   math.Abs(vc.coefficients[i]),
                        stdError:   stdErr,
                }</span>
        }
        
        // Sort by absolute importance (descending)
        <span class="cov0" title="0">sort.Slice(features, func(i, j int) bool </span><span class="cov0" title="0">{
                return features[i].absValue &gt; features[j].absValue
        }</span>)
        
        // Create data points for horizontal bar chart
        <span class="cov0" title="0">for i, feat := range features </span><span class="cov0" title="0">{
                importanceData[i] = DataPoint{
                        X:     feat.coefficient,
                        Y:     float64(i), // Y position for horizontal bars
                        Label: feat.name,
                }
        }</span>
        
        // Calculate confidence intervals if standard errors are available
        <span class="cov0" title="0">var errorBars []DataPoint
        if len(vc.featureStdErrors) &gt; 0 </span><span class="cov0" title="0">{
                errorBars = make([]DataPoint, n)
                for i, feat := range features </span><span class="cov0" title="0">{
                        // 95% confidence interval (1.96 * standard error)
                        margin := 1.96 * feat.stdError
                        errorBars[i] = DataPoint{
                                X: margin,
                                Y: float64(i),
                        }
                }</span>
        }
        
        // Create colors based on coefficient sign
        <span class="cov0" title="0">colors := make([]string, n)
        for i, feat := range features </span><span class="cov0" title="0">{
                if feat.coefficient &gt; 0 </span><span class="cov0" title="0">{
                        colors[i] = "#2ECC71" // Green for positive
                }</span> else<span class="cov0" title="0"> {
                        colors[i] = "#E74C3C" // Red for negative
                }</span>
        }
        
        <span class="cov0" title="0">series := []SeriesData{
                {
                        Name: "Feature Coefficients",
                        Type: "bar",
                        Data: importanceData,
                        Style: map[string]interface{}{
                                "orientation": "horizontal",
                                "colors": colors, // Pass the pre-calculated colors array
                                "alpha": 0.8,
                        },
                },
        }
        
        // Add error bars if available
        if len(errorBars) &gt; 0 </span><span class="cov0" title="0">{
                series = append(series, SeriesData{
                        Name: "95% Confidence Interval",
                        Type: "errorbar",
                        Data: errorBars,
                        Style: map[string]interface{}{
                                "color": "#34495E",
                                "width": 2,
                                "capsize": 5,
                        },
                })
        }</span>
        
        // Get feature labels in sorted order
        <span class="cov0" title="0">featureLabels := make([]string, n)
        for i, feat := range features </span><span class="cov0" title="0">{
                featureLabels[i] = feat.name
        }</span>
        
        // Create descriptive title using model name if available
        <span class="cov0" title="0">title := "Feature Importance Analysis"
        if vc.modelName != "" &amp;&amp; vc.modelName != "Model" </span><span class="cov0" title="0">{
                title = vc.modelName + " - Feature Importance"
        }</span>
        
        <span class="cov0" title="0">return PlotData{
                PlotType:  FeatureImportancePlot,
                Title:     title,
                Timestamp: time.Now(),
                ModelName: vc.modelName,
                Series:    series,
                Config: PlotConfig{
                        XAxisLabel:  "Coefficient Value",
                        YAxisLabel:  "Features",
                        XAxisScale:  "linear",
                        ShowLegend:  len(errorBars) &gt; 0,
                        ShowGrid:    true,
                        Width:       800,
                        Height:      max(400, n*40), // Dynamic height based on feature count
                        Interactive: true,
                        CustomOptions: map[string]interface{}{
                                "yTickLabels": featureLabels,
                                "zeroline":    true,
                                "subtitle":    "Regression coefficients showing feature contribution",
                        },
                },
                Metrics: map[string]interface{}{
                        "num_features": n,
                        "top_feature":  features[0].name,
                        "top_coeff":    features[0].coefficient,
                },
        }</span>
}

// GenerateLearningCurvePlot generates learning curve plot data showing performance vs training set size
func (vc *VisualizationCollector) GenerateLearningCurvePlot() PlotData <span class="cov0" title="0">{
        if len(vc.trainingSizes) == 0 || len(vc.trainingScores) == 0 || len(vc.validationScores) == 0 </span><span class="cov0" title="0">{
                return PlotData{}
        }</span>
        
        <span class="cov0" title="0">n := len(vc.trainingSizes)
        
        // Create training score data points
        trainingData := make([]DataPoint, n)
        for i := 0; i &lt; n; i++ </span><span class="cov0" title="0">{
                trainingData[i] = DataPoint{
                        X: float64(vc.trainingSizes[i]),
                        Y: vc.trainingScores[i],
                }
        }</span>
        
        // Create validation score data points
        <span class="cov0" title="0">validationData := make([]DataPoint, n)
        for i := 0; i &lt; n; i++ </span><span class="cov0" title="0">{
                validationData[i] = DataPoint{
                        X: float64(vc.trainingSizes[i]),
                        Y: vc.validationScores[i],
                }
        }</span>
        
        <span class="cov0" title="0">series := []SeriesData{
                {
                        Name: "Training Score",
                        Type: "line",
                        Data: trainingData,
                        Style: map[string]interface{}{
                                "color":      "#2ECC71",
                                "line_width": 2,
                                "marker":     "circle",
                                "alpha":      0.8,
                        },
                },
                {
                        Name: "Validation Score",
                        Type: "line",
                        Data: validationData,
                        Style: map[string]interface{}{
                                "color":      "#E74C3C",
                                "line_width": 2,
                                "marker":     "circle",
                                "alpha":      0.8,
                        },
                },
        }
        
        // Add error bands if standard errors are available
        if len(vc.trainingStdErrors) &gt; 0 &amp;&amp; len(vc.validationStdErrors) &gt; 0 </span><span class="cov0" title="0">{
                // Training error band (upper and lower bounds)
                trainingUpperBand := make([]DataPoint, n)
                trainingLowerBand := make([]DataPoint, n)
                for i := 0; i &lt; n; i++ </span><span class="cov0" title="0">{
                        trainingUpperBand[i] = DataPoint{
                                X: float64(vc.trainingSizes[i]),
                                Y: vc.trainingScores[i] + vc.trainingStdErrors[i],
                        }
                        trainingLowerBand[i] = DataPoint{
                                X: float64(vc.trainingSizes[i]),
                                Y: vc.trainingScores[i] - vc.trainingStdErrors[i],
                        }
                }</span>
                
                // Validation error band
                <span class="cov0" title="0">validationUpperBand := make([]DataPoint, n)
                validationLowerBand := make([]DataPoint, n)
                for i := 0; i &lt; n; i++ </span><span class="cov0" title="0">{
                        validationUpperBand[i] = DataPoint{
                                X: float64(vc.trainingSizes[i]),
                                Y: vc.validationScores[i] + vc.validationStdErrors[i],
                        }
                        validationLowerBand[i] = DataPoint{
                                X: float64(vc.trainingSizes[i]),
                                Y: vc.validationScores[i] - vc.validationStdErrors[i],
                        }
                }</span>
                
                // Add error band series
                <span class="cov0" title="0">series = append(series, SeriesData{
                        Name: "Training Error Band",
                        Type: "fill",
                        Data: append(trainingUpperBand, reverse(trainingLowerBand)...),
                        Style: map[string]interface{}{
                                "color": "#2ECC71",
                                "alpha": 0.2,
                                "fill":  "tonexty",
                        },
                })
                
                series = append(series, SeriesData{
                        Name: "Validation Error Band",
                        Type: "fill",
                        Data: append(validationUpperBand, reverse(validationLowerBand)...),
                        Style: map[string]interface{}{
                                "color": "#E74C3C",
                                "alpha": 0.2,
                                "fill":  "tonexty",
                        },
                })</span>
        }
        
        // Calculate analysis metrics
        <span class="cov0" title="0">finalTrainingScore := vc.trainingScores[n-1]
        finalValidationScore := vc.validationScores[n-1]
        gap := math.Abs(finalTrainingScore - finalValidationScore)
        
        // Determine learning curve characteristics
        var diagnosis string
        if gap &gt; 0.1 &amp;&amp; finalTrainingScore &gt; finalValidationScore </span><span class="cov0" title="0">{
                diagnosis = "Overfitting detected"
        }</span> else<span class="cov0" title="0"> if finalTrainingScore &lt; 0.7 &amp;&amp; finalValidationScore &lt; 0.7 </span><span class="cov0" title="0">{
                diagnosis = "Underfitting detected"
        }</span> else<span class="cov0" title="0"> if gap &lt; 0.05 </span><span class="cov0" title="0">{
                diagnosis = "Good fit"
        }</span> else<span class="cov0" title="0"> {
                diagnosis = "Slight overfitting"
        }</span>
        
        <span class="cov0" title="0">return PlotData{
                PlotType:  LearningCurvePlot,
                Title:     "Learning Curve Analysis",
                Timestamp: time.Now(),
                ModelName: vc.modelName,
                Series:    series,
                Config: PlotConfig{
                        XAxisLabel:  "Training Set Size",
                        YAxisLabel:  "Score",
                        XAxisScale:  "linear",
                        YAxisScale:  "linear",
                        ShowLegend:  true,
                        ShowGrid:    true,
                        Width:       800,
                        Height:      600,
                        Interactive: true,
                        CustomOptions: map[string]interface{}{
                                "subtitle": "Performance vs Training Set Size - Diagnose overfitting/underfitting",
                                "diagnosis": diagnosis,
                        },
                },
                Metrics: map[string]interface{}{
                        "final_training_score":   finalTrainingScore,
                        "final_validation_score": finalValidationScore,
                        "training_val_gap":       gap,
                        "num_training_sizes":     n,
                        "diagnosis":             diagnosis,
                },
        }</span>
}

// GenerateValidationCurvePlot generates validation curve plot data showing performance vs hyperparameter values
func (vc *VisualizationCollector) GenerateValidationCurvePlot() PlotData <span class="cov0" title="0">{
        // Create descriptive title using model name if available
        title := "Validation Curve Analysis"
        if vc.modelName != "" &amp;&amp; vc.modelName != "Model" </span><span class="cov0" title="0">{
                title = vc.modelName + " - Validation Curve"
        }</span>
        
        <span class="cov0" title="0">if len(vc.parameterValues) == 0 || len(vc.validationCurveTraining) == 0 </span><span class="cov0" title="0">{
                return PlotData{
                        PlotType:  ValidationCurvePlot,
                        Title:     title,
                        Timestamp: time.Now(),
                        ModelName: vc.modelName,
                        Series:    []SeriesData{},
                }
        }</span>
        
        <span class="cov0" title="0">n := len(vc.parameterValues)
        
        // Helper function to reverse slice for error band plotting
        reverse := func(data []DataPoint) []DataPoint </span><span class="cov0" title="0">{
                reversed := make([]DataPoint, len(data))
                for i, point := range data </span><span class="cov0" title="0">{
                        reversed[len(data)-1-i] = point
                }</span>
                <span class="cov0" title="0">return reversed</span>
        }
        
        // Create training score series
        <span class="cov0" title="0">trainingSeries := SeriesData{
                Name: "Training Score",
                Type: "line",
                Data: make([]DataPoint, n),
                Style: map[string]interface{}{
                        "color": "#2ECC71",
                        "width": 2,
                },
        }
        
        for i := 0; i &lt; n; i++ </span><span class="cov0" title="0">{
                trainingSeries.Data[i] = DataPoint{
                        X: vc.parameterValues[i],
                        Y: vc.validationCurveTraining[i],
                }
        }</span>
        
        // Create validation score series
        <span class="cov0" title="0">validationSeries := SeriesData{
                Name: "Validation Score",
                Type: "line",
                Data: make([]DataPoint, n),
                Style: map[string]interface{}{
                        "color": "#E74C3C",
                        "width": 2,
                },
        }
        
        for i := 0; i &lt; n; i++ </span><span class="cov0" title="0">{
                validationSeries.Data[i] = DataPoint{
                        X: vc.parameterValues[i],
                        Y: vc.validationCurveValidation[i],
                }
        }</span>
        
        <span class="cov0" title="0">series := []SeriesData{trainingSeries, validationSeries}
        
        // Add error bands if standard errors are available
        if len(vc.validationCurveTrainingStd) == n &amp;&amp; len(vc.validationCurveValidationStd) == n </span><span class="cov0" title="0">{
                // Training error band
                trainingUpperBand := make([]DataPoint, n)
                trainingLowerBand := make([]DataPoint, n)
                
                for i := 0; i &lt; n; i++ </span><span class="cov0" title="0">{
                        upper := vc.validationCurveTraining[i] + vc.validationCurveTrainingStd[i]
                        lower := vc.validationCurveTraining[i] - vc.validationCurveTrainingStd[i]
                        
                        trainingUpperBand[i] = DataPoint{X: vc.parameterValues[i], Y: upper}
                        trainingLowerBand[i] = DataPoint{X: vc.parameterValues[i], Y: lower}
                }</span>
                
                <span class="cov0" title="0">series = append(series, SeriesData{
                        Name: "Training Error Band",
                        Type: "fill",
                        Data: append(trainingUpperBand, reverse(trainingLowerBand)...),
                        Style: map[string]interface{}{
                                "color": "#2ECC71",
                                "alpha": 0.2,
                                "fill":  "tonexty",
                        },
                })
                
                // Validation error band
                validationUpperBand := make([]DataPoint, n)
                validationLowerBand := make([]DataPoint, n)
                
                for i := 0; i &lt; n; i++ </span><span class="cov0" title="0">{
                        upper := vc.validationCurveValidation[i] + vc.validationCurveValidationStd[i]
                        lower := vc.validationCurveValidation[i] - vc.validationCurveValidationStd[i]
                        
                        validationUpperBand[i] = DataPoint{X: vc.parameterValues[i], Y: upper}
                        validationLowerBand[i] = DataPoint{X: vc.parameterValues[i], Y: lower}
                }</span>
                
                <span class="cov0" title="0">series = append(series, SeriesData{
                        Name: "Validation Error Band",
                        Type: "fill",
                        Data: append(validationUpperBand, reverse(validationLowerBand)...),
                        Style: map[string]interface{}{
                                "color": "#E74C3C",
                                "alpha": 0.2,
                                "fill":  "tonexty",
                        },
                })</span>
        }
        
        // Find optimal parameter value (highest validation score)
        <span class="cov0" title="0">optimalIndex := 0
        maxValidationScore := vc.validationCurveValidation[0]
        for i := 1; i &lt; n; i++ </span><span class="cov0" title="0">{
                if vc.validationCurveValidation[i] &gt; maxValidationScore </span><span class="cov0" title="0">{
                        maxValidationScore = vc.validationCurveValidation[i]
                        optimalIndex = i
                }</span>
        }
        
        <span class="cov0" title="0">optimalValue := vc.parameterValues[optimalIndex]
        
        // Calculate analysis metrics
        finalTrainingScore := vc.validationCurveTraining[n-1]
        finalValidationScore := vc.validationCurveValidation[n-1]
        gap := math.Abs(finalTrainingScore - finalValidationScore)
        
        // Determine validation curve characteristics
        var diagnosis string
        if maxValidationScore == vc.validationCurveValidation[0] || maxValidationScore == vc.validationCurveValidation[n-1] </span><span class="cov0" title="0">{
                diagnosis = "Optimal value at boundary - consider expanding search range"
        }</span> else<span class="cov0" title="0"> if gap &gt; 0.1 </span><span class="cov0" title="0">{
                diagnosis = "Large training-validation gap - possible overfitting"
        }</span> else<span class="cov0" title="0"> if maxValidationScore &lt; 0.7 </span><span class="cov0" title="0">{
                diagnosis = "Low performance - consider different hyperparameter ranges"
        }</span> else<span class="cov0" title="0"> {
                diagnosis = "Good hyperparameter range found"
        }</span>
        
        <span class="cov0" title="0">return PlotData{
                PlotType:  ValidationCurvePlot,
                Title:     title,
                Timestamp: time.Now(),
                ModelName: vc.modelName,
                Series:    series,
                Config: PlotConfig{
                        XAxisLabel:  vc.parameterName,
                        YAxisLabel:  "Score",
                        XAxisScale:  "linear",
                        YAxisScale:  "linear",
                        ShowLegend:  true,
                        ShowGrid:    true,
                        Width:       800,
                        Height:      600,
                        Interactive: true,
                        CustomOptions: map[string]interface{}{
                                "subtitle": fmt.Sprintf("Performance vs %s - Hyperparameter tuning", vc.parameterName),
                                "diagnosis": diagnosis,
                                "optimal_value": optimalValue,
                        },
                },
                Metrics: map[string]interface{}{
                        "parameter_name":        vc.parameterName,
                        "optimal_value":         optimalValue,
                        "optimal_validation_score": maxValidationScore,
                        "final_training_score":  finalTrainingScore,
                        "final_validation_score": finalValidationScore,
                        "training_val_gap":      gap,
                        "num_parameter_values":  n,
                        "diagnosis":            diagnosis,
                },
        }</span>
}

// GeneratePredictionIntervalPlot generates prediction interval plot data showing prediction uncertainty
func (vc *VisualizationCollector) GeneratePredictionIntervalPlot() PlotData <span class="cov0" title="0">{
        // Create descriptive title using model name if available
        title := "Prediction Interval Analysis"
        if vc.modelName != "" &amp;&amp; vc.modelName != "Model" </span><span class="cov0" title="0">{
                title = vc.modelName + " - Prediction Intervals"
        }</span>
        
        <span class="cov0" title="0">if len(vc.predictionIntervalX) == 0 || len(vc.predictionIntervalY) == 0 </span><span class="cov0" title="0">{
                return PlotData{
                        PlotType:  PredictionIntervalPlot,
                        Title:     title,
                        Timestamp: time.Now(),
                        ModelName: vc.modelName,
                        Series:    []SeriesData{},
                }
        }</span>
        
        <span class="cov0" title="0">n := len(vc.predictionIntervalX)
        
        // Create the main prediction line
        predictionData := make([]DataPoint, n)
        for i := 0; i &lt; n; i++ </span><span class="cov0" title="0">{
                predictionData[i] = DataPoint{
                        X: vc.predictionIntervalX[i],
                        Y: vc.predictionIntervalY[i],
                }
        }</span>
        
        <span class="cov0" title="0">series := []SeriesData{
                {
                        Name: "Predictions",
                        Type: "line",
                        Data: predictionData,
                        Style: map[string]interface{}{
                                "color": "#2E86AB",
                                "width": 2,
                        },
                },
        }
        
        // Add confidence interval if available
        if len(vc.confidenceIntervalLower) == n &amp;&amp; len(vc.confidenceIntervalUpper) == n </span><span class="cov0" title="0">{
                // Create confidence interval band
                confidenceData := make([]DataPoint, 2*n)
                
                // Upper band
                for i := 0; i &lt; n; i++ </span><span class="cov0" title="0">{
                        confidenceData[i] = DataPoint{
                                X: vc.predictionIntervalX[i],
                                Y: vc.confidenceIntervalUpper[i],
                        }
                }</span>
                
                // Lower band (reversed order for fill)
                <span class="cov0" title="0">for i := 0; i &lt; n; i++ </span><span class="cov0" title="0">{
                        confidenceData[n+i] = DataPoint{
                                X: vc.predictionIntervalX[n-1-i],
                                Y: vc.confidenceIntervalLower[n-1-i],
                        }
                }</span>
                
                <span class="cov0" title="0">series = append(series, SeriesData{
                        Name: "Confidence Interval (95%)",
                        Type: "fill",
                        Data: confidenceData,
                        Style: map[string]interface{}{
                                "color": "#2E86AB",
                                "alpha": 0.3,
                                "fill":  "tonexty",
                        },
                })</span>
        }
        
        // Add prediction interval if available
        <span class="cov0" title="0">if len(vc.predictionIntervalLower) == n &amp;&amp; len(vc.predictionIntervalUpper) == n </span><span class="cov0" title="0">{
                // Create prediction interval band
                predictionBandData := make([]DataPoint, 2*n)
                
                // Upper band
                for i := 0; i &lt; n; i++ </span><span class="cov0" title="0">{
                        predictionBandData[i] = DataPoint{
                                X: vc.predictionIntervalX[i],
                                Y: vc.predictionIntervalUpper[i],
                        }
                }</span>
                
                // Lower band (reversed order for fill)
                <span class="cov0" title="0">for i := 0; i &lt; n; i++ </span><span class="cov0" title="0">{
                        predictionBandData[n+i] = DataPoint{
                                X: vc.predictionIntervalX[n-1-i],
                                Y: vc.predictionIntervalLower[n-1-i],
                        }
                }</span>
                
                <span class="cov0" title="0">series = append(series, SeriesData{
                        Name: "Prediction Interval (95%)",
                        Type: "fill",
                        Data: predictionBandData,
                        Style: map[string]interface{}{
                                "color": "#F24236",
                                "alpha": 0.2,
                                "fill":  "tonexty",
                        },
                })</span>
        }
        
        // Calculate diagnostic metrics
        <span class="cov0" title="0">var meanStdError float64
        if len(vc.predictionStandardErrors) &gt; 0 </span><span class="cov0" title="0">{
                sum := 0.0
                for _, se := range vc.predictionStandardErrors </span><span class="cov0" title="0">{
                        sum += se
                }</span>
                <span class="cov0" title="0">meanStdError = sum / float64(len(vc.predictionStandardErrors))</span>
        }
        
        // Determine prediction reliability
        <span class="cov0" title="0">var reliability string
        if meanStdError &lt; 0.05 </span><span class="cov0" title="0">{
                reliability = "High confidence predictions"
        }</span> else<span class="cov0" title="0"> if meanStdError &lt; 0.15 </span><span class="cov0" title="0">{
                reliability = "Moderate prediction uncertainty"
        }</span> else<span class="cov0" title="0"> {
                reliability = "High prediction uncertainty"
        }</span>
        
        // Calculate interval widths for analysis
        <span class="cov0" title="0">var avgConfidenceWidth, avgPredictionWidth float64
        if len(vc.confidenceIntervalLower) == n &amp;&amp; len(vc.confidenceIntervalUpper) == n </span><span class="cov0" title="0">{
                for i := 0; i &lt; n; i++ </span><span class="cov0" title="0">{
                        avgConfidenceWidth += vc.confidenceIntervalUpper[i] - vc.confidenceIntervalLower[i]
                }</span>
                <span class="cov0" title="0">avgConfidenceWidth /= float64(n)</span>
        }
        
        <span class="cov0" title="0">if len(vc.predictionIntervalLower) == n &amp;&amp; len(vc.predictionIntervalUpper) == n </span><span class="cov0" title="0">{
                for i := 0; i &lt; n; i++ </span><span class="cov0" title="0">{
                        avgPredictionWidth += vc.predictionIntervalUpper[i] - vc.predictionIntervalLower[i]
                }</span>
                <span class="cov0" title="0">avgPredictionWidth /= float64(n)</span>
        }
        
        <span class="cov0" title="0">return PlotData{
                PlotType:  PredictionIntervalPlot,
                Title:     title,
                Timestamp: time.Now(),
                ModelName: vc.modelName,
                Series:    series,
                Config: PlotConfig{
                        XAxisLabel:  "Input Values",
                        YAxisLabel:  "Predictions",
                        XAxisScale:  "linear",
                        YAxisScale:  "linear",
                        ShowLegend:  true,
                        ShowGrid:    true,
                        Width:       800,
                        Height:      600,
                        Interactive: true,
                        CustomOptions: map[string]interface{}{
                                "subtitle": "Prediction uncertainty with confidence and prediction intervals",
                                "reliability": reliability,
                                "mean_std_error": meanStdError,
                        },
                },
                Metrics: map[string]interface{}{
                        "num_predictions":         n,
                        "mean_standard_error":     meanStdError,
                        "avg_confidence_width":    avgConfidenceWidth,
                        "avg_prediction_width":    avgPredictionWidth,
                        "reliability":            reliability,
                },
        }</span>
}

// GenerateFeatureCorrelationPlot generates feature correlation heatmap for multicollinearity analysis
func (vc *VisualizationCollector) GenerateFeatureCorrelationPlot() PlotData <span class="cov0" title="0">{
        // Create descriptive title using model name if available
        title := "Feature Correlation Heatmap"
        if vc.modelName != "" &amp;&amp; vc.modelName != "Model" </span><span class="cov0" title="0">{
                title = vc.modelName + " - Feature Correlation Analysis"
        }</span>
        
        <span class="cov0" title="0">if len(vc.correlationMatrix) == 0 || len(vc.correlationFeatures) == 0 </span><span class="cov0" title="0">{
                return PlotData{
                        PlotType:  FeatureCorrelationPlot,
                        Title:     title,
                        Timestamp: time.Now(),
                        ModelName: vc.modelName,
                        Series:    []SeriesData{},
                }
        }</span>
        
        <span class="cov0" title="0">n := len(vc.correlationFeatures)
        
        // Create heatmap data structure
        // For heatmaps, we need a series with X, Y, and Z values where:
        // X = feature index (column), Y = feature index (row), Z = correlation value
        heatmapData := make([]DataPoint, n*n)
        
        idx := 0
        for i := 0; i &lt; n; i++ </span><span class="cov0" title="0">{
                for j := 0; j &lt; n; j++ </span><span class="cov0" title="0">{
                        heatmapData[idx] = DataPoint{
                                X:     float64(j), // Column index
                                Y:     float64(i), // Row index 
                                Z:     vc.correlationMatrix[i][j], // Correlation value
                                Label: fmt.Sprintf("%s vs %s: %.3f", vc.correlationFeatures[i], vc.correlationFeatures[j], vc.correlationMatrix[i][j]),
                        }
                        idx++
                }</span>
        }
        
        <span class="cov0" title="0">series := []SeriesData{
                {
                        Name: "Correlation Matrix",
                        Type: "heatmap",
                        Data: heatmapData,
                        Style: map[string]interface{}{
                                "colorscale": "RdBu_r", // Red-Blue reversed (red for positive, blue for negative)
                                "zmin":       -1.0,
                                "zmax":       1.0,
                                "showscale":  true,
                        },
                },
        }
        
        // Analyze correlation patterns for diagnostics
        var strongCorrelations []string
        var maxCorrelation, minCorrelation float64 = -1.0, 1.0
        var highCorrelationCount int
        
        for i := 0; i &lt; n; i++ </span><span class="cov0" title="0">{
                for j := i + 1; j &lt; n; j++ </span><span class="cov0" title="0">{ // Only check upper triangle (avoid diagonal and duplicates)
                        corr := math.Abs(vc.correlationMatrix[i][j])
                        
                        if corr &gt; maxCorrelation </span><span class="cov0" title="0">{
                                maxCorrelation = corr
                        }</span>
                        <span class="cov0" title="0">if corr &lt; minCorrelation </span><span class="cov0" title="0">{
                                minCorrelation = corr
                        }</span>
                        
                        // Flag strong correlations (absolute value &gt; 0.7)
                        <span class="cov0" title="0">if corr &gt; 0.7 </span><span class="cov0" title="0">{
                                highCorrelationCount++
                                strongCorrelations = append(strongCorrelations, 
                                        fmt.Sprintf("%s↔%s (%.3f)", vc.correlationFeatures[i], vc.correlationFeatures[j], vc.correlationMatrix[i][j]))
                        }</span>
                }
        }
        
        // Determine multicollinearity assessment
        <span class="cov0" title="0">var multicollinearityStatus string
        if highCorrelationCount == 0 </span><span class="cov0" title="0">{
                multicollinearityStatus = "Low multicollinearity risk"
        }</span> else<span class="cov0" title="0"> if highCorrelationCount &lt;= 2 </span><span class="cov0" title="0">{
                multicollinearityStatus = "Moderate multicollinearity detected"
        }</span> else<span class="cov0" title="0"> {
                multicollinearityStatus = "High multicollinearity risk"
        }</span>
        
        // Create feature name arrays for axis labels
        <span class="cov0" title="0">xLabels := make([]interface{}, n)
        yLabels := make([]interface{}, n)
        for i, name := range vc.correlationFeatures </span><span class="cov0" title="0">{
                xLabels[i] = name
                yLabels[i] = name
        }</span>
        
        <span class="cov0" title="0">return PlotData{
                PlotType:  FeatureCorrelationPlot,
                Title:     title,
                Timestamp: time.Now(),
                ModelName: vc.modelName,
                Series:    series,
                Config: PlotConfig{
                        XAxisLabel:  "Features",
                        YAxisLabel:  "Features", 
                        XAxisScale:  "linear",
                        YAxisScale:  "linear",
                        ShowLegend:  false,
                        ShowGrid:    false,
                        Width:       max(600, n*40),  // Scale with feature count
                        Height:      max(600, n*40),  // Square aspect ratio
                        Interactive: true,
                        CustomOptions: map[string]interface{}{
                                "subtitle": "Feature correlation analysis for multicollinearity detection",
                                "multicollinearity_status": multicollinearityStatus,
                                "high_correlation_count": highCorrelationCount,
                                "x_labels": xLabels,
                                "y_labels": yLabels,
                                "strong_correlations": strongCorrelations,
                        },
                },
                Metrics: map[string]interface{}{
                        "num_features":           n,
                        "max_correlation":        maxCorrelation,
                        "min_correlation":        minCorrelation,
                        "high_correlation_count": highCorrelationCount,
                        "multicollinearity_status": multicollinearityStatus,
                        "strong_correlations":    strongCorrelations,
                },
        }</span>
}

// GeneratePartialDependencePlot generates partial dependence plots for individual feature effect analysis
func (vc *VisualizationCollector) GeneratePartialDependencePlot() PlotData <span class="cov0" title="0">{
        // Create descriptive title using model name if available
        title := "Partial Dependence Plot"
        if vc.modelName != "" &amp;&amp; vc.modelName != "Model" </span><span class="cov0" title="0">{
                title = vc.modelName + " - Feature Effect Analysis"
        }</span>
        
        <span class="cov0" title="0">if len(vc.partialDependenceFeatures) == 0 || len(vc.partialDependenceValues) == 0 || len(vc.partialDependenceEffects) == 0 </span><span class="cov0" title="0">{
                return PlotData{
                        PlotType:  PartialDependencePlot,
                        Title:     title,
                        Timestamp: time.Now(),
                        ModelName: vc.modelName,
                        Series:    []SeriesData{},
                }
        }</span>
        
        // Create a series for each feature
        <span class="cov0" title="0">series := make([]SeriesData, len(vc.partialDependenceFeatures))
        
        var minEffect, maxEffect float64 = math.Inf(1), math.Inf(-1)
        
        for i, featureName := range vc.partialDependenceFeatures </span><span class="cov0" title="0">{
                if i &gt;= len(vc.partialDependenceValues) || i &gt;= len(vc.partialDependenceEffects) </span><span class="cov0" title="0">{
                        continue</span>
                }
                
                <span class="cov0" title="0">featureValues := vc.partialDependenceValues[i]
                partialEffects := vc.partialDependenceEffects[i]
                
                // Create data points for this feature
                dataPoints := make([]DataPoint, len(featureValues))
                for j, value := range featureValues </span><span class="cov0" title="0">{
                        if j &lt; len(partialEffects) </span><span class="cov0" title="0">{
                                effect := partialEffects[j]
                                
                                // Track min/max for diagnostics
                                if effect &lt; minEffect </span><span class="cov0" title="0">{
                                        minEffect = effect
                                }</span>
                                <span class="cov0" title="0">if effect &gt; maxEffect </span><span class="cov0" title="0">{
                                        maxEffect = effect
                                }</span>
                                
                                <span class="cov0" title="0">dataPoints[j] = DataPoint{
                                        X:     value,
                                        Y:     effect,
                                        Label: fmt.Sprintf("%s = %.3f → Effect: %.3f", featureName, value, effect),
                                }</span>
                        }
                }
                
                <span class="cov0" title="0">series[i] = SeriesData{
                        Name: featureName,
                        Type: "line",
                        Data: dataPoints,
                        Style: map[string]interface{}{
                                "mode": "lines+markers",
                                "line": map[string]interface{}{
                                        "width": 2,
                                },
                        },
                }</span>
        }
        
        // Calculate effect range for analysis
        <span class="cov0" title="0">effectRange := maxEffect - minEffect
        
        // Determine feature importance analysis
        var featureImportance []string
        var mostInfluentialFeature string
        var maxInfluence float64 = 0
        
        for i, featureName := range vc.partialDependenceFeatures </span><span class="cov0" title="0">{
                if i &gt;= len(vc.partialDependenceEffects) </span><span class="cov0" title="0">{
                        continue</span>
                }
                
                <span class="cov0" title="0">effects := vc.partialDependenceEffects[i]
                if len(effects) == 0 </span><span class="cov0" title="0">{
                        continue</span>
                }
                
                // Calculate influence as range of partial effects
                <span class="cov0" title="0">var minFeatureEffect, maxFeatureEffect float64 = math.Inf(1), math.Inf(-1)
                for _, effect := range effects </span><span class="cov0" title="0">{
                        if effect &lt; minFeatureEffect </span><span class="cov0" title="0">{
                                minFeatureEffect = effect
                        }</span>
                        <span class="cov0" title="0">if effect &gt; maxFeatureEffect </span><span class="cov0" title="0">{
                                maxFeatureEffect = effect
                        }</span>
                }
                
                <span class="cov0" title="0">influence := maxFeatureEffect - minFeatureEffect
                if influence &gt; maxInfluence </span><span class="cov0" title="0">{
                        maxInfluence = influence
                        mostInfluentialFeature = featureName
                }</span>
                
                <span class="cov0" title="0">featureImportance = append(featureImportance, 
                        fmt.Sprintf("%s (range: %.3f)", featureName, influence))</span>
        }
        
        // Determine analysis status
        <span class="cov0" title="0">var analysisStatus string
        if effectRange &lt; 0.1 </span><span class="cov0" title="0">{
                analysisStatus = "Low feature impact - all features have minimal effect"
        }</span> else<span class="cov0" title="0"> if effectRange &lt; 0.5 </span><span class="cov0" title="0">{
                analysisStatus = "Moderate feature impact - some features show meaningful effects"
        }</span> else<span class="cov0" title="0"> {
                analysisStatus = "High feature impact - significant variation in feature effects"
        }</span>
        
        <span class="cov0" title="0">return PlotData{
                PlotType:  PartialDependencePlot,
                Title:     title,
                Timestamp: time.Now(),
                ModelName: vc.modelName,
                Series:    series,
                Config: PlotConfig{
                        XAxisLabel:  "Feature Value",
                        YAxisLabel:  "Partial Dependence",
                        XAxisScale:  "linear",
                        YAxisScale:  "linear",
                        ShowLegend:  true,
                        ShowGrid:    true,
                        Width:       800,
                        Height:      600,
                        Interactive: true,
                        CustomOptions: map[string]interface{}{
                                "subtitle": "Individual feature effects on model predictions",
                                "analysis_status": analysisStatus,
                                "most_influential_feature": mostInfluentialFeature,
                                "max_influence": maxInfluence,
                                "feature_importance": featureImportance,
                        },
                },
                Metrics: map[string]interface{}{
                        "num_features":                len(vc.partialDependenceFeatures),
                        "effect_range":               effectRange,
                        "min_effect":                 minEffect,
                        "max_effect":                 maxEffect,
                        "analysis_status":            analysisStatus,
                        "most_influential_feature":   mostInfluentialFeature,
                        "max_influence":              maxInfluence,
                        "feature_importance":         featureImportance,
                },
        }</span>
}

// max returns the larger of two integers
func max(a, b int) int <span class="cov0" title="0">{
        if a &gt; b </span><span class="cov0" title="0">{
                return a
        }</span>
        <span class="cov0" title="0">return b</span>
}

// reverse reverses a slice of DataPoint for fill_between functionality
func reverse(data []DataPoint) []DataPoint <span class="cov0" title="0">{
        reversed := make([]DataPoint, len(data))
        for i, j := 0, len(data)-1; i &lt; len(data); i, j = i+1, j-1 </span><span class="cov0" title="0">{
                reversed[i] = data[j]
        }</span>
        <span class="cov0" title="0">return reversed</span>
}

// normalQuantile calculates approximate normal quantile for probability p
// Uses Beasley-Springer-Moro algorithm approximation
func normalQuantile(p float64) float64 <span class="cov0" title="0">{
        if p &lt;= 0 </span><span class="cov0" title="0">{
                return math.Inf(-1)
        }</span>
        <span class="cov0" title="0">if p &gt;= 1 </span><span class="cov0" title="0">{
                return math.Inf(1)
        }</span>
        
        // For p around 0.5, use direct calculation
        <span class="cov0" title="0">if p == 0.5 </span><span class="cov0" title="0">{
                return 0.0
        }</span>
        
        // Use inverse error function approximation
        // This is a simplified approximation for the normal quantile function
        <span class="cov0" title="0">if p &lt; 0.5 </span><span class="cov0" title="0">{
                // For lower tail, use symmetry
                return -normalQuantile(1.0 - p)
        }</span>
        
        // Rational approximation for upper tail
        <span class="cov0" title="0">t := math.Sqrt(-2.0 * math.Log(1.0-p))
        
        // Coefficients for the approximation
        c0 := 2.515517
        c1 := 0.802853
        c2 := 0.010328
        d1 := 1.432788
        d2 := 0.189269
        d3 := 0.001308
        
        numerator := c0 + c1*t + c2*t*t
        denominator := 1.0 + d1*t + d2*t*t + d3*t*t*t
        
        return t - numerator/denominator</span>
}

// calculateMeanAndStd calculates mean and standard deviation of a slice
func calculateMeanAndStd(values []float64) (float64, float64) <span class="cov0" title="0">{
        if len(values) == 0 </span><span class="cov0" title="0">{
                return 0, 0
        }</span>
        
        // Calculate mean
        <span class="cov0" title="0">sum := 0.0
        for _, v := range values </span><span class="cov0" title="0">{
                sum += v
        }</span>
        <span class="cov0" title="0">mean := sum / float64(len(values))
        
        // Calculate standard deviation
        sumSquaredDiffs := 0.0
        for _, v := range values </span><span class="cov0" title="0">{
                diff := v - mean
                sumSquaredDiffs += diff * diff
        }</span>
        <span class="cov0" title="0">variance := sumSquaredDiffs / float64(len(values)-1) // Sample standard deviation
        stddev := math.Sqrt(variance)
        
        return mean, stddev</span>
}

// ToJSON converts plot data to JSON string
func (pd PlotData) ToJSON() (string, error) <span class="cov0" title="0">{
        jsonData, err := json.MarshalIndent(pd, "", "  ")
        if err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("failed to marshal plot data to JSON: %w", err)
        }</span>
        <span class="cov0" title="0">return string(jsonData), nil</span>
}

// Clear resets all collected data
func (vc *VisualizationCollector) Clear() <span class="cov0" title="0">{
        vc.trainingLoss = vc.trainingLoss[:0]
        vc.trainingAccuracy = vc.trainingAccuracy[:0]
        vc.validationLoss = vc.validationLoss[:0]
        vc.validationAccuracy = vc.validationAccuracy[:0]
        vc.epochs = vc.epochs[:0]
        vc.steps = vc.steps[:0]
        vc.learningRates = vc.learningRates[:0]
        vc.rocPoints = vc.rocPoints[:0]
        vc.prPoints = vc.prPoints[:0]
        vc.confusionMatrix = nil
        vc.classNames = nil
        vc.predictions = vc.predictions[:0]
        vc.trueValues = vc.trueValues[:0]
        vc.residuals = vc.residuals[:0]
        vc.parameterStats = make(map[string]ParameterStats)
        vc.gradientStats = make(map[string]GradientStats)
        vc.activationStats = make(map[string]ActivationStats)
}</pre>
		
		</div>
	</body>
	<script>
	(function() {
		var files = document.getElementById('files');
		var visible;
		files.addEventListener('change', onChange, false);
		function select(part) {
			if (visible)
				visible.style.display = 'none';
			visible = document.getElementById(part);
			if (!visible)
				return;
			files.value = part;
			visible.style.display = 'block';
			location.hash = part;
		}
		function onChange() {
			select(files.value);
			window.scrollTo(0, 0);
		}
		if (location.hash != "") {
			select(location.hash.substr(1));
		}
		if (!visible) {
			select("file0");
		}
	})();
	</script>
</html>
