# Visualization Guide

Advanced visualization techniques for go-metal models and training progress.

## üéØ Overview

This guide covers comprehensive visualization strategies for go-metal models, training metrics, and data analysis. You'll learn to create production-ready visualizations that help debug models, communicate results, and monitor training progress.

## üìä Training Progress Visualization

### Real-Time Training Metrics

```go
package main

import (
    "fmt"
    "log"
    "math"
    "time"
    
    "github.com/tsawler/go-metal/cgo_bridge"
    "github.com/tsawler/go-metal/layers"
    "github.com/tsawler/go-metal/memory"
    "github.com/tsawler/go-metal/training"
)

// TrainingVisualizer manages real-time training visualization
type TrainingVisualizer struct {
    TrainingLosses   []float32
    ValidationLosses []float32
    Accuracies       []float32
    Epochs           []int
    StartTime        time.Time
    PlotWidth        int
    PlotHeight       int
}

func NewTrainingVisualizer() *TrainingVisualizer {
    return &TrainingVisualizer{
        TrainingLosses:   make([]float32, 0),
        ValidationLosses: make([]float32, 0),
        Accuracies:       make([]float32, 0),
        Epochs:           make([]int, 0),
        StartTime:        time.Now(),
        PlotWidth:        80,
        PlotHeight:       20,
    }
}

func (tv *TrainingVisualizer) AddMetrics(epoch int, trainLoss, valLoss, accuracy float32) {
    tv.Epochs = append(tv.Epochs, epoch)
    tv.TrainingLosses = append(tv.TrainingLosses, trainLoss)
    tv.ValidationLosses = append(tv.ValidationLosses, valLoss)
    tv.Accuracies = append(tv.Accuracies, accuracy)
}

func (tv *TrainingVisualizer) DisplayProgress() {
    fmt.Printf("\033[2J\033[H") // Clear screen and move cursor to top
    
    fmt.Println("üöÄ Training Progress Visualization")
    fmt.Println("==================================")
    
    if len(tv.TrainingLosses) == 0 {
        fmt.Println("No training data yet...")
        return
    }
    
    // Current metrics
    latest := len(tv.TrainingLosses) - 1
    currentEpoch := tv.Epochs[latest]
    currentTrainLoss := tv.TrainingLosses[latest]
    currentValLoss := tv.ValidationLosses[latest]
    currentAccuracy := tv.Accuracies[latest]
    elapsed := time.Since(tv.StartTime)
    
    fmt.Printf("üìä Current Status (Epoch %d):\n", currentEpoch)
    fmt.Printf("   Training Loss:   %.6f\n", currentTrainLoss)
    fmt.Printf("   Validation Loss: %.6f\n", currentValLoss)
    fmt.Printf("   Accuracy:        %.1f%%\n", currentAccuracy*100)
    fmt.Printf("   Training Time:   %v\n", elapsed.Round(time.Second))
    
    // Loss trend analysis
    if len(tv.TrainingLosses) >= 2 {
        prevTrainLoss := tv.TrainingLosses[latest-1]
        trainTrend := currentTrainLoss - prevTrainLoss
        
        fmt.Printf("\nüìà Trends:\n")
        if trainTrend < 0 {
            fmt.Printf("   Loss: ‚Üì Improving (Œî %.6f)\n", trainTrend)
        } else {
            fmt.Printf("   Loss: ‚Üë Check learning rate (Œî %.6f)\n", trainTrend)
        }
        
        // Overfitting detection
        if currentValLoss > currentTrainLoss*1.2 {
            fmt.Printf("   ‚ö†Ô∏è  Potential overfitting detected\n")
        }
    }
    
    // ASCII plot of training progress
    tv.plotLossProgress()
    tv.plotAccuracyProgress()
}

func (tv *TrainingVisualizer) plotLossProgress() {
    if len(tv.TrainingLosses) < 2 {
        return
    }
    
    fmt.Printf("\nüìâ Loss Progress (last %d epochs):\n", len(tv.TrainingLosses))
    
    // Find min/max for scaling
    minLoss := tv.TrainingLosses[0]
    maxLoss := tv.TrainingLosses[0]
    
    for _, loss := range tv.TrainingLosses {
        if loss < minLoss {
            minLoss = loss
        }
        if loss > maxLoss {
            maxLoss = loss
        }
    }
    
    for _, loss := range tv.ValidationLosses {
        if loss < minLoss {
            minLoss = loss
        }
        if loss > maxLoss {
            maxLoss = loss
        }
    }
    
    // Avoid division by zero
    if maxLoss == minLoss {
        maxLoss = minLoss + 1.0
    }
    
    // Plot training and validation loss
    plotHeight := 15
    plotWidth := min(len(tv.TrainingLosses), 60)
    
    for y := plotHeight - 1; y >= 0; y-- {
        // Y-axis label
        value := minLoss + (maxLoss-minLoss)*float32(y)/float32(plotHeight-1)
        fmt.Printf("%6.3f ‚îÇ", value)
        
        // Plot line
        for x := 0; x < plotWidth; x++ {
            idx := len(tv.TrainingLosses) - plotWidth + x
            if idx < 0 {
                fmt.Print(" ")
                continue
            }
            
            trainY := int((tv.TrainingLosses[idx] - minLoss) / (maxLoss - minLoss) * float32(plotHeight-1))
            valY := int((tv.ValidationLosses[idx] - minLoss) / (maxLoss - minLoss) * float32(plotHeight-1))
            
            if trainY == y && valY == y {
                fmt.Print("‚óÜ") // Both lines
            } else if trainY == y {
                fmt.Print("‚óè") // Training loss
            } else if valY == y {
                fmt.Print("‚óã") // Validation loss
            } else {
                fmt.Print(" ")
            }
        }
        fmt.Println()
    }
    
    // X-axis
    fmt.Print("       ‚îî")
    for i := 0; i < plotWidth; i++ {
        fmt.Print("‚îÄ")
    }
    fmt.Println()
    fmt.Println("        ‚óè Training Loss    ‚óã Validation Loss")
}

func (tv *TrainingVisualizer) plotAccuracyProgress() {
    if len(tv.Accuracies) < 2 {
        return
    }
    
    fmt.Printf("\nüìà Accuracy Progress:\n")
    
    // Simple horizontal bar chart for latest accuracy
    accuracy := tv.Accuracies[len(tv.Accuracies)-1]
    barLength := int(accuracy * 50) // Scale to 50 chars max
    
    fmt.Print("   ")
    for i := 0; i < barLength; i++ {
        fmt.Print("‚ñà")
    }
    for i := barLength; i < 50; i++ {
        fmt.Print("‚ñë")
    }
    fmt.Printf(" %.1f%%\n", accuracy*100)
    
    // Show accuracy trend
    if len(tv.Accuracies) >= 2 {
        prev := tv.Accuracies[len(tv.Accuracies)-2]
        current := tv.Accuracies[len(tv.Accuracies)-1]
        change := current - prev
        
        if change > 0 {
            fmt.Printf("   üìà Improving (+%.1f%%)\n", change*100)
        } else if change < 0 {
            fmt.Printf("   üìâ Declining (%.1f%%)\n", change*100)
        } else {
            fmt.Printf("   ‚û°Ô∏è  Stable\n")
        }
    }
}

func min(a, b int) int {
    if a < b {
        return a
    }
    return b
}
```

### Training Loop with Visualization

```go
func trainWithVisualization(trainer *training.ModelTrainer, 
                           inputData, targetData []float32,
                           inputShape, targetShape []int, 
                           epochs int) error {
    
    visualizer := NewTrainingVisualizer()
    
    fmt.Println("üé¨ Starting Training with Live Visualization")
    
    for epoch := 1; epoch <= epochs; epoch++ {
        // Training step
        result, err := trainer.TrainBatch(inputData, inputShape, targetData, targetShape)
        if err != nil {
            return fmt.Errorf("training failed at epoch %d: %v", epoch, err)
        }
        
        // Simulate validation metrics (in practice, use separate validation data)
        valLoss := result.Loss * (1.0 + (rand.Float32()-0.5)*0.1)
        accuracy := float32(0.5 + 0.4*math.Exp(-float64(result.Loss)))
        
        // Update visualization
        visualizer.AddMetrics(epoch, result.Loss, valLoss, accuracy)
        
        // Display progress every 5 epochs or on key milestones
        if epoch%5 == 0 || epoch == 1 || epoch == epochs {
            visualizer.DisplayProgress()
            time.Sleep(100 * time.Millisecond) // Brief pause for visibility
        }
        
        // Early stopping with visual feedback
        if result.Loss < 0.01 {
            fmt.Printf("\nüéâ Training converged at epoch %d!\n", epoch)
            break
        }
    }
    
    return nil
}
```

## üé® Model Architecture Visualization

### Network Structure Display

```go
// ModelVisualizer provides detailed model architecture visualization
type ModelVisualizer struct {
    Model *layers.ModelSpec
}

func NewModelVisualizer(model *layers.ModelSpec) *ModelVisualizer {
    return &ModelVisualizer{Model: model}
}

func (mv *ModelVisualizer) DisplayArchitecture() {
    fmt.Println("üèóÔ∏è Model Architecture Visualization")
    fmt.Println("===================================")
    
    if mv.Model == nil || len(mv.Model.Layers) == 0 {
        fmt.Println("‚ùå No model layers to display")
        return
    }
    
    fmt.Printf("üìä Total Layers: %d\n", len(mv.Model.Layers))
    fmt.Printf("üî¢ Input Shape: %v\n", mv.Model.InputShape)
    
    // Layer-by-layer breakdown
    fmt.Println("\nüìã Layer Details:")
    fmt.Printf("%-4s ‚îÇ %-15s ‚îÇ %-20s ‚îÇ %-15s ‚îÇ %-10s\n", 
               "Idx", "Type", "Name", "Output Shape", "Params")
    fmt.Println("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
    
    totalParams := 0
    currentShape := mv.Model.InputShape
    
    for i, layer := range mv.Model.Layers {
        layerType := getLayerType(layer)
        layerName := getLayerName(layer)
        outputShape := calculateOutputShape(layer, currentShape)
        params := calculateLayerParams(layer, currentShape)
        
        fmt.Printf("%4d ‚îÇ %-15s ‚îÇ %-20s ‚îÇ %-15s ‚îÇ %10d\n",
                   i, layerType, layerName, formatShape(outputShape), params)
        
        totalParams += params
        currentShape = outputShape
    }
    
    fmt.Println("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
    fmt.Printf("üìä Total Parameters: %d\n", totalParams)
    fmt.Printf("üéØ Final Output Shape: %v\n", currentShape)
    
    // ASCII architecture diagram
    mv.drawArchitectureDiagram()
}

func (mv *ModelVisualizer) drawArchitectureDiagram() {
    fmt.Println("\nüé® Architecture Diagram:")
    
    maxWidth := 20
    
    // Input
    fmt.Printf("‚îå%s‚îê\n", strings.Repeat("‚îÄ", maxWidth-2))
    fmt.Printf("‚îÇ%s‚îÇ\n", center("INPUT", maxWidth-2))
    fmt.Printf("‚îÇ%s‚îÇ\n", center(formatShape(mv.Model.InputShape), maxWidth-2))
    fmt.Printf("‚îî%s‚îò\n", strings.Repeat("‚îÄ", maxWidth-2))
    fmt.Println("    ‚îÇ")
    fmt.Println("    ‚ñº")
    
    // Layers
    for i, layer := range mv.Model.Layers {
        layerType := getLayerType(layer)
        layerName := getLayerName(layer)
        
        fmt.Printf("‚îå%s‚îê\n", strings.Repeat("‚îÄ", maxWidth-2))
        fmt.Printf("‚îÇ%s‚îÇ\n", center(layerType, maxWidth-2))
        fmt.Printf("‚îÇ%s‚îÇ\n", center(layerName, maxWidth-2))
        fmt.Printf("‚îî%s‚îò\n", strings.Repeat("‚îÄ", maxWidth-2))
        
        if i < len(mv.Model.Layers)-1 {
            fmt.Println("    ‚îÇ")
            fmt.Println("    ‚ñº")
        }
    }
    
    // Output
    fmt.Println("    ‚îÇ")
    fmt.Println("    ‚ñº")
    fmt.Printf("‚îå%s‚îê\n", strings.Repeat("‚îÄ", maxWidth-2))
    fmt.Printf("‚îÇ%s‚îÇ\n", center("OUTPUT", maxWidth-2))
    fmt.Printf("‚îî%s‚îò\n", strings.Repeat("‚îÄ", maxWidth-2))
}

// Helper functions for model visualization
func getLayerType(layer *layers.Layer) string {
    // In a real implementation, you'd inspect the layer type
    // This is a simplified example
    if layer.Name == "conv1" || layer.Name == "conv2" {
        return "Conv2D"
    } else if layer.Name == "relu1" || layer.Name == "relu2" {
        return "ReLU"
    } else if layer.Name == "flatten" {
        return "Flatten"
    } else if layer.Name == "dense1" || layer.Name == "output" {
        return "Dense"
    } else if layer.Name == "dropout1" {
        return "Dropout"
    }
    return "Unknown"
}

func getLayerName(layer *layers.Layer) string {
    if layer.Name != "" {
        return layer.Name
    }
    return "unnamed"
}

func calculateOutputShape(layer *layers.Layer, inputShape []int) []int {
    // Simplified shape calculation - in practice, this would be more complex
    return inputShape // Placeholder
}

func calculateLayerParams(layer *layers.Layer, inputShape []int) int {
    // Simplified parameter calculation
    return 1000 // Placeholder
}

func formatShape(shape []int) string {
    result := "("
    for i, dim := range shape {
        if i > 0 {
            result += ","
        }
        result += fmt.Sprintf("%d", dim)
    }
    result += ")"
    return result
}

func center(text string, width int) string {
    if len(text) >= width {
        return text[:width]
    }
    padding := width - len(text)
    leftPad := padding / 2
    rightPad := padding - leftPad
    return strings.Repeat(" ", leftPad) + text + strings.Repeat(" ", rightPad)
}
```

## üìà Data Visualization

### Dataset Analysis and Visualization

```go
// DataVisualizer provides comprehensive dataset analysis
type DataVisualizer struct {
    Data   []float32
    Labels []float32
    Name   string
}

func NewDataVisualizer(data, labels []float32, name string) *DataVisualizer {
    return &DataVisualizer{
        Data:   data,
        Labels: labels,
        Name:   name,
    }
}

func (dv *DataVisualizer) AnalyzeDataset() {
    fmt.Printf("üìä Dataset Analysis: %s\n", dv.Name)
    fmt.Println("========================")
    
    // Basic statistics
    dv.displayBasicStats()
    
    // Data distribution
    dv.displayDataDistribution()
    
    // Label distribution
    dv.displayLabelDistribution()
    
    // Data quality checks
    dv.checkDataQuality()
}

func (dv *DataVisualizer) displayBasicStats() {
    fmt.Println("\nüìã Basic Statistics:")
    
    if len(dv.Data) == 0 {
        fmt.Println("   ‚ùå No data available")
        return
    }
    
    // Calculate statistics
    min, max, mean, std := calculateStats(dv.Data)
    
    fmt.Printf("   Samples: %d\n", len(dv.Data))
    fmt.Printf("   Min:     %.6f\n", min)
    fmt.Printf("   Max:     %.6f\n", max)
    fmt.Printf("   Mean:    %.6f\n", mean)
    fmt.Printf("   Std:     %.6f\n", std)
    
    // Range analysis
    dataRange := max - min
    fmt.Printf("   Range:   %.6f\n", dataRange)
    
    if dataRange > 100 {
        fmt.Println("   ‚ö†Ô∏è  Large range detected - consider normalization")
    }
    
    if std > mean*2 {
        fmt.Println("   ‚ö†Ô∏è  High variance detected - check for outliers")
    }
}

func (dv *DataVisualizer) displayDataDistribution() {
    fmt.Println("\nüìä Data Distribution:")
    
    if len(dv.Data) == 0 {
        return
    }
    
    // Create histogram
    numBins := 20
    min, max, _, _ := calculateStats(dv.Data)
    
    if max == min {
        fmt.Println("   All values are identical")
        return
    }
    
    binWidth := (max - min) / float32(numBins)
    bins := make([]int, numBins)
    
    // Count values in each bin
    for _, value := range dv.Data {
        binIdx := int((value - min) / binWidth)
        if binIdx >= numBins {
            binIdx = numBins - 1
        }
        bins[binIdx]++
    }
    
    // Find max count for scaling
    maxCount := 0
    for _, count := range bins {
        if count > maxCount {
            maxCount = count
        }
    }
    
    // Display histogram
    plotWidth := 40
    for i := 0; i < numBins; i++ {
        binStart := min + float32(i)*binWidth
        binEnd := binStart + binWidth
        
        barLength := 0
        if maxCount > 0 {
            barLength = (bins[i] * plotWidth) / maxCount
        }
        
        fmt.Printf("   [%6.2f-%6.2f) ‚îÇ", binStart, binEnd)
        for j := 0; j < barLength; j++ {
            fmt.Print("‚ñà")
        }
        fmt.Printf(" (%d)\n", bins[i])
    }
}

func (dv *DataVisualizer) displayLabelDistribution() {
    if len(dv.Labels) == 0 {
        return
    }
    
    fmt.Println("\nüè∑Ô∏è Label Distribution:")
    
    // Count unique labels
    labelCounts := make(map[float32]int)
    for _, label := range dv.Labels {
        labelCounts[label]++
    }
    
    // Display distribution
    totalSamples := len(dv.Labels)
    for label, count := range labelCounts {
        percentage := float32(count) / float32(totalSamples) * 100
        fmt.Printf("   Label %.1f: %d samples (%.1f%%)\n", label, count, percentage)
    }
    
    // Check for class imbalance
    if len(labelCounts) > 1 {
        minCount := totalSamples
        maxCount := 0
        
        for _, count := range labelCounts {
            if count < minCount {
                minCount = count
            }
            if count > maxCount {
                maxCount = count
            }
        }
        
        imbalanceRatio := float32(maxCount) / float32(minCount)
        if imbalanceRatio > 2.0 {
            fmt.Printf("   ‚ö†Ô∏è  Class imbalance detected (ratio: %.1f:1)\n", imbalanceRatio)
        }
    }
}

func (dv *DataVisualizer) checkDataQuality() {
    fmt.Println("\nüîç Data Quality Check:")
    
    // Check for NaN/Inf values
    nanCount := 0
    infCount := 0
    
    for _, value := range dv.Data {
        if math.IsNaN(float64(value)) {
            nanCount++
        } else if math.IsInf(float64(value), 0) {
            infCount++
        }
    }
    
    if nanCount > 0 {
        fmt.Printf("   ‚ùå Found %d NaN values\n", nanCount)
    }
    
    if infCount > 0 {
        fmt.Printf("   ‚ùå Found %d Inf values\n", infCount)
    }
    
    if nanCount == 0 && infCount == 0 {
        fmt.Println("   ‚úÖ No NaN or Inf values detected")
    }
    
    // Check for constant values
    min, max, _, _ := calculateStats(dv.Data)
    if max == min {
        fmt.Println("   ‚ö†Ô∏è  All values are constant")
    } else {
        fmt.Println("   ‚úÖ Data has variation")
    }
    
    // Memory usage estimate
    dataSize := len(dv.Data) * 4 // 4 bytes per float32
    fmt.Printf("   üìä Memory usage: ~%d bytes (%.1f KB)\n", dataSize, float32(dataSize)/1024)
}

func calculateStats(data []float32) (min, max, mean, std float32) {
    if len(data) == 0 {
        return 0, 0, 0, 0
    }
    
    min = data[0]
    max = data[0]
    sum := float32(0)
    
    for _, value := range data {
        if value < min {
            min = value
        }
        if value > max {
            max = value
        }
        sum += value
    }
    
    mean = sum / float32(len(data))
    
    // Calculate standard deviation
    sumSquares := float32(0)
    for _, value := range data {
        diff := value - mean
        sumSquares += diff * diff
    }
    
    std = float32(math.Sqrt(float64(sumSquares / float32(len(data)))))
    
    return min, max, mean, std
}
```

## üîç Model Performance Visualization

### Confusion Matrix and Metrics

```go
// ClassificationVisualizer for classification model analysis
type ClassificationVisualizer struct {
    Predictions []float32
    TrueLabels  []float32
    ClassNames  []string
}

func NewClassificationVisualizer(predictions, trueLabels []float32, classNames []string) *ClassificationVisualizer {
    return &ClassificationVisualizer{
        Predictions: predictions,
        TrueLabels:  trueLabels,
        ClassNames:  classNames,
    }
}

func (cv *ClassificationVisualizer) DisplayConfusionMatrix() {
    fmt.Println("üéØ Confusion Matrix Analysis")
    fmt.Println("============================")
    
    if len(cv.Predictions) != len(cv.TrueLabels) {
        fmt.Println("‚ùå Predictions and labels length mismatch")
        return
    }
    
    // Determine number of classes
    numClasses := len(cv.ClassNames)
    if numClasses == 0 {
        fmt.Println("‚ùå No class names provided")
        return
    }
    
    // Create confusion matrix
    matrix := make([][]int, numClasses)
    for i := range matrix {
        matrix[i] = make([]int, numClasses)
    }
    
    // Fill confusion matrix
    for i := 0; i < len(cv.Predictions); i++ {
        predClass := int(cv.Predictions[i])
        trueClass := int(cv.TrueLabels[i])
        
        if predClass >= 0 && predClass < numClasses && 
           trueClass >= 0 && trueClass < numClasses {
            matrix[trueClass][predClass]++
        }
    }
    
    // Display matrix
    cv.printConfusionMatrix(matrix)
    
    // Calculate and display metrics
    cv.calculateClassificationMetrics(matrix)
}

func (cv *ClassificationVisualizer) printConfusionMatrix(matrix [][]int) {
    numClasses := len(matrix)
    
    fmt.Println("\nüìä Confusion Matrix:")
    fmt.Println("     (Rows: True, Columns: Predicted)")
    
    // Header
    fmt.Print("        ")
    for i := 0; i < numClasses; i++ {
        if i < len(cv.ClassNames) {
            fmt.Printf("%8s", cv.ClassNames[i][:min(8, len(cv.ClassNames[i]))])
        } else {
            fmt.Printf("%8d", i)
        }
    }
    fmt.Println()
    
    // Matrix rows
    for i := 0; i < numClasses; i++ {
        // Row label
        if i < len(cv.ClassNames) {
            fmt.Printf("%8s", cv.ClassNames[i][:min(8, len(cv.ClassNames[i]))])
        } else {
            fmt.Printf("%8d", i)
        }
        
        // Matrix values
        for j := 0; j < numClasses; j++ {
            if i == j {
                fmt.Printf("\033[32m%8d\033[0m", matrix[i][j]) // Green for correct
            } else if matrix[i][j] > 0 {
                fmt.Printf("\033[31m%8d\033[0m", matrix[i][j]) // Red for errors
            } else {
                fmt.Printf("%8d", matrix[i][j])
            }
        }
        fmt.Println()
    }
}

func (cv *ClassificationVisualizer) calculateClassificationMetrics(matrix [][]int) {
    numClasses := len(matrix)
    
    fmt.Println("\nüìà Classification Metrics:")
    
    // Calculate per-class metrics
    fmt.Printf("%-10s ‚îÇ %-9s ‚îÇ %-9s ‚îÇ %-9s ‚îÇ %-9s\n", 
               "Class", "Precision", "Recall", "F1-Score", "Support")
    fmt.Println("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
    
    totalCorrect := 0
    totalSamples := 0
    weightedF1 := float32(0)
    
    for i := 0; i < numClasses; i++ {
        // True positives, false positives, false negatives
        tp := matrix[i][i]
        fp := 0
        fn := 0
        
        // Calculate FP and FN
        for j := 0; j < numClasses; j++ {
            if j != i {
                fp += matrix[j][i] // Predicted as i but actually j
                fn += matrix[i][j] // Actually i but predicted as j
            }
        }
        
        // Support (total samples for this class)
        support := tp + fn
        
        // Precision, Recall, F1
        var precision, recall, f1 float32
        
        if tp+fp > 0 {
            precision = float32(tp) / float32(tp+fp)
        }
        
        if tp+fn > 0 {
            recall = float32(tp) / float32(tp+fn)
        }
        
        if precision+recall > 0 {
            f1 = 2 * precision * recall / (precision + recall)
        }
        
        // Display metrics
        className := fmt.Sprintf("Class %d", i)
        if i < len(cv.ClassNames) {
            className = cv.ClassNames[i]
        }
        
        fmt.Printf("%-10s ‚îÇ %9.3f ‚îÇ %9.3f ‚îÇ %9.3f ‚îÇ %9d\n",
                   className, precision, recall, f1, support)
        
        totalCorrect += tp
        totalSamples += support
        weightedF1 += f1 * float32(support)
    }
    
    // Overall metrics
    fmt.Println("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
    
    accuracy := float32(totalCorrect) / float32(totalSamples)
    avgF1 := weightedF1 / float32(totalSamples)
    
    fmt.Printf("%-10s ‚îÇ           ‚îÇ           ‚îÇ %9.3f ‚îÇ %9d\n",
               "Weighted", avgF1, totalSamples)
    fmt.Printf("\nüéØ Overall Accuracy: %.3f (%.1f%%)\n", accuracy, accuracy*100)
}
```

## üìä Advanced Visualization Techniques

### Real-Time Model Monitoring

```go
// ModelMonitor provides comprehensive real-time model monitoring
type ModelMonitor struct {
    StartTime      time.Time
    EpochTimes     []time.Duration
    LossHistory    []float32
    GradientNorms  []float32
    LearningRates  []float32
    MemoryUsage    []float64
}

func NewModelMonitor() *ModelMonitor {
    return &ModelMonitor{
        StartTime:      time.Now(),
        EpochTimes:     make([]time.Duration, 0),
        LossHistory:    make([]float32, 0),
        GradientNorms:  make([]float32, 0),
        LearningRates:  make([]float32, 0),
        MemoryUsage:    make([]float64, 0),
    }
}

func (mm *ModelMonitor) RecordEpoch(epochTime time.Duration, loss float32, 
                                   gradNorm float32, lr float32, memMB float64) {
    mm.EpochTimes = append(mm.EpochTimes, epochTime)
    mm.LossHistory = append(mm.LossHistory, loss)
    mm.GradientNorms = append(mm.GradientNorms, gradNorm)
    mm.LearningRates = append(mm.LearningRates, lr)
    mm.MemoryUsage = append(mm.MemoryUsage, memMB)
}

func (mm *ModelMonitor) DisplayDashboard() {
    fmt.Printf("\033[2J\033[H") // Clear screen
    
    fmt.Println("üöÄ Real-Time Model Monitor")
    fmt.Println("=========================")
    
    if len(mm.LossHistory) == 0 {
        fmt.Println("No data recorded yet...")
        return
    }
    
    // Current status
    currentEpoch := len(mm.LossHistory)
    currentLoss := mm.LossHistory[len(mm.LossHistory)-1]
    totalTime := time.Since(mm.StartTime)
    avgEpochTime := totalTime / time.Duration(currentEpoch)
    
    fmt.Printf("üìä Status: Epoch %d ‚îÇ Loss %.6f ‚îÇ Time %v ‚îÇ Avg/Epoch %v\n",
               currentEpoch, currentLoss, totalTime.Round(time.Second), 
               avgEpochTime.Round(time.Millisecond))
    
    // Performance indicators
    mm.displayPerformanceIndicators()
    
    // Training progress visualization
    mm.displayProgressCharts()
    
    // System resources
    mm.displayResourceUsage()
}

func (mm *ModelMonitor) displayPerformanceIndicators() {
    if len(mm.LossHistory) < 2 {
        return
    }
    
    fmt.Println("\nüéØ Performance Indicators:")
    
    // Loss trend
    recentLoss := mm.LossHistory[len(mm.LossHistory)-1]
    prevLoss := mm.LossHistory[len(mm.LossHistory)-2]
    lossTrend := recentLoss - prevLoss
    
    fmt.Printf("   Loss Trend: ")
    if lossTrend < 0 {
        fmt.Printf("üìâ Improving (Œî %.6f)\n", lossTrend)
    } else {
        fmt.Printf("üìà Increasing (Œî %.6f)\n", lossTrend)
    }
    
    // Convergence rate
    if len(mm.LossHistory) >= 10 {
        initialLoss := mm.LossHistory[0]
        currentLoss := mm.LossHistory[len(mm.LossHistory)-1]
        improvement := (initialLoss - currentLoss) / initialLoss * 100
        
        fmt.Printf("   Improvement: %.1f%% from initial loss\n", improvement)
    }
    
    // Training speed
    if len(mm.EpochTimes) > 0 {
        avgTime := calculateAverageTime(mm.EpochTimes)
        fmt.Printf("   Avg Speed: %v per epoch\n", avgTime.Round(time.Millisecond))
    }
}

func (mm *ModelMonitor) displayProgressCharts() {
    fmt.Println("\nüìà Training Progress:")
    
    // Loss chart
    mm.plotSimpleChart("Loss", mm.LossHistory, 15)
    
    // Gradient norms (if available)
    if len(mm.GradientNorms) > 0 {
        mm.plotSimpleChart("Grad Norm", mm.GradientNorms, 10)
    }
}

func (mm *ModelMonitor) plotSimpleChart(title string, data []float32, height int) {
    if len(data) < 2 {
        return
    }
    
    fmt.Printf("\n   %s:\n", title)
    
    // Find min/max for scaling
    min, max := data[0], data[0]
    for _, value := range data {
        if value < min {
            min = value
        }
        if value > max {
            max = value
        }
    }
    
    if max == min {
        max = min + 1 // Avoid division by zero
    }
    
    // Simple sparkline
    width := min(len(data), 60)
    fmt.Print("   ")
    
    for i := 0; i < width; i++ {
        idx := len(data) - width + i
        if idx < 0 {
            continue
        }
        
        normalized := (data[idx] - min) / (max - min)
        
        if normalized < 0.2 {
            fmt.Print("‚ñÅ")
        } else if normalized < 0.4 {
            fmt.Print("‚ñÇ")
        } else if normalized < 0.6 {
            fmt.Print("‚ñÑ")
        } else if normalized < 0.8 {
            fmt.Print("‚ñÜ")
        } else {
            fmt.Print("‚ñà")
        }
    }
    
    fmt.Printf(" (%.4f ‚Üí %.4f)\n", data[0], data[len(data)-1])
}

func (mm *ModelMonitor) displayResourceUsage() {
    if len(mm.MemoryUsage) == 0 {
        return
    }
    
    fmt.Println("\nüíæ Resource Usage:")
    
    currentMem := mm.MemoryUsage[len(mm.MemoryUsage)-1]
    fmt.Printf("   Memory: %.1f MB\n", currentMem)
    
    // Memory trend
    if len(mm.MemoryUsage) > 1 {
        prevMem := mm.MemoryUsage[len(mm.MemoryUsage)-2]
        memChange := currentMem - prevMem
        
        if memChange > 1.0 {
            fmt.Printf("   ‚ö†Ô∏è  Memory increasing (+%.1f MB)\n", memChange)
        } else if memChange < -1.0 {
            fmt.Printf("   ‚úÖ Memory decreasing (%.1f MB)\n", memChange)
        } else {
            fmt.Printf("   ‚û°Ô∏è  Memory stable\n")
        }
    }
}

func calculateAverageTime(times []time.Duration) time.Duration {
    if len(times) == 0 {
        return 0
    }
    
    var total time.Duration
    for _, t := range times {
        total += t
    }
    
    return total / time.Duration(len(times))
}
```

## üéØ Best Practices for Visualization

### Production Visualization Guidelines

```go
func visualizationBestPractices() {
    fmt.Println("üéØ Visualization Best Practices")
    fmt.Println("===============================")
    
    fmt.Println("\nüìä Training Monitoring:")
    fmt.Println("   ‚úÖ Plot training and validation loss together")
    fmt.Println("   ‚úÖ Use log scale for large loss ranges")
    fmt.Println("   ‚úÖ Show learning rate changes")
    fmt.Println("   ‚úÖ Monitor gradient norms for stability")
    fmt.Println("   ‚úÖ Track memory usage over time")
    
    fmt.Println("\nüé® Chart Design:")
    fmt.Println("   ‚úÖ Use clear, contrasting colors")
    fmt.Println("   ‚úÖ Add legends and axis labels")
    fmt.Println("   ‚úÖ Choose appropriate scales")
    fmt.Println("   ‚úÖ Highlight important thresholds")
    fmt.Println("   ‚úÖ Use consistent styling")
    
    fmt.Println("\nüìà Data Analysis:")
    fmt.Println("   ‚úÖ Show data distribution histograms")
    fmt.Println("   ‚úÖ Check for class imbalance")
    fmt.Println("   ‚úÖ Visualize feature correlations")
    fmt.Println("   ‚úÖ Identify outliers and anomalies")
    fmt.Println("   ‚úÖ Display sample data examples")
    
    fmt.Println("\nüîç Model Analysis:")
    fmt.Println("   ‚úÖ Confusion matrices for classification")
    fmt.Println("   ‚úÖ ROC curves and AUC scores")
    fmt.Println("   ‚úÖ Precision-recall curves")
    fmt.Println("   ‚úÖ Feature importance plots")
    fmt.Println("   ‚úÖ Model architecture diagrams")
    
    fmt.Println("\n‚ö° Performance Tips:")
    fmt.Println("   ‚úÖ Update visualizations periodically, not every epoch")
    fmt.Println("   ‚úÖ Use efficient ASCII plots for real-time monitoring")
    fmt.Println("   ‚úÖ Save plots to files for later analysis")
    fmt.Println("   ‚úÖ Implement visualization caching for large datasets")
    fmt.Println("   ‚úÖ Consider web-based dashboards for remote monitoring")
}

func exampleUsage() {
    fmt.Println("\nüöÄ Example Usage")
    fmt.Println("================")
    
    fmt.Println(`
// 1. Training with visualization
visualizer := NewTrainingVisualizer()
for epoch := 1; epoch <= numEpochs; epoch++ {
    result, _ := trainer.TrainBatch(inputs, inputShape, targets, targetShape)
    visualizer.AddMetrics(epoch, result.Loss, valLoss, accuracy)
    
    if epoch%5 == 0 {
        visualizer.DisplayProgress()
    }
}

// 2. Model architecture analysis
modelViz := NewModelVisualizer(model)
modelViz.DisplayArchitecture()

// 3. Dataset analysis
dataViz := NewDataVisualizer(trainData, trainLabels, "Training Set")
dataViz.AnalyzeDataset()

// 4. Classification results
classViz := NewClassificationVisualizer(predictions, trueLabels, classNames)
classViz.DisplayConfusionMatrix()

// 5. Real-time monitoring
monitor := NewModelMonitor()
for epoch := 1; epoch <= numEpochs; epoch++ {
    start := time.Now()
    result, _ := trainer.TrainBatch(inputs, inputShape, targets, targetShape)
    epochTime := time.Since(start)
    
    monitor.RecordEpoch(epochTime, result.Loss, gradNorm, learningRate, memUsage)
    monitor.DisplayDashboard()
}`)
}
```

## üöÄ Integration with External Tools

### Exporting Data for Advanced Visualization

```go
// DataExporter helps export go-metal data to external visualization tools
type DataExporter struct {
    OutputDir string
}

func NewDataExporter(outputDir string) *DataExporter {
    return &DataExporter{OutputDir: outputDir}
}

func (de *DataExporter) ExportTrainingMetrics(losses []float32, accuracies []float32, filename string) error {
    fmt.Printf("üìÅ Exporting training metrics to %s/%s.csv\n", de.OutputDir, filename)
    
    // Create CSV content
    csvContent := "epoch,loss,accuracy\n"
    for i := 0; i < len(losses); i++ {
        accuracy := float32(0)
        if i < len(accuracies) {
            accuracy = accuracies[i]
        }
        csvContent += fmt.Sprintf("%d,%.6f,%.6f\n", i+1, losses[i], accuracy)
    }
    
    // Save to file (simplified - in practice, use proper file handling)
    fmt.Printf("   ‚úÖ CSV format ready (%d rows)\n", len(losses))
    fmt.Println("   üí° Import into tools like Excel, Python/matplotlib, R, etc.")
    
    return nil
}

func (de *DataExporter) ExportPythonScript(modelName string) {
    fmt.Printf("üêç Generating Python visualization script for %s\n", modelName)
    
    pythonScript := `
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Load training data
data = pd.read_csv('training_metrics.csv')

# Create comprehensive visualization
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
fig.suptitle('Go-Metal Model Training Analysis', fontsize=16)

# Training loss
axes[0,0].plot(data['epoch'], data['loss'], 'b-', linewidth=2)
axes[0,0].set_title('Training Loss')
axes[0,0].set_xlabel('Epoch')
axes[0,0].set_ylabel('Loss')
axes[0,0].grid(True, alpha=0.3)

# Training accuracy
axes[0,1].plot(data['epoch'], data['accuracy']*100, 'g-', linewidth=2)
axes[0,1].set_title('Training Accuracy')
axes[0,1].set_xlabel('Epoch')
axes[0,1].set_ylabel('Accuracy (%)')
axes[0,1].grid(True, alpha=0.3)

# Loss distribution
axes[1,0].hist(data['loss'], bins=20, alpha=0.7, color='blue')
axes[1,0].set_title('Loss Distribution')
axes[1,0].set_xlabel('Loss Value')
axes[1,0].set_ylabel('Frequency')

# Training progress
axes[1,1].plot(data['epoch'], data['loss'], 'b-', label='Loss', linewidth=2)
axes[1,1].set_xlabel('Epoch')
axes[1,1].set_ylabel('Loss', color='b')
axes[1,1].tick_params(axis='y', labelcolor='b')

ax2 = axes[1,1].twinx()
ax2.plot(data['epoch'], data['accuracy']*100, 'g-', label='Accuracy', linewidth=2)
ax2.set_ylabel('Accuracy (%)', color='g')
ax2.tick_params(axis='y', labelcolor='g')

plt.tight_layout()
plt.savefig('training_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

print("‚úÖ Visualization saved as 'training_analysis.png'")
`
    
    fmt.Println("   ‚úÖ Python script generated")
    fmt.Println("   üí° Run with: python visualize_training.py")
    fmt.Println("   üìä Requires: matplotlib, pandas, numpy")
}

func (de *DataExporter) SuggestVisualizationTools() {
    fmt.Println("\nüõ†Ô∏è Recommended Visualization Tools")
    fmt.Println("==================================")
    
    tools := []struct {
        name string
        description string
        useCase string
        setup string
    }{
        {
            "Python + Matplotlib",
            "Comprehensive plotting library",
            "Static plots, research, reports",
            "pip install matplotlib pandas",
        },
        {
            "Python + Plotly",
            "Interactive web-based plots",
            "Interactive dashboards, exploration",
            "pip install plotly",
        },
        {
            "TensorBoard",
            "ML-focused visualization platform",
            "Real-time monitoring, experiment tracking",
            "pip install tensorboard",
        },
        {
            "Grafana",
            "Real-time dashboard platform",
            "Production monitoring, alerting",
            "Docker: grafana/grafana",
        },
        {
            "R + ggplot2",
            "Statistical visualization",
            "Statistical analysis, publication",
            "install.packages('ggplot2')",
        },
    }
    
    fmt.Printf("%-20s ‚îÇ %-30s ‚îÇ %-25s ‚îÇ %-25s\n",
               "Tool", "Description", "Best For", "Installation")
    fmt.Println("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
    
    for _, tool := range tools {
        fmt.Printf("%-20s ‚îÇ %-30s ‚îÇ %-25s ‚îÇ %-25s\n",
                   tool.name, tool.description, tool.useCase, tool.setup)
    }
    
    fmt.Println("\nüí° Quick Start Recommendations:")
    fmt.Println("   üêç Python users: Start with matplotlib for static plots")
    fmt.Println("   üåê Interactive needs: Use Plotly for web-based dashboards") 
    fmt.Println("   üîÑ Real-time monitoring: Set up Grafana for production")
    fmt.Println("   üìä Statistical analysis: Use R + ggplot2 for research")
}
```

## üéì Complete Visualization Example

```go
func completeVisualizationExample() {
    fmt.Println("üéì Complete Visualization Workflow")
    fmt.Println("==================================")
    
    fmt.Println(`
// Complete example integrating all visualization components
func runCompleteVisualizationWorkflow() {
    // 1. Setup
    device, _ := cgo_bridge.CreateMetalDevice()
    defer cgo_bridge.DestroyMetalDevice(device)
    memory.InitializeGlobalMemoryManager(device)
    
    // 2. Data analysis
    dataViz := NewDataVisualizer(trainData, trainLabels, "MNIST Training")
    dataViz.AnalyzeDataset()
    
    // 3. Model architecture
    modelViz := NewModelVisualizer(model)
    modelViz.DisplayArchitecture()
    
    // 4. Training with visualization
    visualizer := NewTrainingVisualizer()
    monitor := NewModelMonitor()
    
    for epoch := 1; epoch <= 100; epoch++ {
        start := time.Now()
        
        // Training step
        result, _ := trainer.TrainBatch(inputs, inputShape, targets, targetShape)
        
        // Record metrics
        epochTime := time.Since(start)
        gradNorm := float32(1.0) // Calculate actual gradient norm
        lr := 0.001
        memUsage := 256.0 // Get actual memory usage
        
        visualizer.AddMetrics(epoch, result.Loss, result.Loss*1.1, 0.85)
        monitor.RecordEpoch(epochTime, result.Loss, gradNorm, lr, memUsage)
        
        // Display progress
        if epoch%10 == 0 {
            visualizer.DisplayProgress()
            monitor.DisplayDashboard()
        }
    }
    
    // 5. Final analysis
    predictions := make([]float32, len(testLabels)) // Get actual predictions
    classViz := NewClassificationVisualizer(predictions, testLabels, classNames)
    classViz.DisplayConfusionMatrix()
    
    // 6. Export for external tools
    exporter := NewDataExporter("./visualization_output")
    exporter.ExportTrainingMetrics(visualizer.TrainingLosses, visualizer.Accuracies, "training")
    exporter.ExportPythonScript("mnist_model")
    exporter.SuggestVisualizationTools()
    
    fmt.Println("\\nüéâ Complete visualization workflow finished!")
    fmt.Println("   ‚úÖ Real-time training monitoring")
    fmt.Println("   ‚úÖ Model architecture analysis")
    fmt.Println("   ‚úÖ Data quality assessment")
    fmt.Println("   ‚úÖ Performance evaluation")
    fmt.Println("   ‚úÖ Export for external tools")
}`)
}
```

## üöÄ Ready for Production

This comprehensive visualization guide demonstrates:

- **Real-time Monitoring**: Live training progress and performance tracking
- **Model Analysis**: Architecture visualization and performance metrics
- **Data Insights**: Dataset analysis and quality assessment
- **Production Integration**: Export capabilities and tool recommendations
- **Best Practices**: Professional visualization standards

**Continue Learning:**
- **[Performance Guide](performance.md)** - Optimize visualization performance
- **[Mixed Precision Tutorial](../tutorials/mixed-precision.md)** - Monitor FP16 training
- **[Advanced Examples](../examples/)** - Real-world visualization applications

---

## üß† Key Takeaways

- **Real-time feedback improves training**: Monitor progress as it happens
- **Visualization reveals insights**: Spot overfitting, convergence issues, data problems
- **ASCII plots work well in CLI**: Effective for terminal-based monitoring
- **Export enables collaboration**: Share data with visualization specialists
- **Multiple views tell the story**: Combine training metrics, model analysis, and data exploration
- **Go-metal advantages**: GPU-resident data enables efficient monitoring without performance impact

You now have the skills to create production-ready visualizations for any go-metal project!